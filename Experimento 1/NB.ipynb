{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf026ff-8cbf-414b-a47b-9ca1cb0b2652",
   "metadata": {
    "tags": []
   },
   "source": [
    "_Alberto Medrano Fernández_\n",
    "\n",
    "# NB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe473f3-1603-43b8-8c4a-fe001e945785",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a37898-36cc-40b9-a502-97fc4f538cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from time import time\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder \n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeacebd-c31e-45bb-8d1c-037352c4acc7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd39d501-dc75-4f2e-a36c-1e26ad59c861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uid</th>\n",
       "      <th>originh</th>\n",
       "      <th>originp</th>\n",
       "      <th>responh</th>\n",
       "      <th>responp</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>idle.max</th>\n",
       "      <th>idle.tot</th>\n",
       "      <th>idle.avg</th>\n",
       "      <th>idle.std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>bwd_last_window_size</th>\n",
       "      <th>attack_category</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cmu9v81jToQyRF1gbk</td>\n",
       "      <td>184.0.48.168</td>\n",
       "      <td>38164</td>\n",
       "      <td>184.0.48.150</td>\n",
       "      <td>50443</td>\n",
       "      <td>0 days 00:00:00.000060</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CO21hl3TWkuXTOgajk</td>\n",
       "      <td>184.0.48.169</td>\n",
       "      <td>43068</td>\n",
       "      <td>184.0.48.150</td>\n",
       "      <td>50443</td>\n",
       "      <td>0 days 00:00:00.000083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBLJ6L19FP0MfYX7Oh</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:01:59.996602</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999912e+07</td>\n",
       "      <td>1.199966e+08</td>\n",
       "      <td>5.999830e+07</td>\n",
       "      <td>1156.846698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ChTG451zJ7hUYOcqje</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:00:59.996909</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cn9y6E2KVxzQbs5wjc</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:00:59.992130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>16634</td>\n",
       "      <td>Clt16PPxzrXEtpa5d</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>53866</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000027</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>53170</td>\n",
       "      <td>Cs8RA72uHDiQa5ch2k</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>54318</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000027</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>53529</td>\n",
       "      <td>Cy4dqo4YEq5YGxjUXa</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>65355</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>86308</td>\n",
       "      <td>CFXfNV3OTG04e0UnP4</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>53642</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000054</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>99240</td>\n",
       "      <td>CqO7kc2eC5InNvWrtl</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>61000</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                 uid       originh  originp  \\\n",
       "0                0  Cmu9v81jToQyRF1gbk  184.0.48.168    38164   \n",
       "1                1  CO21hl3TWkuXTOgajk  184.0.48.169    43068   \n",
       "2                2  CBLJ6L19FP0MfYX7Oh  184.0.48.124     5678   \n",
       "3                3  ChTG451zJ7hUYOcqje  184.0.48.124     5678   \n",
       "4                4  Cn9y6E2KVxzQbs5wjc  184.0.48.124     5678   \n",
       "...            ...                 ...           ...      ...   \n",
       "228248       16634   Clt16PPxzrXEtpa5d   184.0.48.20    53866   \n",
       "228249       53170  Cs8RA72uHDiQa5ch2k   184.0.48.20    54318   \n",
       "228250       53529  Cy4dqo4YEq5YGxjUXa   184.0.48.20    65355   \n",
       "228251       86308  CFXfNV3OTG04e0UnP4   184.0.48.20    53642   \n",
       "228252       99240  CqO7kc2eC5InNvWrtl   184.0.48.20    61000   \n",
       "\n",
       "                responh  responp           flow_duration  fwd_pkts_tot  \\\n",
       "0          184.0.48.150    50443  0 days 00:00:00.000060             1   \n",
       "1          184.0.48.150    50443  0 days 00:00:00.000083             1   \n",
       "2       255.255.255.255     5678  0 days 00:01:59.996602             3   \n",
       "3       255.255.255.255     5678  0 days 00:00:59.996909             2   \n",
       "4       255.255.255.255     5678  0 days 00:00:59.992130             2   \n",
       "...                 ...      ...                     ...           ...   \n",
       "228248     184.0.48.255     1947  0 days 00:00:00.000027             2   \n",
       "228249     184.0.48.255     1947  0 days 00:00:00.000027             2   \n",
       "228250     184.0.48.255     1947         0 days 00:00:00             2   \n",
       "228251     184.0.48.255     1947  0 days 00:00:00.000054             2   \n",
       "228252     184.0.48.255     1947         0 days 00:00:00             2   \n",
       "\n",
       "        bwd_pkts_tot  fwd_data_pkts_tot  ...      idle.max      idle.tot  \\\n",
       "0                  1                  0  ...  0.000000e+00  0.000000e+00   \n",
       "1                  1                  0  ...  0.000000e+00  0.000000e+00   \n",
       "2                  0                  3  ...  5.999912e+07  1.199966e+08   \n",
       "3                  0                  2  ...  5.999691e+07  5.999691e+07   \n",
       "4                  0                  2  ...  5.999213e+07  5.999213e+07   \n",
       "...              ...                ...  ...           ...           ...   \n",
       "228248             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228249             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228250             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228251             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228252             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "\n",
       "            idle.avg     idle.std  fwd_init_window_size  bwd_init_window_size  \\\n",
       "0       0.000000e+00     0.000000                 64240                     0   \n",
       "1       0.000000e+00     0.000000                 64240                     0   \n",
       "2       5.999830e+07  1156.846698                     0                     0   \n",
       "3       5.999691e+07     0.000000                     0                     0   \n",
       "4       5.999213e+07     0.000000                     0                     0   \n",
       "...              ...          ...                   ...                   ...   \n",
       "228248  0.000000e+00     0.000000                     0                     0   \n",
       "228249  0.000000e+00     0.000000                     0                     0   \n",
       "228250  0.000000e+00     0.000000                     0                     0   \n",
       "228251  0.000000e+00     0.000000                     0                     0   \n",
       "228252  0.000000e+00     0.000000                     0                     0   \n",
       "\n",
       "        fwd_last_window_size  bwd_last_window_size      attack_category  Label  \n",
       "0                      64240                     0               Benign      0  \n",
       "1                      64240                     0               Benign      0  \n",
       "2                          0                     0               Benign      0  \n",
       "3                          0                     0               Benign      0  \n",
       "4                          0                     0               Benign      0  \n",
       "...                      ...                   ...                  ...    ...  \n",
       "228248                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228249                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228250                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228251                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228252                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "\n",
       "[228253 rows x 88 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hikari_2022 = pd.read_csv('ALLFLOWMETER_HIKARI2022.csv', sep=',')\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956f3516-19f9-4d0e-8610-f3ebbc7a3fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originp</th>\n",
       "      <th>responp</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>idle.min</th>\n",
       "      <th>idle.max</th>\n",
       "      <th>idle.tot</th>\n",
       "      <th>idle.avg</th>\n",
       "      <th>idle.std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>bwd_last_window_size</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38164</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>33288.126984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43068</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>24105.195402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999748e+07</td>\n",
       "      <td>5.999912e+07</td>\n",
       "      <td>1.199966e+08</td>\n",
       "      <td>5.999830e+07</td>\n",
       "      <td>1156.846698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>53866</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>73584.280702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73584.280702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>54318</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74235.469027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74235.469027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>65355</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>53642</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37117.734513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37117.734513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>61000</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        originp  responp  fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  \\\n",
       "0         38164    50443             1             1                  0   \n",
       "1         43068    50443             1             1                  0   \n",
       "2          5678     5678             3             0                  3   \n",
       "3          5678     5678             2             0                  2   \n",
       "4          5678     5678             2             0                  2   \n",
       "...         ...      ...           ...           ...                ...   \n",
       "228248    53866     1947             2             0                  2   \n",
       "228249    54318     1947             2             0                  2   \n",
       "228250    65355     1947             2             0                  2   \n",
       "228251    53642     1947             2             0                  2   \n",
       "228252    61000     1947             2             0                  2   \n",
       "\n",
       "        bwd_data_pkts_tot  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
       "0                       0      16644.063492      16644.063492   \n",
       "1                       0      12052.597701      12052.597701   \n",
       "2                       0          0.025001          0.000000   \n",
       "3                       0          0.033335          0.000000   \n",
       "4                       0          0.033338          0.000000   \n",
       "...                   ...               ...               ...   \n",
       "228248                  0      73584.280702          0.000000   \n",
       "228249                  0      74235.469027          0.000000   \n",
       "228250                  0          0.000000          0.000000   \n",
       "228251                  0      37117.734513          0.000000   \n",
       "228252                  0          0.000000          0.000000   \n",
       "\n",
       "        flow_pkts_per_sec  down_up_ratio  ...      idle.min      idle.max  \\\n",
       "0            33288.126984            1.0  ...  0.000000e+00  0.000000e+00   \n",
       "1            24105.195402            1.0  ...  0.000000e+00  0.000000e+00   \n",
       "2                0.025001            0.0  ...  5.999748e+07  5.999912e+07   \n",
       "3                0.033335            0.0  ...  5.999691e+07  5.999691e+07   \n",
       "4                0.033338            0.0  ...  5.999213e+07  5.999213e+07   \n",
       "...                   ...            ...  ...           ...           ...   \n",
       "228248       73584.280702            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228249       74235.469027            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228250           0.000000            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228251       37117.734513            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228252           0.000000            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "\n",
       "            idle.tot      idle.avg     idle.std  fwd_init_window_size  \\\n",
       "0       0.000000e+00  0.000000e+00     0.000000                 64240   \n",
       "1       0.000000e+00  0.000000e+00     0.000000                 64240   \n",
       "2       1.199966e+08  5.999830e+07  1156.846698                     0   \n",
       "3       5.999691e+07  5.999691e+07     0.000000                     0   \n",
       "4       5.999213e+07  5.999213e+07     0.000000                     0   \n",
       "...              ...           ...          ...                   ...   \n",
       "228248  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228249  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228250  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228251  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228252  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "\n",
       "        bwd_init_window_size  fwd_last_window_size  bwd_last_window_size  \\\n",
       "0                          0                 64240                     0   \n",
       "1                          0                 64240                     0   \n",
       "2                          0                     0                     0   \n",
       "3                          0                     0                     0   \n",
       "4                          0                     0                     0   \n",
       "...                      ...                   ...                   ...   \n",
       "228248                     0                     0                     0   \n",
       "228249                     0                     0                     0   \n",
       "228250                     0                     0                     0   \n",
       "228251                     0                     0                     0   \n",
       "228252                     0                     0                     0   \n",
       "\n",
       "        Label  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "228248      1  \n",
       "228249      1  \n",
       "228250      1  \n",
       "228251      1  \n",
       "228252      1  \n",
       "\n",
       "[228253 rows x 80 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hikari_2022 = hikari_2022.drop(columns=['Unnamed: 0', 'uid', 'originh', 'responh', 'flow_duration', 'fwd_URG_flag_count', \n",
    "                                        'bwd_URG_flag_count', 'attack_category'])\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1982d3e1-56ee-4d9c-9a35-30da7a4dface",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after EDA:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originp</th>\n",
       "      <th>responp</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_tot</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>...</th>\n",
       "      <th>bwd_subflow_bytes</th>\n",
       "      <th>fwd_bulk_packets</th>\n",
       "      <th>bwd_bulk_packets</th>\n",
       "      <th>active.min</th>\n",
       "      <th>active.max</th>\n",
       "      <th>active.avg</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38164</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43068</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>53866</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>54318</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>65355</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>53642</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>61000</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        originp  responp  fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  \\\n",
       "0         38164    50443             1             1                  0   \n",
       "1         43068    50443             1             1                  0   \n",
       "2          5678     5678             3             0                  3   \n",
       "3          5678     5678             2             0                  2   \n",
       "4          5678     5678             2             0                  2   \n",
       "...         ...      ...           ...           ...                ...   \n",
       "228248    53866     1947             2             0                  2   \n",
       "228249    54318     1947             2             0                  2   \n",
       "228250    65355     1947             2             0                  2   \n",
       "228251    53642     1947             2             0                  2   \n",
       "228252    61000     1947             2             0                  2   \n",
       "\n",
       "        bwd_data_pkts_tot  bwd_pkts_per_sec  down_up_ratio  \\\n",
       "0                       0      16644.063492            1.0   \n",
       "1                       0      12052.597701            1.0   \n",
       "2                       0          0.000000            0.0   \n",
       "3                       0          0.000000            0.0   \n",
       "4                       0          0.000000            0.0   \n",
       "...                   ...               ...            ...   \n",
       "228248                  0          0.000000            0.0   \n",
       "228249                  0          0.000000            0.0   \n",
       "228250                  0          0.000000            0.0   \n",
       "228251                  0          0.000000            0.0   \n",
       "228252                  0          0.000000            0.0   \n",
       "\n",
       "        fwd_header_size_tot  fwd_header_size_min  ...  bwd_subflow_bytes  \\\n",
       "0                        40                   40  ...                0.0   \n",
       "1                        40                   40  ...                0.0   \n",
       "2                        24                    8  ...                0.0   \n",
       "3                        16                    8  ...                0.0   \n",
       "4                        16                    8  ...                0.0   \n",
       "...                     ...                  ...  ...                ...   \n",
       "228248                   16                    8  ...                0.0   \n",
       "228249                   16                    8  ...                0.0   \n",
       "228250                   16                    8  ...                0.0   \n",
       "228251                   16                    8  ...                0.0   \n",
       "228252                   16                    8  ...                0.0   \n",
       "\n",
       "        fwd_bulk_packets  bwd_bulk_packets  active.min  active.max  \\\n",
       "0                    0.0               0.0   60.081482   60.081482   \n",
       "1                    0.0               0.0   82.969666   82.969666   \n",
       "2                    0.0               0.0    0.000000    0.000000   \n",
       "3                    0.0               0.0    0.000000    0.000000   \n",
       "4                    0.0               0.0    0.000000    0.000000   \n",
       "...                  ...               ...         ...         ...   \n",
       "228248               0.0               0.0   27.179718   27.179718   \n",
       "228249               0.0               0.0   26.941299   26.941299   \n",
       "228250               0.0               0.0    0.000000    0.000000   \n",
       "228251               0.0               0.0   53.882599   53.882599   \n",
       "228252               0.0               0.0    0.000000    0.000000   \n",
       "\n",
       "        active.avg  fwd_init_window_size  bwd_init_window_size  \\\n",
       "0        60.081482                 64240                     0   \n",
       "1        82.969666                 64240                     0   \n",
       "2         0.000000                     0                     0   \n",
       "3         0.000000                     0                     0   \n",
       "4         0.000000                     0                     0   \n",
       "...            ...                   ...                   ...   \n",
       "228248   27.179718                     0                     0   \n",
       "228249   26.941299                     0                     0   \n",
       "228250    0.000000                     0                     0   \n",
       "228251   53.882599                     0                     0   \n",
       "228252    0.000000                     0                     0   \n",
       "\n",
       "        fwd_last_window_size  Label  \n",
       "0                      64240      0  \n",
       "1                      64240      0  \n",
       "2                          0      0  \n",
       "3                          0      0  \n",
       "4                          0      0  \n",
       "...                      ...    ...  \n",
       "228248                     0      1  \n",
       "228249                     0      1  \n",
       "228250                     0      1  \n",
       "228251                     0      1  \n",
       "228252                     0      1  \n",
       "\n",
       "[228253 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Pearson correlation coefficient\n",
    "corr = hikari_2022.corr(method ='pearson')\n",
    "\n",
    "# Extract the correlation with the target variable 'Label'\n",
    "corr_with_target = corr['Label']\n",
    "\n",
    "# Select only columns with a correlation less than 0.05\n",
    "relevant_features = corr_with_target[abs(corr_with_target) >= 0.05].index\n",
    "\n",
    "# Filter the DataFrame to keep only the relevant features\n",
    "hikari_2022 = hikari_2022[relevant_features]\n",
    "\n",
    "print(\"Dataset after EDA:\")\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078bc70f-198a-4179-8ff3-bffd38e7a6ee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dbbf30-c098-442b-92ad-ed1a9263d351",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Without feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac2ada9-2383-428d-ae11-0992d1cb9792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 0.9261790541280586\n",
      "Fold precision: 0.4426229508196721\n",
      "Fold recall: 0.9985057900635039\n",
      "Fold F1-score: 0.6133547498852685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96     42974\n",
      "           1       0.44      1.00      0.61      2677\n",
      "\n",
      "    accuracy                           0.93     45651\n",
      "   macro avg       0.72      0.96      0.79     45651\n",
      "weighted avg       0.97      0.93      0.94     45651\n",
      "\n",
      "Fold accuracy: 0.9293115156294495\n",
      "Fold precision: 0.4575614685079151\n",
      "Fold recall: 0.9977965479250827\n",
      "Fold F1-score: 0.627410229765616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96     42928\n",
      "           1       0.46      1.00      0.63      2723\n",
      "\n",
      "    accuracy                           0.93     45651\n",
      "   macro avg       0.73      0.96      0.79     45651\n",
      "weighted avg       0.97      0.93      0.94     45651\n",
      "\n",
      "Fold accuracy: 0.9317649120501194\n",
      "Fold precision: 0.455055195374102\n",
      "Fold recall: 0.9980784012298232\n",
      "Fold F1-score: 0.6251053074978938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     43049\n",
      "           1       0.46      1.00      0.63      2602\n",
      "\n",
      "    accuracy                           0.93     45651\n",
      "   macro avg       0.73      0.96      0.79     45651\n",
      "weighted avg       0.97      0.93      0.94     45651\n",
      "\n",
      "Fold accuracy: 0.9273822562979189\n",
      "Fold precision: 0.44895244429664116\n",
      "Fold recall: 0.9996297667530544\n",
      "Fold F1-score: 0.6196213425129088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96     42949\n",
      "           1       0.45      1.00      0.62      2701\n",
      "\n",
      "    accuracy                           0.93     45650\n",
      "   macro avg       0.72      0.96      0.79     45650\n",
      "weighted avg       0.97      0.93      0.94     45650\n",
      "\n",
      "Fold accuracy: 0.9307338444687843\n",
      "Fold precision: 0.4555632104719256\n",
      "Fold recall: 0.9996220710506425\n",
      "Fold F1-score: 0.6258873639375295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     43004\n",
      "           1       0.46      1.00      0.63      2646\n",
      "\n",
      "    accuracy                           0.93     45650\n",
      "   macro avg       0.73      0.96      0.79     45650\n",
      "weighted avg       0.97      0.93      0.94     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9290743165148662\n",
      "Mean precision: 0.4519510538940512\n",
      "Mean recall: 0.9987265154044213\n",
      "Mean F1-score: 0.6222757987198433\n",
      "\n",
      "El tiempo de ejecucion fue: 1.6092870235443115\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Train Naive Bayes classifier\n",
    "        nb_classifier = GaussianNB()\n",
    "        nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")   \n",
    "\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e322040-5e11-4f73-bacc-00e3a7880e76",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### With DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f870be6e-6e65-4768-8b9a-5ef0dad8660e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855us/step - accuracy: 0.9738 - loss: 0.0744 - val_accuracy: 0.9841 - val_loss: 0.0259\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 868us/step - accuracy: 0.9839 - loss: 0.0262 - val_accuracy: 0.9843 - val_loss: 0.0240\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 847us/step - accuracy: 0.9839 - loss: 0.0247 - val_accuracy: 0.9835 - val_loss: 0.0245\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 843us/step - accuracy: 0.9839 - loss: 0.0245 - val_accuracy: 0.9829 - val_loss: 0.0317\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 849us/step - accuracy: 0.9846 - loss: 0.0239 - val_accuracy: 0.9837 - val_loss: 0.0260\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 467us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448us/step\n",
      "Fold accuracy: 0.9823004972508816\n",
      "Fold precision: 0.7709481008988113\n",
      "Fold recall: 0.9932760552857677\n",
      "Fold F1-score: 0.8681031668299053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42974\n",
      "           1       0.77      0.99      0.87      2677\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.99      0.93     45651\n",
      "weighted avg       0.99      0.98      0.98     45651\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 874us/step - accuracy: 0.9718 - loss: 0.0788 - val_accuracy: 0.9834 - val_loss: 0.0279\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 911us/step - accuracy: 0.9835 - loss: 0.0269 - val_accuracy: 0.9835 - val_loss: 0.0268\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 944us/step - accuracy: 0.9844 - loss: 0.0245 - val_accuracy: 0.9837 - val_loss: 0.0250\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 880us/step - accuracy: 0.9839 - loss: 0.0242 - val_accuracy: 0.9835 - val_loss: 0.0257\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 868us/step - accuracy: 0.9849 - loss: 0.0236 - val_accuracy: 0.9837 - val_loss: 0.0247\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 850us/step - accuracy: 0.9844 - loss: 0.0236 - val_accuracy: 0.9837 - val_loss: 0.0248\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 830us/step - accuracy: 0.9843 - loss: 0.0238 - val_accuracy: 0.9836 - val_loss: 0.0248\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 846us/step - accuracy: 0.9846 - loss: 0.0237 - val_accuracy: 0.9834 - val_loss: 0.0259\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 458us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450us/step\n",
      "Fold accuracy: 0.9810518937153622\n",
      "Fold precision: 0.7688078703703703\n",
      "Fold recall: 0.9757620271759089\n",
      "Fold F1-score: 0.8600097103091116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42928\n",
      "           1       0.77      0.98      0.86      2723\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.88      0.98      0.92     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 866us/step - accuracy: 0.9682 - loss: 0.0886 - val_accuracy: 0.9837 - val_loss: 0.0260\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 842us/step - accuracy: 0.9831 - loss: 0.0274 - val_accuracy: 0.9849 - val_loss: 0.0248\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 844us/step - accuracy: 0.9841 - loss: 0.0255 - val_accuracy: 0.9839 - val_loss: 0.0253\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 837us/step - accuracy: 0.9831 - loss: 0.0259 - val_accuracy: 0.9853 - val_loss: 0.0227\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 838us/step - accuracy: 0.9838 - loss: 0.0249 - val_accuracy: 0.9851 - val_loss: 0.0238\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 858us/step - accuracy: 0.9843 - loss: 0.0240 - val_accuracy: 0.9853 - val_loss: 0.0226\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 842us/step - accuracy: 0.9847 - loss: 0.0238 - val_accuracy: 0.9852 - val_loss: 0.0232\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 846us/step - accuracy: 0.9841 - loss: 0.0239 - val_accuracy: 0.9853 - val_loss: 0.0227\n",
      "Epoch 9/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 841us/step - accuracy: 0.9845 - loss: 0.0235 - val_accuracy: 0.9852 - val_loss: 0.0226\n",
      "Epoch 10/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 836us/step - accuracy: 0.9847 - loss: 0.0237 - val_accuracy: 0.9853 - val_loss: 0.0226\n",
      "Epoch 11/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 830us/step - accuracy: 0.9840 - loss: 0.0237 - val_accuracy: 0.9854 - val_loss: 0.0223\n",
      "Epoch 12/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 835us/step - accuracy: 0.9845 - loss: 0.0235 - val_accuracy: 0.9853 - val_loss: 0.0231\n",
      "Epoch 13/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 842us/step - accuracy: 0.9847 - loss: 0.0236 - val_accuracy: 0.9854 - val_loss: 0.0222\n",
      "Epoch 14/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 880us/step - accuracy: 0.9849 - loss: 0.0232 - val_accuracy: 0.9853 - val_loss: 0.0229\n",
      "Epoch 15/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 859us/step - accuracy: 0.9841 - loss: 0.0240 - val_accuracy: 0.9854 - val_loss: 0.0223\n",
      "Epoch 16/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 866us/step - accuracy: 0.9841 - loss: 0.0237 - val_accuracy: 0.9854 - val_loss: 0.0224\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 461us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455us/step\n",
      "Fold accuracy: 0.9825852664782808\n",
      "Fold precision: 0.7689788627567729\n",
      "Fold recall: 0.9926979246733282\n",
      "Fold F1-score: 0.8666331152491192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43049\n",
      "           1       0.77      0.99      0.87      2602\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.88      0.99      0.93     45651\n",
      "weighted avg       0.99      0.98      0.98     45651\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846us/step - accuracy: 0.9738 - loss: 0.0826 - val_accuracy: 0.9847 - val_loss: 0.0244\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 843us/step - accuracy: 0.9839 - loss: 0.0265 - val_accuracy: 0.9841 - val_loss: 0.0267\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 828us/step - accuracy: 0.9845 - loss: 0.0250 - val_accuracy: 0.9846 - val_loss: 0.0239\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 830us/step - accuracy: 0.9847 - loss: 0.0240 - val_accuracy: 0.9845 - val_loss: 0.0241\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 848us/step - accuracy: 0.9842 - loss: 0.0245 - val_accuracy: 0.9839 - val_loss: 0.0263\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 848us/step - accuracy: 0.9850 - loss: 0.0233 - val_accuracy: 0.9847 - val_loss: 0.0236\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 862us/step - accuracy: 0.9850 - loss: 0.0234 - val_accuracy: 0.9844 - val_loss: 0.0246\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 871us/step - accuracy: 0.9846 - loss: 0.0234 - val_accuracy: 0.9847 - val_loss: 0.0234\n",
      "Epoch 9/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 840us/step - accuracy: 0.9847 - loss: 0.0233 - val_accuracy: 0.9845 - val_loss: 0.0246\n",
      "Epoch 10/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 835us/step - accuracy: 0.9852 - loss: 0.0228 - val_accuracy: 0.9846 - val_loss: 0.0235\n",
      "Epoch 11/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 837us/step - accuracy: 0.9847 - loss: 0.0231 - val_accuracy: 0.9832 - val_loss: 0.0375\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 458us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465us/step\n",
      "Fold accuracy: 0.9817305585980285\n",
      "Fold precision: 0.7643726989521382\n",
      "Fold recall: 0.9992595335061089\n",
      "Fold F1-score: 0.8661745827984596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42949\n",
      "           1       0.76      1.00      0.87      2701\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.88      0.99      0.93     45650\n",
      "weighted avg       0.99      0.98      0.98     45650\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 871us/step - accuracy: 0.9759 - loss: 0.0757 - val_accuracy: 0.9830 - val_loss: 0.0281\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 831us/step - accuracy: 0.9829 - loss: 0.0272 - val_accuracy: 0.9843 - val_loss: 0.0256\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 854us/step - accuracy: 0.9845 - loss: 0.0250 - val_accuracy: 0.9840 - val_loss: 0.0243\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 849us/step - accuracy: 0.9838 - loss: 0.0251 - val_accuracy: 0.9843 - val_loss: 0.0244\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 833us/step - accuracy: 0.9843 - loss: 0.0244 - val_accuracy: 0.9848 - val_loss: 0.0236\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 837us/step - accuracy: 0.9842 - loss: 0.0239 - val_accuracy: 0.9853 - val_loss: 0.0222\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 854us/step - accuracy: 0.9842 - loss: 0.0235 - val_accuracy: 0.9841 - val_loss: 0.0252\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 856us/step - accuracy: 0.9846 - loss: 0.0234 - val_accuracy: 0.9853 - val_loss: 0.0222\n",
      "Epoch 9/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 828us/step - accuracy: 0.9840 - loss: 0.0241 - val_accuracy: 0.9839 - val_loss: 0.0248\n",
      "Epoch 10/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 830us/step - accuracy: 0.9844 - loss: 0.0236 - val_accuracy: 0.9853 - val_loss: 0.0227\n",
      "Epoch 11/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 836us/step - accuracy: 0.9848 - loss: 0.0230 - val_accuracy: 0.9857 - val_loss: 0.0224\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 463us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455us/step\n",
      "Fold accuracy: 0.9828477546549835\n",
      "Fold precision: 0.7730870712401056\n",
      "Fold recall: 0.9965986394557823\n",
      "Fold F1-score: 0.8707280832095097\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43004\n",
      "           1       0.77      1.00      0.87      2646\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.89      0.99      0.93     45650\n",
      "weighted avg       0.99      0.98      0.98     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9821031941395073\n",
      "Mean precision: 0.7692389208436397\n",
      "Mean recall: 0.9915188360193792\n",
      "Mean F1-score: 0.866329731679221\n",
      "\n",
      "El tiempo de ejecucion fue: 282.8523144721985\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the DNN model\n",
    "def create_dnn(input_dim):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    \n",
    "    # Hidden layer 1\n",
    "    x = Dense(input_dim * 2)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Hidden layer 2\n",
    "    x = Dense(input_dim)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Feature layer\n",
    "    n_bottleneck = round(float(input_dim) / 2.0)\n",
    "    bottleneck = Dense(n_bottleneck)(x)\n",
    "    bottleneck = BatchNormalization()(bottleneck)\n",
    "    bottleneck = ReLU()(bottleneck)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation='sigmoid')(bottleneck)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Model for feature extraction\n",
    "    feature_extractor = Model(inputs=inputs, outputs=bottleneck)\n",
    "    \n",
    "    return model, feature_extractor\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_dnn(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        dnn, feature_extractor = create_dnn(n_inputs)\n",
    "        \n",
    "        # Early Stopping\n",
    "        early_stopping1 = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "        early_stopping2 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # Fit the DNN model\n",
    "        dnn.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        callbacks=[early_stopping1, early_stopping2])\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = feature_extractor.predict(X_train)\n",
    "        X_test_encoded = feature_extractor.predict(X_test)\n",
    "        \n",
    "        # Train Naive Bayes classifier\n",
    "        nb_classifier_encoded = GaussianNB()\n",
    "        nb_classifier_encoded.fit(X_train_encoded, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = nb_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_dnn(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9176c09-ba87-45f0-9113-30f7de69c72d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### With DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f60b25-c365-4e28-9022-59c22addcd30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_dbn(layers, file_name='dbn_structure.png'):\n",
    "    # Crear un grafo dirigido\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Añadir nodos para cada capa RBM\n",
    "    for i, n_units in enumerate(layers):\n",
    "        G.add_node(f\"RBM {i+1}\\n{n_units} unidades\", layer=i+1)\n",
    "\n",
    "    # Añadir aristas entre nodos (de una capa a otra)\n",
    "    for i in range(len(layers) - 1):\n",
    "        G.add_edge(f\"RBM {i+1}\\n{layers[i]} unidades\", f\"RBM {i+2}\\n{layers[i+1]} unidades\")\n",
    "\n",
    "    # Dibujar el grafo\n",
    "    pos = nx.spring_layout(G)  # Posición de los nodos\n",
    "    nx.draw(G, pos, with_labels=True, node_size=3000, node_color='lightblue', font_size=10, font_weight='bold')\n",
    "    \n",
    "    # Guardar la imagen a un archivo\n",
    "    plt.title(\"Arquitectura de la DBN\")\n",
    "    plt.savefig(file_name)\n",
    "    plt.show()\n",
    "    \n",
    "#visualize_dbn([X.shape[1]*2, X.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d237480-eb1b-4961-9f4d-0846b4517f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -6.25, time = 2.68s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.46, time = 3.26s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.74, time = 3.45s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.33, time = 3.29s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.79, time = 3.35s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.63, time = 3.41s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.52, time = 3.32s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.60, time = 3.22s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.58, time = 3.27s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.87, time = 3.38s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -4.79, time = 2.38s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -4.00, time = 2.85s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.15, time = 2.83s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -3.97, time = 2.81s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.14, time = 2.87s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.09, time = 2.95s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.02, time = 2.84s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.15, time = 2.88s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.13, time = 2.87s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.18, time = 2.87s\n",
      "Fold accuracy: 0.9034632319116778\n",
      "Fold precision: 0.3220896750308515\n",
      "Fold recall: 0.5849831901382144\n",
      "Fold F1-score: 0.41543971348985276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95     42974\n",
      "           1       0.32      0.58      0.42      2677\n",
      "\n",
      "    accuracy                           0.90     45651\n",
      "   macro avg       0.65      0.75      0.68     45651\n",
      "weighted avg       0.93      0.90      0.92     45651\n",
      "\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -6.49, time = 2.53s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.20, time = 3.24s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.41, time = 3.28s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.44, time = 3.27s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.68, time = 3.37s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.78, time = 3.45s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.94, time = 3.31s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.88, time = 3.34s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.90, time = 3.28s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.86, time = 3.23s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -4.57, time = 2.51s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -3.69, time = 2.89s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -3.55, time = 2.91s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -3.78, time = 2.82s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -3.50, time = 2.90s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -3.60, time = 3.20s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -3.71, time = 2.86s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -3.78, time = 2.90s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.60, time = 2.91s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.60, time = 2.81s\n",
      "Fold accuracy: 0.7241462399509321\n",
      "Fold precision: 0.12149102623101703\n",
      "Fold recall: 0.5817113477781858\n",
      "Fold F1-score: 0.2010024744622803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.73      0.83     42928\n",
      "           1       0.12      0.58      0.20      2723\n",
      "\n",
      "    accuracy                           0.72     45651\n",
      "   macro avg       0.54      0.66      0.52     45651\n",
      "weighted avg       0.91      0.72      0.80     45651\n",
      "\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -6.12, time = 2.61s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.03, time = 3.28s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.94, time = 3.37s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.21, time = 3.37s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.24, time = 3.31s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.62, time = 3.58s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.76, time = 3.35s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.72, time = 3.24s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.58, time = 3.31s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.52, time = 3.26s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.12, time = 2.51s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -4.83, time = 2.93s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.09, time = 2.89s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.16, time = 2.89s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.18, time = 2.88s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.27, time = 3.10s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5.35, time = 2.85s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5.23, time = 3.08s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.19, time = 2.93s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.30, time = 2.86s\n",
      "Fold accuracy: 0.7806400736018926\n",
      "Fold precision: 0.13970445265409295\n",
      "Fold recall: 0.5522674865488086\n",
      "Fold F1-score: 0.22299813780260708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87     43049\n",
      "           1       0.14      0.55      0.22      2602\n",
      "\n",
      "    accuracy                           0.78     45651\n",
      "   macro avg       0.55      0.67      0.55     45651\n",
      "weighted avg       0.92      0.78      0.84     45651\n",
      "\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.58, time = 2.63s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -4.86, time = 3.38s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.82, time = 3.42s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.73, time = 3.33s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.79, time = 3.36s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.70, time = 3.42s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.77, time = 3.27s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.52, time = 3.43s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.58, time = 3.20s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.52, time = 3.23s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.51, time = 2.54s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.21, time = 3.04s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.35, time = 2.91s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.39, time = 2.96s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.44, time = 3.10s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.52, time = 3.09s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5.42, time = 2.97s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5.62, time = 2.90s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.64, time = 2.93s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.43, time = 2.95s\n",
      "Fold accuracy: 0.9067469879518072\n",
      "Fold precision: 0.33035324901875274\n",
      "Fold recall: 0.5609033691225472\n",
      "Fold F1-score: 0.4158089748867847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95     42949\n",
      "           1       0.33      0.56      0.42      2701\n",
      "\n",
      "    accuracy                           0.91     45650\n",
      "   macro avg       0.65      0.74      0.68     45650\n",
      "weighted avg       0.93      0.91      0.92     45650\n",
      "\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.22, time = 2.65s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.07, time = 3.29s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.76, time = 3.33s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.69, time = 3.33s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.62, time = 3.28s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.74, time = 3.30s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.37, time = 3.29s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.75, time = 3.40s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.54, time = 3.38s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.72, time = 3.34s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -4.62, time = 2.56s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -3.88, time = 2.93s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -3.73, time = 2.90s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.92, time = 2.96s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -3.78, time = 3.07s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -3.51, time = 3.00s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -3.55, time = 2.93s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -3.67, time = 2.97s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.41, time = 2.99s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.20, time = 2.96s\n",
      "Fold accuracy: 0.9075355969331873\n",
      "Fold precision: 0.32741617357001973\n",
      "Fold recall: 0.564625850340136\n",
      "Fold F1-score: 0.41448189762796506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95     43004\n",
      "           1       0.33      0.56      0.41      2646\n",
      "\n",
      "    accuracy                           0.91     45650\n",
      "   macro avg       0.65      0.75      0.68     45650\n",
      "weighted avg       0.93      0.91      0.92     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.8445064260698993\n",
      "Mean precision: 0.24821091530094677\n",
      "Mean recall: 0.5688982487855785\n",
      "Mean F1-score: 0.333946239653898\n",
      "\n",
      "El tiempo de ejecucion fue: 317.8612217903137\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the DBN class\n",
    "class DBN(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rbm_layers, rbm_learning_rate, rbm_n_iter):\n",
    "        self.rbm_layers = rbm_layers\n",
    "        self.rbm_learning_rate = rbm_learning_rate\n",
    "        self.rbm_n_iter = rbm_n_iter\n",
    "        self.rbms = []\n",
    "        for i, n_components in enumerate(rbm_layers):\n",
    "            self.rbms.append(BernoulliRBM(n_components=n_components, learning_rate=rbm_learning_rate, n_iter=rbm_n_iter, verbose=1))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        input_data = X\n",
    "        for rbm in self.rbms:\n",
    "            rbm.fit(input_data)\n",
    "            input_data = rbm.transform(input_data)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        input_data = X\n",
    "        for rbm in self.rbms:\n",
    "            input_data = rbm.transform(input_data)\n",
    "        return input_data\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_dbn(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        dbn = DBN(rbm_layers=[n_inputs*2, n_inputs], rbm_learning_rate=0.1, rbm_n_iter=10)\n",
    "        \n",
    "        # Fit the DBN model\n",
    "        dbn.fit(X_train)\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = dbn.transform(X_train)\n",
    "        X_test_encoded = dbn.transform(X_test)\n",
    "        \n",
    "        # Train Naive Bayes classifier\n",
    "        nb_classifier_encoded = GaussianNB()\n",
    "        nb_classifier_encoded.fit(X_train_encoded, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = nb_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "    \n",
    "    \n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_dbn(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8124559-b551-4af6-8503-0901cfc82b15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### With Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c58e6d3-7e3c-4147-8ef4-a057322d7f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 755us/step - loss: 0.2424 - val_loss: 0.0999\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 723us/step - loss: 0.1851 - val_loss: 0.0575\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 734us/step - loss: 0.0932 - val_loss: 0.0519\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 746us/step - loss: 0.1615 - val_loss: 0.0370\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 716us/step - loss: 0.1229 - val_loss: 0.0429\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 715us/step - loss: 0.0805 - val_loss: 0.0316\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 736us/step - loss: 0.0862 - val_loss: 0.0838\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 727us/step - loss: 0.0885 - val_loss: 0.0329\n",
      "Epoch 9/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 729us/step - loss: 0.1326 - val_loss: 0.1329\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 415us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414us/step\n",
      "Fold accuracy: 0.9424766160653655\n",
      "Fold precision: 0.5051629884592023\n",
      "Fold recall: 0.9320134478894284\n",
      "Fold F1-score: 0.6551995798319328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     42974\n",
      "           1       0.51      0.93      0.66      2677\n",
      "\n",
      "    accuracy                           0.94     45651\n",
      "   macro avg       0.75      0.94      0.81     45651\n",
      "weighted avg       0.97      0.94      0.95     45651\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 768us/step - loss: 0.2789 - val_loss: 0.1248\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 727us/step - loss: 0.1551 - val_loss: 0.1033\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 728us/step - loss: 0.1389 - val_loss: 0.0872\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 733us/step - loss: 0.0837 - val_loss: 0.1323\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 726us/step - loss: 0.1042 - val_loss: 0.2431\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 725us/step - loss: 0.1427 - val_loss: 0.0456\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 722us/step - loss: 0.1532 - val_loss: 0.1236\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 725us/step - loss: 0.0617 - val_loss: 0.0788\n",
      "Epoch 9/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 721us/step - loss: 0.1048 - val_loss: 0.0601\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 418us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step\n",
      "Fold accuracy: 0.9497491840266369\n",
      "Fold precision: 0.546178686759957\n",
      "Fold recall: 0.9316929856775615\n",
      "Fold F1-score: 0.6886536373507057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     42928\n",
      "           1       0.55      0.93      0.69      2723\n",
      "\n",
      "    accuracy                           0.95     45651\n",
      "   macro avg       0.77      0.94      0.83     45651\n",
      "weighted avg       0.97      0.95      0.96     45651\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 780us/step - loss: 0.2415 - val_loss: 2.0957\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 730us/step - loss: 0.0969 - val_loss: 2.4022\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 719us/step - loss: 0.0693 - val_loss: 1.3902\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 739us/step - loss: 0.0780 - val_loss: 2.1887\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 722us/step - loss: 0.0715 - val_loss: 2.5624\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 727us/step - loss: 0.0792 - val_loss: 2.2379\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 412us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416us/step\n",
      "Fold accuracy: 0.9488948763444394\n",
      "Fold precision: 0.5274657953849295\n",
      "Fold recall: 0.9926979246733282\n",
      "Fold F1-score: 0.6888918522469663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     43049\n",
      "           1       0.53      0.99      0.69      2602\n",
      "\n",
      "    accuracy                           0.95     45651\n",
      "   macro avg       0.76      0.97      0.83     45651\n",
      "weighted avg       0.97      0.95      0.96     45651\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 771us/step - loss: 0.2579 - val_loss: 0.1357\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 741us/step - loss: 0.1164 - val_loss: 0.2166\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 744us/step - loss: 0.1413 - val_loss: 0.1608\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 757us/step - loss: 0.1442 - val_loss: 0.0771\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 753us/step - loss: 0.0887 - val_loss: 0.0875\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 747us/step - loss: 0.0929 - val_loss: 0.0655\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 741us/step - loss: 0.0592 - val_loss: 0.0407\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 756us/step - loss: 0.1126 - val_loss: 0.0917\n",
      "Epoch 9/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 742us/step - loss: 0.0871 - val_loss: 0.0645\n",
      "Epoch 10/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 742us/step - loss: 0.0639 - val_loss: 0.0386\n",
      "Epoch 11/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 746us/step - loss: 0.1188 - val_loss: 0.0587\n",
      "Epoch 12/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 751us/step - loss: 0.0593 - val_loss: 0.2261\n",
      "Epoch 13/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 740us/step - loss: 0.0707 - val_loss: 0.0379\n",
      "Epoch 14/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 741us/step - loss: 0.0899 - val_loss: 0.0483\n",
      "Epoch 15/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 752us/step - loss: 0.0814 - val_loss: 0.0523\n",
      "Epoch 16/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 759us/step - loss: 0.0799 - val_loss: 0.0742\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 422us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407us/step\n",
      "Fold accuracy: 0.9553121577217962\n",
      "Fold precision: 0.5717386585630562\n",
      "Fold recall: 0.9751943724546465\n",
      "Fold F1-score: 0.7208538587848933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98     42949\n",
      "           1       0.57      0.98      0.72      2701\n",
      "\n",
      "    accuracy                           0.96     45650\n",
      "   macro avg       0.79      0.96      0.85     45650\n",
      "weighted avg       0.97      0.96      0.96     45650\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 759us/step - loss: 0.2841 - val_loss: 0.4439\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 732us/step - loss: 0.1696 - val_loss: 0.2381\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 735us/step - loss: 0.0956 - val_loss: 0.1267\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 732us/step - loss: 0.1062 - val_loss: 0.0624\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 737us/step - loss: 0.0886 - val_loss: 0.5576\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 742us/step - loss: 0.1103 - val_loss: 0.5862\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 742us/step - loss: 0.1047 - val_loss: 0.1108\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 420us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409us/step\n",
      "Fold accuracy: 0.9536473165388828\n",
      "Fold precision: 0.5573593073593074\n",
      "Fold recall: 0.973167044595616\n",
      "Fold F1-score: 0.7087806220754198\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     43004\n",
      "           1       0.56      0.97      0.71      2646\n",
      "\n",
      "    accuracy                           0.95     45650\n",
      "   macro avg       0.78      0.96      0.84     45650\n",
      "weighted avg       0.97      0.95      0.96     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9500160301394243\n",
      "Mean precision: 0.5415810873052904\n",
      "Mean recall: 0.9609531550581162\n",
      "Mean F1-score: 0.6924759100579836\n",
      "\n",
      "El tiempo de ejecucion fue: 229.49069714546204\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the autoencoder model\n",
    "def create_autoencoder(n_inputs):\n",
    "    inputs = Input(shape=(n_inputs,))\n",
    "    \n",
    "    # Define Encoder\n",
    "    e = Dense(n_inputs*2)(inputs)\n",
    "    e = BatchNormalization()(e)\n",
    "    e = LeakyReLU()(e)\n",
    "    \n",
    "    # Bottleneck\n",
    "    n_bottleneck = round(float(n_inputs)/2.0)\n",
    "    bottleneck = Dense(n_bottleneck)(e)\n",
    "    \n",
    "    # Define Decoder\n",
    "    d = Dense(n_inputs*2)(bottleneck)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU()(d)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(n_inputs, activation='linear')(d)\n",
    "    \n",
    "    # Define autoencoder model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Define encoder model\n",
    "    encoder = Model(inputs=inputs, outputs=bottleneck)\n",
    "    \n",
    "    return model, encoder\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_autoencoder(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        autoencoder, encoder = create_autoencoder(n_inputs)\n",
    "        \n",
    "        # Early Stopping\n",
    "        early_stopping1 = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "        early_stopping2 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # Fit the autoencoder model\n",
    "        autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, verbose=1,\n",
    "                        validation_data=(X_test, X_test),\n",
    "                        callbacks=[early_stopping1, early_stopping2])\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = encoder.predict(X_train)\n",
    "        X_test_encoded = encoder.predict(X_test)\n",
    "        \n",
    "        # Train Naive Bayes classifier\n",
    "        nb_classifier_encoded = GaussianNB()\n",
    "        nb_classifier_encoded.fit(X_train_encoded, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = nb_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_autoencoder(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4daef-afdd-4dfe-a145-05ab6c4368c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
