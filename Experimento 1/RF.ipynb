{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf026ff-8cbf-414b-a47b-9ca1cb0b2652",
   "metadata": {
    "tags": []
   },
   "source": [
    "_Alberto Medrano Fernández_\n",
    "\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe473f3-1603-43b8-8c4a-fe001e945785",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a37898-36cc-40b9-a502-97fc4f538cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from time import time\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder \n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeacebd-c31e-45bb-8d1c-037352c4acc7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd39d501-dc75-4f2e-a36c-1e26ad59c861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uid</th>\n",
       "      <th>originh</th>\n",
       "      <th>originp</th>\n",
       "      <th>responh</th>\n",
       "      <th>responp</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>idle.max</th>\n",
       "      <th>idle.tot</th>\n",
       "      <th>idle.avg</th>\n",
       "      <th>idle.std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>bwd_last_window_size</th>\n",
       "      <th>attack_category</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cmu9v81jToQyRF1gbk</td>\n",
       "      <td>184.0.48.168</td>\n",
       "      <td>38164</td>\n",
       "      <td>184.0.48.150</td>\n",
       "      <td>50443</td>\n",
       "      <td>0 days 00:00:00.000060</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CO21hl3TWkuXTOgajk</td>\n",
       "      <td>184.0.48.169</td>\n",
       "      <td>43068</td>\n",
       "      <td>184.0.48.150</td>\n",
       "      <td>50443</td>\n",
       "      <td>0 days 00:00:00.000083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBLJ6L19FP0MfYX7Oh</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:01:59.996602</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999912e+07</td>\n",
       "      <td>1.199966e+08</td>\n",
       "      <td>5.999830e+07</td>\n",
       "      <td>1156.846698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ChTG451zJ7hUYOcqje</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:00:59.996909</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cn9y6E2KVxzQbs5wjc</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:00:59.992130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>16634</td>\n",
       "      <td>Clt16PPxzrXEtpa5d</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>53866</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000027</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>53170</td>\n",
       "      <td>Cs8RA72uHDiQa5ch2k</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>54318</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000027</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>53529</td>\n",
       "      <td>Cy4dqo4YEq5YGxjUXa</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>65355</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>86308</td>\n",
       "      <td>CFXfNV3OTG04e0UnP4</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>53642</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000054</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>99240</td>\n",
       "      <td>CqO7kc2eC5InNvWrtl</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>61000</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                 uid       originh  originp  \\\n",
       "0                0  Cmu9v81jToQyRF1gbk  184.0.48.168    38164   \n",
       "1                1  CO21hl3TWkuXTOgajk  184.0.48.169    43068   \n",
       "2                2  CBLJ6L19FP0MfYX7Oh  184.0.48.124     5678   \n",
       "3                3  ChTG451zJ7hUYOcqje  184.0.48.124     5678   \n",
       "4                4  Cn9y6E2KVxzQbs5wjc  184.0.48.124     5678   \n",
       "...            ...                 ...           ...      ...   \n",
       "228248       16634   Clt16PPxzrXEtpa5d   184.0.48.20    53866   \n",
       "228249       53170  Cs8RA72uHDiQa5ch2k   184.0.48.20    54318   \n",
       "228250       53529  Cy4dqo4YEq5YGxjUXa   184.0.48.20    65355   \n",
       "228251       86308  CFXfNV3OTG04e0UnP4   184.0.48.20    53642   \n",
       "228252       99240  CqO7kc2eC5InNvWrtl   184.0.48.20    61000   \n",
       "\n",
       "                responh  responp           flow_duration  fwd_pkts_tot  \\\n",
       "0          184.0.48.150    50443  0 days 00:00:00.000060             1   \n",
       "1          184.0.48.150    50443  0 days 00:00:00.000083             1   \n",
       "2       255.255.255.255     5678  0 days 00:01:59.996602             3   \n",
       "3       255.255.255.255     5678  0 days 00:00:59.996909             2   \n",
       "4       255.255.255.255     5678  0 days 00:00:59.992130             2   \n",
       "...                 ...      ...                     ...           ...   \n",
       "228248     184.0.48.255     1947  0 days 00:00:00.000027             2   \n",
       "228249     184.0.48.255     1947  0 days 00:00:00.000027             2   \n",
       "228250     184.0.48.255     1947         0 days 00:00:00             2   \n",
       "228251     184.0.48.255     1947  0 days 00:00:00.000054             2   \n",
       "228252     184.0.48.255     1947         0 days 00:00:00             2   \n",
       "\n",
       "        bwd_pkts_tot  fwd_data_pkts_tot  ...      idle.max      idle.tot  \\\n",
       "0                  1                  0  ...  0.000000e+00  0.000000e+00   \n",
       "1                  1                  0  ...  0.000000e+00  0.000000e+00   \n",
       "2                  0                  3  ...  5.999912e+07  1.199966e+08   \n",
       "3                  0                  2  ...  5.999691e+07  5.999691e+07   \n",
       "4                  0                  2  ...  5.999213e+07  5.999213e+07   \n",
       "...              ...                ...  ...           ...           ...   \n",
       "228248             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228249             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228250             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228251             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228252             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "\n",
       "            idle.avg     idle.std  fwd_init_window_size  bwd_init_window_size  \\\n",
       "0       0.000000e+00     0.000000                 64240                     0   \n",
       "1       0.000000e+00     0.000000                 64240                     0   \n",
       "2       5.999830e+07  1156.846698                     0                     0   \n",
       "3       5.999691e+07     0.000000                     0                     0   \n",
       "4       5.999213e+07     0.000000                     0                     0   \n",
       "...              ...          ...                   ...                   ...   \n",
       "228248  0.000000e+00     0.000000                     0                     0   \n",
       "228249  0.000000e+00     0.000000                     0                     0   \n",
       "228250  0.000000e+00     0.000000                     0                     0   \n",
       "228251  0.000000e+00     0.000000                     0                     0   \n",
       "228252  0.000000e+00     0.000000                     0                     0   \n",
       "\n",
       "        fwd_last_window_size  bwd_last_window_size      attack_category  Label  \n",
       "0                      64240                     0               Benign      0  \n",
       "1                      64240                     0               Benign      0  \n",
       "2                          0                     0               Benign      0  \n",
       "3                          0                     0               Benign      0  \n",
       "4                          0                     0               Benign      0  \n",
       "...                      ...                   ...                  ...    ...  \n",
       "228248                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228249                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228250                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228251                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228252                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "\n",
       "[228253 rows x 88 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hikari_2022 = pd.read_csv('ALLFLOWMETER_HIKARI2022.csv', sep=',')\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956f3516-19f9-4d0e-8610-f3ebbc7a3fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originp</th>\n",
       "      <th>responp</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>idle.min</th>\n",
       "      <th>idle.max</th>\n",
       "      <th>idle.tot</th>\n",
       "      <th>idle.avg</th>\n",
       "      <th>idle.std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>bwd_last_window_size</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38164</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>33288.126984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43068</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>24105.195402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999748e+07</td>\n",
       "      <td>5.999912e+07</td>\n",
       "      <td>1.199966e+08</td>\n",
       "      <td>5.999830e+07</td>\n",
       "      <td>1156.846698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>53866</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>73584.280702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73584.280702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>54318</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74235.469027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74235.469027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>65355</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>53642</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37117.734513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37117.734513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>61000</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        originp  responp  fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  \\\n",
       "0         38164    50443             1             1                  0   \n",
       "1         43068    50443             1             1                  0   \n",
       "2          5678     5678             3             0                  3   \n",
       "3          5678     5678             2             0                  2   \n",
       "4          5678     5678             2             0                  2   \n",
       "...         ...      ...           ...           ...                ...   \n",
       "228248    53866     1947             2             0                  2   \n",
       "228249    54318     1947             2             0                  2   \n",
       "228250    65355     1947             2             0                  2   \n",
       "228251    53642     1947             2             0                  2   \n",
       "228252    61000     1947             2             0                  2   \n",
       "\n",
       "        bwd_data_pkts_tot  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
       "0                       0      16644.063492      16644.063492   \n",
       "1                       0      12052.597701      12052.597701   \n",
       "2                       0          0.025001          0.000000   \n",
       "3                       0          0.033335          0.000000   \n",
       "4                       0          0.033338          0.000000   \n",
       "...                   ...               ...               ...   \n",
       "228248                  0      73584.280702          0.000000   \n",
       "228249                  0      74235.469027          0.000000   \n",
       "228250                  0          0.000000          0.000000   \n",
       "228251                  0      37117.734513          0.000000   \n",
       "228252                  0          0.000000          0.000000   \n",
       "\n",
       "        flow_pkts_per_sec  down_up_ratio  ...      idle.min      idle.max  \\\n",
       "0            33288.126984            1.0  ...  0.000000e+00  0.000000e+00   \n",
       "1            24105.195402            1.0  ...  0.000000e+00  0.000000e+00   \n",
       "2                0.025001            0.0  ...  5.999748e+07  5.999912e+07   \n",
       "3                0.033335            0.0  ...  5.999691e+07  5.999691e+07   \n",
       "4                0.033338            0.0  ...  5.999213e+07  5.999213e+07   \n",
       "...                   ...            ...  ...           ...           ...   \n",
       "228248       73584.280702            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228249       74235.469027            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228250           0.000000            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228251       37117.734513            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228252           0.000000            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "\n",
       "            idle.tot      idle.avg     idle.std  fwd_init_window_size  \\\n",
       "0       0.000000e+00  0.000000e+00     0.000000                 64240   \n",
       "1       0.000000e+00  0.000000e+00     0.000000                 64240   \n",
       "2       1.199966e+08  5.999830e+07  1156.846698                     0   \n",
       "3       5.999691e+07  5.999691e+07     0.000000                     0   \n",
       "4       5.999213e+07  5.999213e+07     0.000000                     0   \n",
       "...              ...           ...          ...                   ...   \n",
       "228248  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228249  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228250  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228251  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228252  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "\n",
       "        bwd_init_window_size  fwd_last_window_size  bwd_last_window_size  \\\n",
       "0                          0                 64240                     0   \n",
       "1                          0                 64240                     0   \n",
       "2                          0                     0                     0   \n",
       "3                          0                     0                     0   \n",
       "4                          0                     0                     0   \n",
       "...                      ...                   ...                   ...   \n",
       "228248                     0                     0                     0   \n",
       "228249                     0                     0                     0   \n",
       "228250                     0                     0                     0   \n",
       "228251                     0                     0                     0   \n",
       "228252                     0                     0                     0   \n",
       "\n",
       "        Label  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "228248      1  \n",
       "228249      1  \n",
       "228250      1  \n",
       "228251      1  \n",
       "228252      1  \n",
       "\n",
       "[228253 rows x 80 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hikari_2022 = hikari_2022.drop(columns=['Unnamed: 0', 'uid', 'originh', 'responh', 'flow_duration', 'fwd_URG_flag_count', \n",
    "                                        'bwd_URG_flag_count', 'attack_category'])\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1982d3e1-56ee-4d9c-9a35-30da7a4dface",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after EDA:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originp</th>\n",
       "      <th>responp</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_tot</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>...</th>\n",
       "      <th>bwd_subflow_bytes</th>\n",
       "      <th>fwd_bulk_packets</th>\n",
       "      <th>bwd_bulk_packets</th>\n",
       "      <th>active.min</th>\n",
       "      <th>active.max</th>\n",
       "      <th>active.avg</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38164</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43068</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>53866</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>54318</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>65355</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>53642</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>61000</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        originp  responp  fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  \\\n",
       "0         38164    50443             1             1                  0   \n",
       "1         43068    50443             1             1                  0   \n",
       "2          5678     5678             3             0                  3   \n",
       "3          5678     5678             2             0                  2   \n",
       "4          5678     5678             2             0                  2   \n",
       "...         ...      ...           ...           ...                ...   \n",
       "228248    53866     1947             2             0                  2   \n",
       "228249    54318     1947             2             0                  2   \n",
       "228250    65355     1947             2             0                  2   \n",
       "228251    53642     1947             2             0                  2   \n",
       "228252    61000     1947             2             0                  2   \n",
       "\n",
       "        bwd_data_pkts_tot  bwd_pkts_per_sec  down_up_ratio  \\\n",
       "0                       0      16644.063492            1.0   \n",
       "1                       0      12052.597701            1.0   \n",
       "2                       0          0.000000            0.0   \n",
       "3                       0          0.000000            0.0   \n",
       "4                       0          0.000000            0.0   \n",
       "...                   ...               ...            ...   \n",
       "228248                  0          0.000000            0.0   \n",
       "228249                  0          0.000000            0.0   \n",
       "228250                  0          0.000000            0.0   \n",
       "228251                  0          0.000000            0.0   \n",
       "228252                  0          0.000000            0.0   \n",
       "\n",
       "        fwd_header_size_tot  fwd_header_size_min  ...  bwd_subflow_bytes  \\\n",
       "0                        40                   40  ...                0.0   \n",
       "1                        40                   40  ...                0.0   \n",
       "2                        24                    8  ...                0.0   \n",
       "3                        16                    8  ...                0.0   \n",
       "4                        16                    8  ...                0.0   \n",
       "...                     ...                  ...  ...                ...   \n",
       "228248                   16                    8  ...                0.0   \n",
       "228249                   16                    8  ...                0.0   \n",
       "228250                   16                    8  ...                0.0   \n",
       "228251                   16                    8  ...                0.0   \n",
       "228252                   16                    8  ...                0.0   \n",
       "\n",
       "        fwd_bulk_packets  bwd_bulk_packets  active.min  active.max  \\\n",
       "0                    0.0               0.0   60.081482   60.081482   \n",
       "1                    0.0               0.0   82.969666   82.969666   \n",
       "2                    0.0               0.0    0.000000    0.000000   \n",
       "3                    0.0               0.0    0.000000    0.000000   \n",
       "4                    0.0               0.0    0.000000    0.000000   \n",
       "...                  ...               ...         ...         ...   \n",
       "228248               0.0               0.0   27.179718   27.179718   \n",
       "228249               0.0               0.0   26.941299   26.941299   \n",
       "228250               0.0               0.0    0.000000    0.000000   \n",
       "228251               0.0               0.0   53.882599   53.882599   \n",
       "228252               0.0               0.0    0.000000    0.000000   \n",
       "\n",
       "        active.avg  fwd_init_window_size  bwd_init_window_size  \\\n",
       "0        60.081482                 64240                     0   \n",
       "1        82.969666                 64240                     0   \n",
       "2         0.000000                     0                     0   \n",
       "3         0.000000                     0                     0   \n",
       "4         0.000000                     0                     0   \n",
       "...            ...                   ...                   ...   \n",
       "228248   27.179718                     0                     0   \n",
       "228249   26.941299                     0                     0   \n",
       "228250    0.000000                     0                     0   \n",
       "228251   53.882599                     0                     0   \n",
       "228252    0.000000                     0                     0   \n",
       "\n",
       "        fwd_last_window_size  Label  \n",
       "0                      64240      0  \n",
       "1                      64240      0  \n",
       "2                          0      0  \n",
       "3                          0      0  \n",
       "4                          0      0  \n",
       "...                      ...    ...  \n",
       "228248                     0      1  \n",
       "228249                     0      1  \n",
       "228250                     0      1  \n",
       "228251                     0      1  \n",
       "228252                     0      1  \n",
       "\n",
       "[228253 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Pearson correlation coefficient\n",
    "corr = hikari_2022.corr(method ='pearson')\n",
    "\n",
    "# Extract the correlation with the target variable 'Label'\n",
    "corr_with_target = corr['Label']\n",
    "\n",
    "# Select only columns with a correlation less than 0.05\n",
    "relevant_features = corr_with_target[abs(corr_with_target) >= 0.05].index\n",
    "\n",
    "# Filter the DataFrame to keep only the relevant features\n",
    "hikari_2022 = hikari_2022[relevant_features]\n",
    "\n",
    "print(\"Dataset after EDA:\")\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078bc70f-198a-4179-8ff3-bffd38e7a6ee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dbbf30-c098-442b-92ad-ed1a9263d351",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Without feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac2ada9-2383-428d-ae11-0992d1cb9792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 0.9785327813191387\n",
      "Fold precision: 0.8106920541926035\n",
      "Fold recall: 0.827045199850579\n",
      "Fold F1-score: 0.8187869822485208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     42974\n",
      "           1       0.81      0.83      0.82      2677\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.90      0.91      0.90     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "Fold accuracy: 0.9780946748154477\n",
      "Fold precision: 0.8154522153057489\n",
      "Fold recall: 0.8178479618068307\n",
      "Fold F1-score: 0.8166483314998166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     42928\n",
      "           1       0.82      0.82      0.82      2723\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.90      0.90      0.90     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "Fold accuracy: 0.9794308996517054\n",
      "Fold precision: 0.8172453262113697\n",
      "Fold recall: 0.8232129131437356\n",
      "Fold F1-score: 0.8202182653647329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     43049\n",
      "           1       0.82      0.82      0.82      2602\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.90      0.91      0.90     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "Fold accuracy: 0.9790361445783132\n",
      "Fold precision: 0.8220088626292467\n",
      "Fold recall: 0.8241392077008516\n",
      "Fold F1-score: 0.8230726566833056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     42949\n",
      "           1       0.82      0.82      0.82      2701\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.91      0.91      0.91     45650\n",
      "weighted avg       0.98      0.98      0.98     45650\n",
      "\n",
      "Fold accuracy: 0.9801533406352684\n",
      "Fold precision: 0.8243847874720358\n",
      "Fold recall: 0.8356009070294784\n",
      "Fold F1-score: 0.829954954954955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     43004\n",
      "           1       0.82      0.84      0.83      2646\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.91      0.91      0.91     45650\n",
      "weighted avg       0.98      0.98      0.98     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9790495681999746\n",
      "Mean precision: 0.8179566491622008\n",
      "Mean recall: 0.8255692379062951\n",
      "Mean F1-score: 0.8217362381502662\n",
      "\n",
      "El tiempo de ejecucion fue: 53.05242967605591\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Train Random Forest classifier\n",
    "        rf_classifier = RandomForestClassifier(random_state=42)\n",
    "        rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")   \n",
    "\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e322040-5e11-4f73-bacc-00e3a7880e76",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### With DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f870be6e-6e65-4768-8b9a-5ef0dad8660e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850us/step - accuracy: 0.9464 - loss: 0.1271 - val_accuracy: 0.9825 - val_loss: 0.0273\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 842us/step - accuracy: 0.9843 - loss: 0.0265 - val_accuracy: 0.9842 - val_loss: 0.0260\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 820us/step - accuracy: 0.9843 - loss: 0.0248 - val_accuracy: 0.9843 - val_loss: 0.0241\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 809us/step - accuracy: 0.9843 - loss: 0.0245 - val_accuracy: 0.9843 - val_loss: 0.0239\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 816us/step - accuracy: 0.9855 - loss: 0.0233 - val_accuracy: 0.9840 - val_loss: 0.0241\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 818us/step - accuracy: 0.9842 - loss: 0.0244 - val_accuracy: 0.9842 - val_loss: 0.0247\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 815us/step - accuracy: 0.9847 - loss: 0.0240 - val_accuracy: 0.9843 - val_loss: 0.0239\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 458us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 458us/step\n",
      "Fold accuracy: 0.9794308996517054\n",
      "Fold precision: 0.8329501915708812\n",
      "Fold recall: 0.8121031004856182\n",
      "Fold F1-score: 0.8223945526763761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     42974\n",
      "           1       0.83      0.81      0.82      2677\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.91      0.90      0.91     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849us/step - accuracy: 0.9751 - loss: 0.0773 - val_accuracy: 0.9820 - val_loss: 0.0287\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 827us/step - accuracy: 0.9840 - loss: 0.0264 - val_accuracy: 0.9832 - val_loss: 0.0297\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 822us/step - accuracy: 0.9837 - loss: 0.0255 - val_accuracy: 0.9837 - val_loss: 0.0251\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 811us/step - accuracy: 0.9847 - loss: 0.0246 - val_accuracy: 0.9833 - val_loss: 0.0271\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 811us/step - accuracy: 0.9845 - loss: 0.0243 - val_accuracy: 0.9836 - val_loss: 0.0254\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 822us/step - accuracy: 0.9847 - loss: 0.0233 - val_accuracy: 0.9836 - val_loss: 0.0259\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 448us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450us/step\n",
      "Fold accuracy: 0.9780289588398939\n",
      "Fold precision: 0.815712187958884\n",
      "Fold recall: 0.8160117517443995\n",
      "Fold F1-score: 0.8158619423535891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     42928\n",
      "           1       0.82      0.82      0.82      2723\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.90      0.90      0.90     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 854us/step - accuracy: 0.9741 - loss: 0.0796 - val_accuracy: 0.9841 - val_loss: 0.0269\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 866us/step - accuracy: 0.9832 - loss: 0.0265 - val_accuracy: 0.9851 - val_loss: 0.0245\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 821us/step - accuracy: 0.9840 - loss: 0.0256 - val_accuracy: 0.9833 - val_loss: 0.0239\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 834us/step - accuracy: 0.9836 - loss: 0.0254 - val_accuracy: 0.9835 - val_loss: 0.0247\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 827us/step - accuracy: 0.9841 - loss: 0.0241 - val_accuracy: 0.9831 - val_loss: 0.0236\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 823us/step - accuracy: 0.9840 - loss: 0.0241 - val_accuracy: 0.9852 - val_loss: 0.0226\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 822us/step - accuracy: 0.9844 - loss: 0.0239 - val_accuracy: 0.9853 - val_loss: 0.0226\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 864us/step - accuracy: 0.9848 - loss: 0.0234 - val_accuracy: 0.9842 - val_loss: 0.0270\n",
      "Epoch 9/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 849us/step - accuracy: 0.9847 - loss: 0.0240 - val_accuracy: 0.9847 - val_loss: 0.0234\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 452us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439us/step\n",
      "Fold accuracy: 0.9790804144487525\n",
      "Fold precision: 0.8180764774044033\n",
      "Fold recall: 0.813989239046887\n",
      "Fold F1-score: 0.8160277403197842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     43049\n",
      "           1       0.82      0.81      0.82      2602\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.90      0.90      0.90     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 882us/step - accuracy: 0.9786 - loss: 0.0669 - val_accuracy: 0.9843 - val_loss: 0.0253\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 835us/step - accuracy: 0.9841 - loss: 0.0260 - val_accuracy: 0.9820 - val_loss: 0.0245\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 836us/step - accuracy: 0.9837 - loss: 0.0252 - val_accuracy: 0.9817 - val_loss: 0.0247\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 840us/step - accuracy: 0.9837 - loss: 0.0244 - val_accuracy: 0.9846 - val_loss: 0.0238\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 829us/step - accuracy: 0.9843 - loss: 0.0243 - val_accuracy: 0.9822 - val_loss: 0.0237\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 839us/step - accuracy: 0.9843 - loss: 0.0242 - val_accuracy: 0.9844 - val_loss: 0.0244\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 866us/step - accuracy: 0.9838 - loss: 0.0240 - val_accuracy: 0.9846 - val_loss: 0.0234\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 828us/step - accuracy: 0.9849 - loss: 0.0238 - val_accuracy: 0.9823 - val_loss: 0.0238\n",
      "Epoch 9/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 834us/step - accuracy: 0.9841 - loss: 0.0240 - val_accuracy: 0.9846 - val_loss: 0.0235\n",
      "Epoch 10/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 845us/step - accuracy: 0.9847 - loss: 0.0234 - val_accuracy: 0.9845 - val_loss: 0.0237\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 452us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444us/step\n",
      "Fold accuracy: 0.9788608981380066\n",
      "Fold precision: 0.8212435233160622\n",
      "Fold recall: 0.8215475749722325\n",
      "Fold F1-score: 0.8213955210068481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     42949\n",
      "           1       0.82      0.82      0.82      2701\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.91      0.91      0.91     45650\n",
      "weighted avg       0.98      0.98      0.98     45650\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 865us/step - accuracy: 0.9780 - loss: 0.0615 - val_accuracy: 0.9850 - val_loss: 0.0246\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 841us/step - accuracy: 0.9841 - loss: 0.0258 - val_accuracy: 0.9852 - val_loss: 0.0231\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 839us/step - accuracy: 0.9846 - loss: 0.0247 - val_accuracy: 0.9842 - val_loss: 0.0253\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 875us/step - accuracy: 0.9842 - loss: 0.0248 - val_accuracy: 0.9852 - val_loss: 0.0231\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 852us/step - accuracy: 0.9840 - loss: 0.0245 - val_accuracy: 0.9851 - val_loss: 0.0227\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 859us/step - accuracy: 0.9841 - loss: 0.0246 - val_accuracy: 0.9849 - val_loss: 0.0236\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 848us/step - accuracy: 0.9844 - loss: 0.0245 - val_accuracy: 0.9851 - val_loss: 0.0240\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 843us/step - accuracy: 0.9843 - loss: 0.0243 - val_accuracy: 0.9851 - val_loss: 0.0224\n",
      "Epoch 9/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 838us/step - accuracy: 0.9843 - loss: 0.0243 - val_accuracy: 0.9852 - val_loss: 0.0223\n",
      "Epoch 10/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 865us/step - accuracy: 0.9849 - loss: 0.0237 - val_accuracy: 0.9851 - val_loss: 0.0227\n",
      "Epoch 11/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 843us/step - accuracy: 0.9845 - loss: 0.0234 - val_accuracy: 0.9852 - val_loss: 0.0229\n",
      "Epoch 12/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 821us/step - accuracy: 0.9841 - loss: 0.0238 - val_accuracy: 0.9852 - val_loss: 0.0222\n",
      "Epoch 13/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 830us/step - accuracy: 0.9843 - loss: 0.0235 - val_accuracy: 0.9853 - val_loss: 0.0236\n",
      "Epoch 14/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 827us/step - accuracy: 0.9842 - loss: 0.0238 - val_accuracy: 0.9851 - val_loss: 0.0228\n",
      "Epoch 15/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 827us/step - accuracy: 0.9842 - loss: 0.0236 - val_accuracy: 0.9853 - val_loss: 0.0223\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 461us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469us/step\n",
      "Fold accuracy: 0.9844687842278204\n",
      "Fold precision: 0.9671972986010613\n",
      "Fold recall: 0.7577475434618292\n",
      "Fold F1-score: 0.8497563043017589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     43004\n",
      "           1       0.97      0.76      0.85      2646\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.98      0.88      0.92     45650\n",
      "weighted avg       0.98      0.98      0.98     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9799739910612357\n",
      "Mean precision: 0.8510359357702584\n",
      "Mean recall: 0.8042798419421933\n",
      "Mean F1-score: 0.8250872121316712\n",
      "\n",
      "El tiempo de ejecucion fue: 353.5967881679535\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the DNN model\n",
    "def create_dnn(input_dim):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    \n",
    "    # Hidden layer 1\n",
    "    x = Dense(input_dim * 2)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Hidden layer 2\n",
    "    x = Dense(input_dim)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Feature layer\n",
    "    n_bottleneck = round(float(input_dim) / 2.0)\n",
    "    bottleneck = Dense(n_bottleneck)(x)\n",
    "    bottleneck = BatchNormalization()(bottleneck)\n",
    "    bottleneck = ReLU()(bottleneck)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation='sigmoid')(bottleneck)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Model for feature extraction\n",
    "    feature_extractor = Model(inputs=inputs, outputs=bottleneck)\n",
    "    \n",
    "    return model, feature_extractor\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_dnn(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        dnn, feature_extractor = create_dnn(n_inputs)\n",
    "        \n",
    "        # Early Stopping\n",
    "        early_stopping1 = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "        early_stopping2 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # Fit the DNN model\n",
    "        dnn.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        callbacks=[early_stopping1, early_stopping2])\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = feature_extractor.predict(X_train)\n",
    "        X_test_encoded = feature_extractor.predict(X_test)\n",
    "        \n",
    "        # Train Random Forest classifier\n",
    "        rf_classifier_encoded = RandomForestClassifier(random_state=42)\n",
    "        rf_classifier_encoded.fit(X_train_encoded, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = rf_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_dnn(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9176c09-ba87-45f0-9113-30f7de69c72d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### With DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d237480-eb1b-4961-9f4d-0846b4517f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.86, time = 2.60s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.57, time = 3.39s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.97, time = 3.51s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.84, time = 3.47s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.97, time = 3.54s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.79, time = 3.49s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.65, time = 3.41s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.70, time = 3.36s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.63, time = 3.63s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.68, time = 3.61s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -4.49, time = 2.75s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -3.83, time = 3.33s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -3.95, time = 3.27s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.03, time = 3.39s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -3.84, time = 3.26s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -3.84, time = 2.94s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -3.89, time = 3.08s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.15, time = 3.06s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.99, time = 3.13s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.90, time = 3.17s\n",
      "Fold accuracy: 0.9837243433878776\n",
      "Fold precision: 0.987891019172553\n",
      "Fold recall: 0.73141576391483\n",
      "Fold F1-score: 0.8405237175359519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     42974\n",
      "           1       0.99      0.73      0.84      2677\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.99      0.87      0.92     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.92, time = 2.63s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.29, time = 3.31s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.14, time = 3.35s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.32, time = 3.48s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.68, time = 3.52s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.79, time = 3.47s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.54, time = 3.45s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.77, time = 3.54s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.63, time = 3.54s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.69, time = 3.40s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.33, time = 2.55s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.65, time = 3.16s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.73, time = 3.07s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.97, time = 3.10s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.85, time = 3.00s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.95, time = 3.14s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5.99, time = 3.11s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -6.07, time = 3.14s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.94, time = 3.28s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.90, time = 2.97s\n",
      "Fold accuracy: 0.9738450417296445\n",
      "Fold precision: 0.8716577540106952\n",
      "Fold recall: 0.6584649283878076\n",
      "Fold F1-score: 0.7502092050209205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     42928\n",
      "           1       0.87      0.66      0.75      2723\n",
      "\n",
      "    accuracy                           0.97     45651\n",
      "   macro avg       0.93      0.83      0.87     45651\n",
      "weighted avg       0.97      0.97      0.97     45651\n",
      "\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -6.17, time = 2.74s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.46, time = 3.68s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.55, time = 3.46s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.67, time = 3.47s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.09, time = 3.43s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.80, time = 3.55s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.98, time = 3.46s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.91, time = 3.39s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.81, time = 3.70s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.03, time = 3.52s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -6.25, time = 2.62s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -4.51, time = 3.09s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.18, time = 3.20s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.12, time = 3.10s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.01, time = 3.08s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -3.94, time = 3.01s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -3.98, time = 3.09s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -3.98, time = 2.91s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.00, time = 3.30s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.93, time = 3.22s\n",
      "Fold accuracy: 0.9744364855096274\n",
      "Fold precision: 0.7722960151802657\n",
      "Fold recall: 0.7820906994619523\n",
      "Fold F1-score: 0.7771624976131373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     43049\n",
      "           1       0.77      0.78      0.78      2602\n",
      "\n",
      "    accuracy                           0.97     45651\n",
      "   macro avg       0.88      0.88      0.88     45651\n",
      "weighted avg       0.97      0.97      0.97     45651\n",
      "\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.37, time = 2.68s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.24, time = 3.55s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.22, time = 3.51s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.91, time = 3.44s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.76, time = 3.49s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.53, time = 3.57s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.56, time = 3.37s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.66, time = 3.38s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.62, time = 3.43s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.83, time = 3.34s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -4.60, time = 2.63s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -4.37, time = 3.02s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.58, time = 2.94s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.56, time = 2.96s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.55, time = 2.98s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.58, time = 3.03s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.49, time = 3.02s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.57, time = 3.07s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.61, time = 3.38s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.55, time = 3.10s\n",
      "Fold accuracy: 0.9840306681270536\n",
      "Fold precision: 0.985236220472441\n",
      "Fold recall: 0.7412069603850425\n",
      "Fold F1-score: 0.8459750686668075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     42949\n",
      "           1       0.99      0.74      0.85      2701\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.98      0.87      0.92     45650\n",
      "weighted avg       0.98      0.98      0.98     45650\n",
      "\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.37, time = 2.68s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -4.98, time = 3.49s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.14, time = 3.40s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.81, time = 3.44s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.60, time = 3.46s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.58, time = 3.65s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.57, time = 3.43s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.51, time = 3.39s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.58, time = 3.39s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.48, time = 3.57s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -6.41, time = 2.67s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -6.67, time = 3.01s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -6.73, time = 3.13s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -6.81, time = 3.11s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -6.69, time = 3.17s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -6.91, time = 3.37s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -6.83, time = 3.26s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -6.90, time = 2.89s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -6.79, time = 2.88s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -6.88, time = 2.98s\n",
      "Fold accuracy: 0.9748083242059146\n",
      "Fold precision: 0.968671679197995\n",
      "Fold recall: 0.5842781557067271\n",
      "Fold F1-score: 0.7289014615747289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     43004\n",
      "           1       0.97      0.58      0.73      2646\n",
      "\n",
      "    accuracy                           0.97     45650\n",
      "   macro avg       0.97      0.79      0.86     45650\n",
      "weighted avg       0.97      0.97      0.97     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9781689725920236\n",
      "Mean precision: 0.91715053760679\n",
      "Mean recall: 0.6994913015712718\n",
      "Mean F1-score: 0.7885543900823093\n",
      "\n",
      "El tiempo de ejecucion fue: 677.0882494449615\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the DBN class\n",
    "class DBN(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rbm_layers, rbm_learning_rate, rbm_n_iter):\n",
    "        self.rbm_layers = rbm_layers\n",
    "        self.rbm_learning_rate = rbm_learning_rate\n",
    "        self.rbm_n_iter = rbm_n_iter\n",
    "        self.rbms = []\n",
    "        for i, n_components in enumerate(rbm_layers):\n",
    "            self.rbms.append(BernoulliRBM(n_components=n_components, learning_rate=rbm_learning_rate, n_iter=rbm_n_iter, verbose=1))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        input_data = X\n",
    "        for rbm in self.rbms:\n",
    "            rbm.fit(input_data)\n",
    "            input_data = rbm.transform(input_data)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        input_data = X\n",
    "        for rbm in self.rbms:\n",
    "            input_data = rbm.transform(input_data)\n",
    "        return input_data\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_dbn(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        dbn = DBN(rbm_layers=[n_inputs*2, n_inputs], rbm_learning_rate=0.1, rbm_n_iter=10)\n",
    "        \n",
    "        # Fit the DBN model\n",
    "        dbn.fit(X_train)\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = dbn.transform(X_train)\n",
    "        X_test_encoded = dbn.transform(X_test)\n",
    "        \n",
    "        # Train Random Forest classifier\n",
    "        rf_classifier_encoded = RandomForestClassifier(random_state=42)\n",
    "        rf_classifier_encoded.fit(X_train_encoded, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = rf_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "    \n",
    "    \n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_dbn(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8124559-b551-4af6-8503-0901cfc82b15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### With Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c58e6d3-7e3c-4147-8ef4-a057322d7f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 763us/step - loss: 0.2944 - val_loss: 0.1369\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 740us/step - loss: 0.1470 - val_loss: 0.1243\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 734us/step - loss: 0.1146 - val_loss: 0.0579\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 741us/step - loss: 0.0818 - val_loss: 0.0581\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 743us/step - loss: 0.1750 - val_loss: 0.0686\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 737us/step - loss: 0.0837 - val_loss: 0.0567\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 731us/step - loss: 0.1351 - val_loss: 0.1648\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 736us/step - loss: 0.0580 - val_loss: 0.0543\n",
      "Epoch 9/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 748us/step - loss: 0.0623 - val_loss: 0.0538\n",
      "Epoch 10/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 732us/step - loss: 0.0674 - val_loss: 0.0396\n",
      "Epoch 11/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 738us/step - loss: 0.0971 - val_loss: 0.0410\n",
      "Epoch 12/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 781us/step - loss: 0.0451 - val_loss: 0.0495\n",
      "Epoch 13/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 759us/step - loss: 0.0460 - val_loss: 0.0465\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 433us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 405us/step\n",
      "Fold accuracy: 0.9783575387176623\n",
      "Fold precision: 0.8135907909394727\n",
      "Fold recall: 0.8184534927157265\n",
      "Fold F1-score: 0.8160148975791434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     42974\n",
      "           1       0.81      0.82      0.82      2677\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.90      0.90      0.90     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 789us/step - loss: 0.3274 - val_loss: 0.2646\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 743us/step - loss: 0.1335 - val_loss: 0.1388\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 729us/step - loss: 0.1431 - val_loss: 0.1055\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 734us/step - loss: 0.1084 - val_loss: 0.2240\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 738us/step - loss: 0.1146 - val_loss: 0.0636\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 731us/step - loss: 0.0872 - val_loss: 0.0907\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 729us/step - loss: 0.1166 - val_loss: 0.0560\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 761us/step - loss: 0.0731 - val_loss: 0.0550\n",
      "Epoch 9/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 758us/step - loss: 0.1232 - val_loss: 0.0636\n",
      "Epoch 10/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 755us/step - loss: 0.1008 - val_loss: 0.0720\n",
      "Epoch 11/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 729us/step - loss: 0.1013 - val_loss: 0.1580\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 420us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409us/step\n",
      "Fold accuracy: 0.9777003789621257\n",
      "Fold precision: 0.8130738156445098\n",
      "Fold recall: 0.8130738156445098\n",
      "Fold F1-score: 0.8130738156445098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     42928\n",
      "           1       0.81      0.81      0.81      2723\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.90      0.90      0.90     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 753us/step - loss: 0.2203 - val_loss: 1.8548\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 734us/step - loss: 0.1051 - val_loss: 3.1600\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 739us/step - loss: 0.1407 - val_loss: 1.2090\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 743us/step - loss: 0.1105 - val_loss: 2.1483\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 749us/step - loss: 0.1011 - val_loss: 1.0111\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 772us/step - loss: 0.0643 - val_loss: 1.4586\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 740us/step - loss: 0.0721 - val_loss: 2.2746\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 766us/step - loss: 0.0525 - val_loss: 1.2058\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 460us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446us/step\n",
      "Fold accuracy: 0.9787080239206151\n",
      "Fold precision: 0.8146718146718147\n",
      "Fold recall: 0.8109146810146042\n",
      "Fold F1-score: 0.812788906009245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     43049\n",
      "           1       0.81      0.81      0.81      2602\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.90      0.90      0.90     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 759us/step - loss: 0.2771 - val_loss: 0.0728\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 734us/step - loss: 0.2313 - val_loss: 0.1869\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 738us/step - loss: 0.1592 - val_loss: 0.2529\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 749us/step - loss: 0.1381 - val_loss: 0.1128\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 432us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430us/step\n",
      "Fold accuracy: 0.9782913472070098\n",
      "Fold precision: 0.8166666666666667\n",
      "Fold recall: 0.8163643095149945\n",
      "Fold F1-score: 0.8165154600999814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     42949\n",
      "           1       0.82      0.82      0.82      2701\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.90      0.90      0.90     45650\n",
      "weighted avg       0.98      0.98      0.98     45650\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 780us/step - loss: 0.3003 - val_loss: 0.0661\n",
      "Epoch 2/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 758us/step - loss: 0.1520 - val_loss: 0.1178\n",
      "Epoch 3/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 735us/step - loss: 0.1388 - val_loss: 0.2395\n",
      "Epoch 4/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 740us/step - loss: 0.1133 - val_loss: 0.0600\n",
      "Epoch 5/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 736us/step - loss: 0.1450 - val_loss: 0.0676\n",
      "Epoch 6/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 734us/step - loss: 0.0996 - val_loss: 0.0582\n",
      "Epoch 7/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 763us/step - loss: 0.0924 - val_loss: 0.1962\n",
      "Epoch 8/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 754us/step - loss: 0.0788 - val_loss: 0.1160\n",
      "Epoch 9/100\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 741us/step - loss: 0.0892 - val_loss: 0.0825\n",
      "\u001b[1m5707/5707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409us/step\n",
      "Fold accuracy: 0.9794304490690033\n",
      "Fold precision: 0.8224404986777484\n",
      "Fold recall: 0.8227513227513228\n",
      "Fold F1-score: 0.82259588135273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     43004\n",
      "           1       0.82      0.82      0.82      2646\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.91      0.91      0.91     45650\n",
      "weighted avg       0.98      0.98      0.98     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9784975475752832\n",
      "Mean precision: 0.8160887173200424\n",
      "Mean recall: 0.8163115243282316\n",
      "Mean F1-score: 0.816197792137122\n",
      "\n",
      "El tiempo de ejecucion fue: 483.4700255393982\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the autoencoder model\n",
    "def create_autoencoder(n_inputs):\n",
    "    inputs = Input(shape=(n_inputs,))\n",
    "    \n",
    "    # Define Encoder\n",
    "    e = Dense(n_inputs*2)(inputs)\n",
    "    e = BatchNormalization()(e)\n",
    "    e = LeakyReLU()(e)\n",
    "    \n",
    "    # Bottleneck\n",
    "    n_bottleneck = round(float(n_inputs)/2.0)\n",
    "    bottleneck = Dense(n_bottleneck)(e)\n",
    "    \n",
    "    # Define Decoder\n",
    "    d = Dense(n_inputs*2)(bottleneck)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU()(d)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(n_inputs, activation='linear')(d)\n",
    "    \n",
    "    # Define autoencoder model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Define encoder model\n",
    "    encoder = Model(inputs=inputs, outputs=bottleneck)\n",
    "    \n",
    "    return model, encoder\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_autoencoder(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        autoencoder, encoder = create_autoencoder(n_inputs)\n",
    "        \n",
    "        # Early Stopping\n",
    "        early_stopping1 = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "        early_stopping2 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # Fit the autoencoder model\n",
    "        autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, verbose=1,\n",
    "                        validation_data=(X_test, X_test),\n",
    "                        callbacks=[early_stopping1, early_stopping2])\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = encoder.predict(X_train)\n",
    "        X_test_encoded = encoder.predict(X_test)\n",
    "        \n",
    "        # Train Random Forest classifier\n",
    "        rf_classifier_encoded = RandomForestClassifier(random_state=42)\n",
    "        rf_classifier_encoded.fit(X_train_encoded, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = rf_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_autoencoder(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4daef-afdd-4dfe-a145-05ab6c4368c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
