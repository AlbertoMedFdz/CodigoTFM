{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf026ff-8cbf-414b-a47b-9ca1cb0b2652",
   "metadata": {
    "tags": []
   },
   "source": [
    "_Alberto Medrano Fern√°ndez_\n",
    "\n",
    "# AdaBoost (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe473f3-1603-43b8-8c4a-fe001e945785",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a37898-36cc-40b9-a502-97fc4f538cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from time import time\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder \n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeacebd-c31e-45bb-8d1c-037352c4acc7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd39d501-dc75-4f2e-a36c-1e26ad59c861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uid</th>\n",
       "      <th>originh</th>\n",
       "      <th>originp</th>\n",
       "      <th>responh</th>\n",
       "      <th>responp</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>idle.max</th>\n",
       "      <th>idle.tot</th>\n",
       "      <th>idle.avg</th>\n",
       "      <th>idle.std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>bwd_last_window_size</th>\n",
       "      <th>attack_category</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cmu9v81jToQyRF1gbk</td>\n",
       "      <td>184.0.48.168</td>\n",
       "      <td>38164</td>\n",
       "      <td>184.0.48.150</td>\n",
       "      <td>50443</td>\n",
       "      <td>0 days 00:00:00.000060</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CO21hl3TWkuXTOgajk</td>\n",
       "      <td>184.0.48.169</td>\n",
       "      <td>43068</td>\n",
       "      <td>184.0.48.150</td>\n",
       "      <td>50443</td>\n",
       "      <td>0 days 00:00:00.000083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBLJ6L19FP0MfYX7Oh</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:01:59.996602</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999912e+07</td>\n",
       "      <td>1.199966e+08</td>\n",
       "      <td>5.999830e+07</td>\n",
       "      <td>1156.846698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ChTG451zJ7hUYOcqje</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:00:59.996909</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cn9y6E2KVxzQbs5wjc</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:00:59.992130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>16634</td>\n",
       "      <td>Clt16PPxzrXEtpa5d</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>53866</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000027</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>53170</td>\n",
       "      <td>Cs8RA72uHDiQa5ch2k</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>54318</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000027</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>53529</td>\n",
       "      <td>Cy4dqo4YEq5YGxjUXa</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>65355</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>86308</td>\n",
       "      <td>CFXfNV3OTG04e0UnP4</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>53642</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000054</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>99240</td>\n",
       "      <td>CqO7kc2eC5InNvWrtl</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>61000</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows √ó 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                 uid       originh  originp  \\\n",
       "0                0  Cmu9v81jToQyRF1gbk  184.0.48.168    38164   \n",
       "1                1  CO21hl3TWkuXTOgajk  184.0.48.169    43068   \n",
       "2                2  CBLJ6L19FP0MfYX7Oh  184.0.48.124     5678   \n",
       "3                3  ChTG451zJ7hUYOcqje  184.0.48.124     5678   \n",
       "4                4  Cn9y6E2KVxzQbs5wjc  184.0.48.124     5678   \n",
       "...            ...                 ...           ...      ...   \n",
       "228248       16634   Clt16PPxzrXEtpa5d   184.0.48.20    53866   \n",
       "228249       53170  Cs8RA72uHDiQa5ch2k   184.0.48.20    54318   \n",
       "228250       53529  Cy4dqo4YEq5YGxjUXa   184.0.48.20    65355   \n",
       "228251       86308  CFXfNV3OTG04e0UnP4   184.0.48.20    53642   \n",
       "228252       99240  CqO7kc2eC5InNvWrtl   184.0.48.20    61000   \n",
       "\n",
       "                responh  responp           flow_duration  fwd_pkts_tot  \\\n",
       "0          184.0.48.150    50443  0 days 00:00:00.000060             1   \n",
       "1          184.0.48.150    50443  0 days 00:00:00.000083             1   \n",
       "2       255.255.255.255     5678  0 days 00:01:59.996602             3   \n",
       "3       255.255.255.255     5678  0 days 00:00:59.996909             2   \n",
       "4       255.255.255.255     5678  0 days 00:00:59.992130             2   \n",
       "...                 ...      ...                     ...           ...   \n",
       "228248     184.0.48.255     1947  0 days 00:00:00.000027             2   \n",
       "228249     184.0.48.255     1947  0 days 00:00:00.000027             2   \n",
       "228250     184.0.48.255     1947         0 days 00:00:00             2   \n",
       "228251     184.0.48.255     1947  0 days 00:00:00.000054             2   \n",
       "228252     184.0.48.255     1947         0 days 00:00:00             2   \n",
       "\n",
       "        bwd_pkts_tot  fwd_data_pkts_tot  ...      idle.max      idle.tot  \\\n",
       "0                  1                  0  ...  0.000000e+00  0.000000e+00   \n",
       "1                  1                  0  ...  0.000000e+00  0.000000e+00   \n",
       "2                  0                  3  ...  5.999912e+07  1.199966e+08   \n",
       "3                  0                  2  ...  5.999691e+07  5.999691e+07   \n",
       "4                  0                  2  ...  5.999213e+07  5.999213e+07   \n",
       "...              ...                ...  ...           ...           ...   \n",
       "228248             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228249             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228250             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228251             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228252             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "\n",
       "            idle.avg     idle.std  fwd_init_window_size  bwd_init_window_size  \\\n",
       "0       0.000000e+00     0.000000                 64240                     0   \n",
       "1       0.000000e+00     0.000000                 64240                     0   \n",
       "2       5.999830e+07  1156.846698                     0                     0   \n",
       "3       5.999691e+07     0.000000                     0                     0   \n",
       "4       5.999213e+07     0.000000                     0                     0   \n",
       "...              ...          ...                   ...                   ...   \n",
       "228248  0.000000e+00     0.000000                     0                     0   \n",
       "228249  0.000000e+00     0.000000                     0                     0   \n",
       "228250  0.000000e+00     0.000000                     0                     0   \n",
       "228251  0.000000e+00     0.000000                     0                     0   \n",
       "228252  0.000000e+00     0.000000                     0                     0   \n",
       "\n",
       "        fwd_last_window_size  bwd_last_window_size      attack_category  Label  \n",
       "0                      64240                     0               Benign      0  \n",
       "1                      64240                     0               Benign      0  \n",
       "2                          0                     0               Benign      0  \n",
       "3                          0                     0               Benign      0  \n",
       "4                          0                     0               Benign      0  \n",
       "...                      ...                   ...                  ...    ...  \n",
       "228248                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228249                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228250                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228251                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228252                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "\n",
       "[228253 rows x 88 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hikari_2022 = pd.read_csv('ALLFLOWMETER_HIKARI2022.csv', sep=',')\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956f3516-19f9-4d0e-8610-f3ebbc7a3fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originp</th>\n",
       "      <th>responp</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>idle.min</th>\n",
       "      <th>idle.max</th>\n",
       "      <th>idle.tot</th>\n",
       "      <th>idle.avg</th>\n",
       "      <th>idle.std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>bwd_last_window_size</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38164</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>33288.126984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43068</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>24105.195402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999748e+07</td>\n",
       "      <td>5.999912e+07</td>\n",
       "      <td>1.199966e+08</td>\n",
       "      <td>5.999830e+07</td>\n",
       "      <td>1156.846698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>53866</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>73584.280702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73584.280702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>54318</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74235.469027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74235.469027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>65355</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>53642</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37117.734513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37117.734513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>61000</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows √ó 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        originp  responp  fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  \\\n",
       "0         38164    50443             1             1                  0   \n",
       "1         43068    50443             1             1                  0   \n",
       "2          5678     5678             3             0                  3   \n",
       "3          5678     5678             2             0                  2   \n",
       "4          5678     5678             2             0                  2   \n",
       "...         ...      ...           ...           ...                ...   \n",
       "228248    53866     1947             2             0                  2   \n",
       "228249    54318     1947             2             0                  2   \n",
       "228250    65355     1947             2             0                  2   \n",
       "228251    53642     1947             2             0                  2   \n",
       "228252    61000     1947             2             0                  2   \n",
       "\n",
       "        bwd_data_pkts_tot  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
       "0                       0      16644.063492      16644.063492   \n",
       "1                       0      12052.597701      12052.597701   \n",
       "2                       0          0.025001          0.000000   \n",
       "3                       0          0.033335          0.000000   \n",
       "4                       0          0.033338          0.000000   \n",
       "...                   ...               ...               ...   \n",
       "228248                  0      73584.280702          0.000000   \n",
       "228249                  0      74235.469027          0.000000   \n",
       "228250                  0          0.000000          0.000000   \n",
       "228251                  0      37117.734513          0.000000   \n",
       "228252                  0          0.000000          0.000000   \n",
       "\n",
       "        flow_pkts_per_sec  down_up_ratio  ...      idle.min      idle.max  \\\n",
       "0            33288.126984            1.0  ...  0.000000e+00  0.000000e+00   \n",
       "1            24105.195402            1.0  ...  0.000000e+00  0.000000e+00   \n",
       "2                0.025001            0.0  ...  5.999748e+07  5.999912e+07   \n",
       "3                0.033335            0.0  ...  5.999691e+07  5.999691e+07   \n",
       "4                0.033338            0.0  ...  5.999213e+07  5.999213e+07   \n",
       "...                   ...            ...  ...           ...           ...   \n",
       "228248       73584.280702            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228249       74235.469027            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228250           0.000000            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228251       37117.734513            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228252           0.000000            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "\n",
       "            idle.tot      idle.avg     idle.std  fwd_init_window_size  \\\n",
       "0       0.000000e+00  0.000000e+00     0.000000                 64240   \n",
       "1       0.000000e+00  0.000000e+00     0.000000                 64240   \n",
       "2       1.199966e+08  5.999830e+07  1156.846698                     0   \n",
       "3       5.999691e+07  5.999691e+07     0.000000                     0   \n",
       "4       5.999213e+07  5.999213e+07     0.000000                     0   \n",
       "...              ...           ...          ...                   ...   \n",
       "228248  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228249  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228250  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228251  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228252  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "\n",
       "        bwd_init_window_size  fwd_last_window_size  bwd_last_window_size  \\\n",
       "0                          0                 64240                     0   \n",
       "1                          0                 64240                     0   \n",
       "2                          0                     0                     0   \n",
       "3                          0                     0                     0   \n",
       "4                          0                     0                     0   \n",
       "...                      ...                   ...                   ...   \n",
       "228248                     0                     0                     0   \n",
       "228249                     0                     0                     0   \n",
       "228250                     0                     0                     0   \n",
       "228251                     0                     0                     0   \n",
       "228252                     0                     0                     0   \n",
       "\n",
       "        Label  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "228248      1  \n",
       "228249      1  \n",
       "228250      1  \n",
       "228251      1  \n",
       "228252      1  \n",
       "\n",
       "[228253 rows x 80 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hikari_2022 = hikari_2022.drop(columns=['Unnamed: 0', 'uid', 'originh', 'responh', 'flow_duration', 'fwd_URG_flag_count', \n",
    "                                        'bwd_URG_flag_count', 'attack_category'])\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1982d3e1-56ee-4d9c-9a35-30da7a4dface",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after EDA:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originp</th>\n",
       "      <th>responp</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_tot</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>...</th>\n",
       "      <th>bwd_subflow_bytes</th>\n",
       "      <th>fwd_bulk_packets</th>\n",
       "      <th>bwd_bulk_packets</th>\n",
       "      <th>active.min</th>\n",
       "      <th>active.max</th>\n",
       "      <th>active.avg</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38164</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43068</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>53866</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>54318</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>65355</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>53642</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>61000</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows √ó 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        originp  responp  fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  \\\n",
       "0         38164    50443             1             1                  0   \n",
       "1         43068    50443             1             1                  0   \n",
       "2          5678     5678             3             0                  3   \n",
       "3          5678     5678             2             0                  2   \n",
       "4          5678     5678             2             0                  2   \n",
       "...         ...      ...           ...           ...                ...   \n",
       "228248    53866     1947             2             0                  2   \n",
       "228249    54318     1947             2             0                  2   \n",
       "228250    65355     1947             2             0                  2   \n",
       "228251    53642     1947             2             0                  2   \n",
       "228252    61000     1947             2             0                  2   \n",
       "\n",
       "        bwd_data_pkts_tot  bwd_pkts_per_sec  down_up_ratio  \\\n",
       "0                       0      16644.063492            1.0   \n",
       "1                       0      12052.597701            1.0   \n",
       "2                       0          0.000000            0.0   \n",
       "3                       0          0.000000            0.0   \n",
       "4                       0          0.000000            0.0   \n",
       "...                   ...               ...            ...   \n",
       "228248                  0          0.000000            0.0   \n",
       "228249                  0          0.000000            0.0   \n",
       "228250                  0          0.000000            0.0   \n",
       "228251                  0          0.000000            0.0   \n",
       "228252                  0          0.000000            0.0   \n",
       "\n",
       "        fwd_header_size_tot  fwd_header_size_min  ...  bwd_subflow_bytes  \\\n",
       "0                        40                   40  ...                0.0   \n",
       "1                        40                   40  ...                0.0   \n",
       "2                        24                    8  ...                0.0   \n",
       "3                        16                    8  ...                0.0   \n",
       "4                        16                    8  ...                0.0   \n",
       "...                     ...                  ...  ...                ...   \n",
       "228248                   16                    8  ...                0.0   \n",
       "228249                   16                    8  ...                0.0   \n",
       "228250                   16                    8  ...                0.0   \n",
       "228251                   16                    8  ...                0.0   \n",
       "228252                   16                    8  ...                0.0   \n",
       "\n",
       "        fwd_bulk_packets  bwd_bulk_packets  active.min  active.max  \\\n",
       "0                    0.0               0.0   60.081482   60.081482   \n",
       "1                    0.0               0.0   82.969666   82.969666   \n",
       "2                    0.0               0.0    0.000000    0.000000   \n",
       "3                    0.0               0.0    0.000000    0.000000   \n",
       "4                    0.0               0.0    0.000000    0.000000   \n",
       "...                  ...               ...         ...         ...   \n",
       "228248               0.0               0.0   27.179718   27.179718   \n",
       "228249               0.0               0.0   26.941299   26.941299   \n",
       "228250               0.0               0.0    0.000000    0.000000   \n",
       "228251               0.0               0.0   53.882599   53.882599   \n",
       "228252               0.0               0.0    0.000000    0.000000   \n",
       "\n",
       "        active.avg  fwd_init_window_size  bwd_init_window_size  \\\n",
       "0        60.081482                 64240                     0   \n",
       "1        82.969666                 64240                     0   \n",
       "2         0.000000                     0                     0   \n",
       "3         0.000000                     0                     0   \n",
       "4         0.000000                     0                     0   \n",
       "...            ...                   ...                   ...   \n",
       "228248   27.179718                     0                     0   \n",
       "228249   26.941299                     0                     0   \n",
       "228250    0.000000                     0                     0   \n",
       "228251   53.882599                     0                     0   \n",
       "228252    0.000000                     0                     0   \n",
       "\n",
       "        fwd_last_window_size  Label  \n",
       "0                      64240      0  \n",
       "1                      64240      0  \n",
       "2                          0      0  \n",
       "3                          0      0  \n",
       "4                          0      0  \n",
       "...                      ...    ...  \n",
       "228248                     0      1  \n",
       "228249                     0      1  \n",
       "228250                     0      1  \n",
       "228251                     0      1  \n",
       "228252                     0      1  \n",
       "\n",
       "[228253 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Pearson correlation coefficient\n",
    "corr = hikari_2022.corr(method ='pearson')\n",
    "\n",
    "# Extract the correlation with the target variable 'Label'\n",
    "corr_with_target = corr['Label']\n",
    "\n",
    "# Select only columns with a correlation less than 0.05\n",
    "relevant_features = corr_with_target[abs(corr_with_target) >= 0.05].index\n",
    "\n",
    "# Filter the DataFrame to keep only the relevant features\n",
    "hikari_2022 = hikari_2022[relevant_features]\n",
    "\n",
    "print(\"Dataset after EDA:\")\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078bc70f-198a-4179-8ff3-bffd38e7a6ee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dbbf30-c098-442b-92ad-ed1a9263d351",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Without feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac2ada9-2383-428d-ae11-0992d1cb9792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled,  (343860, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171930\n",
      "1    171930\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.9781384854658167\n",
      "Fold precision: 0.7286842822119314\n",
      "Fold recall: 0.999252895031752\n",
      "Fold F1-score: 0.8427851291745432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42974\n",
      "           1       0.73      1.00      0.84      2677\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.86      0.99      0.92     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343952, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171976\n",
      "1    171976\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.9782918227421086\n",
      "Fold precision: 0.7339276066990815\n",
      "Fold recall: 0.9977965479250827\n",
      "Fold F1-score: 0.8457587548638132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42928\n",
      "           1       0.73      1.00      0.85      2723\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.87      0.99      0.92     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343710, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171855\n",
      "1    171855\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.9791242250991216\n",
      "Fold precision: 0.7323189630881939\n",
      "Fold recall: 0.9988470407378939\n",
      "Fold F1-score: 0.8450658429523654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43049\n",
      "           1       0.73      1.00      0.85      2602\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.87      0.99      0.92     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343910, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171955\n",
      "1    171955\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.976210295728368\n",
      "Fold precision: 0.71334214002642\n",
      "Fold recall: 0.9996297667530544\n",
      "Fold F1-score: 0.8325624421831638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     42949\n",
      "           1       0.71      1.00      0.83      2701\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.86      0.99      0.91     45650\n",
      "weighted avg       0.98      0.98      0.98     45650\n",
      "\n",
      "X_train_resampled,  (343800, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171900\n",
      "1    171900\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.9785104052573932\n",
      "Fold precision: 0.7296551724137931\n",
      "Fold recall: 0.9996220710506425\n",
      "Fold F1-score: 0.8435656195184181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43004\n",
      "           1       0.73      1.00      0.84      2646\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.86      0.99      0.92     45650\n",
      "weighted avg       0.98      0.98      0.98     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9780550468585616\n",
      "Mean precision: 0.727585632887884\n",
      "Mean recall: 0.9990296642996851\n",
      "Mean F1-score: 0.8419475577384608\n",
      "\n",
      "El tiempo de ejecucion fue: 237.87291193008423\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Resample with SMOTE \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        print(\"X_train_resampled, \", X_train_resampled.shape)\n",
    "        print(\"y_train_resampled, \", y_train_resampled.value_counts())\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Train AdaBoost classifier\n",
    "        ab_classifier = AdaBoostClassifier(n_estimators=100, algorithm='SAMME', random_state=42)\n",
    "        ab_classifier.fit(X_train, y_train_resampled)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = ab_classifier.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")   \n",
    "\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e322040-5e11-4f73-bacc-00e3a7880e76",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### With DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f870be6e-6e65-4768-8b9a-5ef0dad8660e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled,  (343860, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171930\n",
      "1    171930\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 811us/step - accuracy: 0.9840 - loss: 0.0593 - val_accuracy: 0.9809 - val_loss: 0.0545\n",
      "Epoch 2/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 822us/step - accuracy: 0.9900 - loss: 0.0364 - val_accuracy: 0.9811 - val_loss: 0.0577\n",
      "Epoch 3/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 792us/step - accuracy: 0.9900 - loss: 0.0364 - val_accuracy: 0.9817 - val_loss: 0.0485\n",
      "Epoch 4/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 793us/step - accuracy: 0.9899 - loss: 0.0362 - val_accuracy: 0.9814 - val_loss: 0.0479\n",
      "Epoch 5/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 819us/step - accuracy: 0.9901 - loss: 0.0359 - val_accuracy: 0.9812 - val_loss: 0.0500\n",
      "Epoch 6/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 794us/step - accuracy: 0.9903 - loss: 0.0352 - val_accuracy: 0.9825 - val_loss: 0.0453\n",
      "Epoch 7/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 793us/step - accuracy: 0.9903 - loss: 0.0352 - val_accuracy: 0.9812 - val_loss: 0.0510\n",
      "Epoch 8/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 792us/step - accuracy: 0.9905 - loss: 0.0349 - val_accuracy: 0.9819 - val_loss: 0.0501\n",
      "Epoch 9/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 793us/step - accuracy: 0.9903 - loss: 0.0351 - val_accuracy: 0.9801 - val_loss: 0.0525\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 448us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450us/step\n",
      "Fold accuracy: 0.9824538345271736\n",
      "Fold precision: 0.7704728950403691\n",
      "Fold recall: 0.9981322375793799\n",
      "Fold F1-score: 0.8696501220504476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42974\n",
      "           1       0.77      1.00      0.87      2677\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.99      0.93     45651\n",
      "weighted avg       0.99      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343952, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171976\n",
      "1    171976\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 864us/step - accuracy: 0.9850 - loss: 0.0567 - val_accuracy: 0.9812 - val_loss: 0.0495\n",
      "Epoch 2/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 789us/step - accuracy: 0.9897 - loss: 0.0374 - val_accuracy: 0.9820 - val_loss: 0.0482\n",
      "Epoch 3/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 784us/step - accuracy: 0.9904 - loss: 0.0351 - val_accuracy: 0.9823 - val_loss: 0.0435\n",
      "Epoch 4/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 785us/step - accuracy: 0.9903 - loss: 0.0356 - val_accuracy: 0.9814 - val_loss: 0.0587\n",
      "Epoch 5/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 796us/step - accuracy: 0.9902 - loss: 0.0353 - val_accuracy: 0.9815 - val_loss: 0.0521\n",
      "Epoch 6/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 779us/step - accuracy: 0.9900 - loss: 0.0360 - val_accuracy: 0.9818 - val_loss: 0.0530\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 449us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447us/step\n",
      "Fold accuracy: 0.982190970624959\n",
      "Fold precision: 0.771152754116979\n",
      "Fold recall: 0.9974293059125964\n",
      "Fold F1-score: 0.8698158526821457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42928\n",
      "           1       0.77      1.00      0.87      2723\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.99      0.93     45651\n",
      "weighted avg       0.99      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343710, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171855\n",
      "1    171855\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 811us/step - accuracy: 0.9851 - loss: 0.0577 - val_accuracy: 0.9804 - val_loss: 0.0585\n",
      "Epoch 2/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 791us/step - accuracy: 0.9897 - loss: 0.0374 - val_accuracy: 0.9797 - val_loss: 0.0542\n",
      "Epoch 3/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 785us/step - accuracy: 0.9897 - loss: 0.0371 - val_accuracy: 0.9818 - val_loss: 0.0544\n",
      "Epoch 4/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 795us/step - accuracy: 0.9903 - loss: 0.0358 - val_accuracy: 0.9826 - val_loss: 0.0492\n",
      "Epoch 5/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 796us/step - accuracy: 0.9902 - loss: 0.0358 - val_accuracy: 0.9826 - val_loss: 0.0464\n",
      "Epoch 6/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 785us/step - accuracy: 0.9903 - loss: 0.0351 - val_accuracy: 0.9828 - val_loss: 0.0469\n",
      "Epoch 7/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 783us/step - accuracy: 0.9904 - loss: 0.0353 - val_accuracy: 0.9828 - val_loss: 0.0471\n",
      "Epoch 8/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 782us/step - accuracy: 0.9902 - loss: 0.0359 - val_accuracy: 0.9825 - val_loss: 0.0497\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 455us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453us/step\n",
      "Fold accuracy: 0.9826509824538345\n",
      "Fold precision: 0.7672770230360307\n",
      "Fold recall: 0.9984627209838586\n",
      "Fold F1-score: 0.8677354709418837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43049\n",
      "           1       0.77      1.00      0.87      2602\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.88      0.99      0.93     45651\n",
      "weighted avg       0.99      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343910, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171955\n",
      "1    171955\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 812us/step - accuracy: 0.9851 - loss: 0.0575 - val_accuracy: 0.9798 - val_loss: 0.0579\n",
      "Epoch 2/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 779us/step - accuracy: 0.9898 - loss: 0.0367 - val_accuracy: 0.9811 - val_loss: 0.0573\n",
      "Epoch 3/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 776us/step - accuracy: 0.9900 - loss: 0.0362 - val_accuracy: 0.9813 - val_loss: 0.0510\n",
      "Epoch 4/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 783us/step - accuracy: 0.9900 - loss: 0.0362 - val_accuracy: 0.9815 - val_loss: 0.0528\n",
      "Epoch 5/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 778us/step - accuracy: 0.9903 - loss: 0.0352 - val_accuracy: 0.9814 - val_loss: 0.0502\n",
      "Epoch 6/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 790us/step - accuracy: 0.9903 - loss: 0.0355 - val_accuracy: 0.9806 - val_loss: 0.0536\n",
      "Epoch 7/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 780us/step - accuracy: 0.9903 - loss: 0.0356 - val_accuracy: 0.9816 - val_loss: 0.0513\n",
      "Epoch 8/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 784us/step - accuracy: 0.9908 - loss: 0.0338 - val_accuracy: 0.9804 - val_loss: 0.0543\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 455us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456us/step\n",
      "Fold accuracy: 0.9819934282584885\n",
      "Fold precision: 0.7666761282997445\n",
      "Fold recall: 1.0\n",
      "Fold F1-score: 0.8679305912596401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42949\n",
      "           1       0.77      1.00      0.87      2701\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.88      0.99      0.93     45650\n",
      "weighted avg       0.99      0.98      0.98     45650\n",
      "\n",
      "X_train_resampled,  (343800, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171900\n",
      "1    171900\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 797us/step - accuracy: 0.9859 - loss: 0.0567 - val_accuracy: 0.9819 - val_loss: 0.0481\n",
      "Epoch 2/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 789us/step - accuracy: 0.9895 - loss: 0.0378 - val_accuracy: 0.9802 - val_loss: 0.0543\n",
      "Epoch 3/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 786us/step - accuracy: 0.9895 - loss: 0.0378 - val_accuracy: 0.9817 - val_loss: 0.0493\n",
      "Epoch 4/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 804us/step - accuracy: 0.9898 - loss: 0.0369 - val_accuracy: 0.9818 - val_loss: 0.0497\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 454us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452us/step\n",
      "Fold accuracy: 0.982935377875137\n",
      "Fold precision: 0.7725547445255474\n",
      "Fold recall: 1.0\n",
      "Fold F1-score: 0.871685060121891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43004\n",
      "           1       0.77      1.00      0.87      2646\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.89      0.99      0.93     45650\n",
      "weighted avg       0.99      0.98      0.98     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9824449187479185\n",
      "Mean precision: 0.7696267090037342\n",
      "Mean recall: 0.998804852895167\n",
      "Mean F1-score: 0.8693634194112017\n",
      "\n",
      "El tiempo de ejecucion fue: 653.159187078476\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the DNN model\n",
    "def create_dnn(input_dim):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    \n",
    "    # Hidden layer 1\n",
    "    x = Dense(input_dim * 2)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Hidden layer 2\n",
    "    x = Dense(input_dim)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Feature layer\n",
    "    n_bottleneck = round(float(input_dim) / 2.0)\n",
    "    bottleneck = Dense(n_bottleneck)(x)\n",
    "    bottleneck = BatchNormalization()(bottleneck)\n",
    "    bottleneck = ReLU()(bottleneck)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation='sigmoid')(bottleneck)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Model for feature extraction\n",
    "    feature_extractor = Model(inputs=inputs, outputs=bottleneck)\n",
    "    \n",
    "    return model, feature_extractor\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_dnn(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Resample with SMOTE \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        print(\"X_train_resampled, \", X_train_resampled.shape)\n",
    "        print(\"y_train_resampled, \", y_train_resampled.value_counts())\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        dnn, feature_extractor = create_dnn(n_inputs)\n",
    "        \n",
    "        # Early Stopping\n",
    "        early_stopping1 = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "        early_stopping2 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # Fit the DNN model\n",
    "        dnn.fit(X_train, y_train_resampled, epochs=100, batch_size=32, verbose=1,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        callbacks=[early_stopping1, early_stopping2])\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = feature_extractor.predict(X_train)\n",
    "        X_test_encoded = feature_extractor.predict(X_test)\n",
    "        \n",
    "        # Train AdaBoost classifier\n",
    "        ab_classifier_encoded = AdaBoostClassifier(n_estimators=100, algorithm='SAMME', random_state=42)\n",
    "        ab_classifier_encoded.fit(X_train_encoded, y_train_resampled)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = ab_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_dnn(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9176c09-ba87-45f0-9113-30f7de69c72d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### With DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f60b25-c365-4e28-9022-59c22addcd30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_dbn(layers, file_name='dbn_structure.png'):\n",
    "    # Crear un grafo dirigido\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # A√±adir nodos para cada capa RBM\n",
    "    for i, n_units in enumerate(layers):\n",
    "        G.add_node(f\"RBM {i+1}\\n{n_units} unidades\", layer=i+1)\n",
    "\n",
    "    # A√±adir aristas entre nodos (de una capa a otra)\n",
    "    for i in range(len(layers) - 1):\n",
    "        G.add_edge(f\"RBM {i+1}\\n{layers[i]} unidades\", f\"RBM {i+2}\\n{layers[i+1]} unidades\")\n",
    "\n",
    "    # Dibujar el grafo\n",
    "    pos = nx.spring_layout(G)  # Posici√≥n de los nodos\n",
    "    nx.draw(G, pos, with_labels=True, node_size=3000, node_color='lightblue', font_size=10, font_weight='bold')\n",
    "    \n",
    "    # Guardar la imagen a un archivo\n",
    "    plt.title(\"Arquitectura de la DBN\")\n",
    "    plt.savefig(file_name)\n",
    "    plt.show()\n",
    "    \n",
    "#visualize_dbn([X.shape[1]*2, X.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d237480-eb1b-4961-9f4d-0846b4517f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled,  (343860, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171930\n",
      "1    171930\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.41, time = 4.79s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.35, time = 6.18s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.05, time = 6.23s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.87, time = 6.13s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.02, time = 6.36s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.85, time = 6.21s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.98, time = 6.08s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.88, time = 6.16s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.09, time = 6.04s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.90, time = 6.18s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -4.27, time = 4.69s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -4.23, time = 5.56s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.61, time = 5.60s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.20, time = 5.53s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.19, time = 5.57s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.11, time = 5.67s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.37, time = 5.56s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.30, time = 5.53s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -7.33, time = 5.56s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.33, time = 5.48s\n",
      "Fold accuracy: 0.932422071805656\n",
      "Fold precision: 0.4423076923076923\n",
      "Fold recall: 0.5842360851699664\n",
      "Fold F1-score: 0.5034604860775793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     42974\n",
      "           1       0.44      0.58      0.50      2677\n",
      "\n",
      "    accuracy                           0.93     45651\n",
      "   macro avg       0.71      0.77      0.73     45651\n",
      "weighted avg       0.94      0.93      0.94     45651\n",
      "\n",
      "X_train_resampled,  (343952, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171976\n",
      "1    171976\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.51, time = 4.81s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.27, time = 6.17s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.30, time = 6.30s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.11, time = 6.14s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.17, time = 6.18s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.95, time = 6.08s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5.10, time = 6.19s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5.13, time = 6.22s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.95, time = 6.21s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.02, time = 6.14s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -3.86, time = 4.73s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -3.39, time = 5.52s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -3.47, time = 5.61s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -3.48, time = 5.60s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -3.81, time = 5.50s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -3.33, time = 5.56s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -3.41, time = 5.53s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -3.33, time = 5.55s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.28, time = 5.66s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.27, time = 5.59s\n",
      "Fold accuracy: 0.9479091367111345\n",
      "Fold precision: 0.5611485288904644\n",
      "Fold recall: 0.5813441057656996\n",
      "Fold F1-score: 0.5710678210678211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     42928\n",
      "           1       0.56      0.58      0.57      2723\n",
      "\n",
      "    accuracy                           0.95     45651\n",
      "   macro avg       0.77      0.78      0.77     45651\n",
      "weighted avg       0.95      0.95      0.95     45651\n",
      "\n",
      "X_train_resampled,  (343710, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171855\n",
      "1    171855\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.48, time = 4.90s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.55, time = 6.19s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.43, time = 6.20s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.35, time = 6.16s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.43, time = 6.20s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.22, time = 6.16s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5.30, time = 6.12s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5.32, time = 6.10s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.20, time = 6.14s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.15, time = 6.04s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -0.58, time = 4.66s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1.93, time = 5.65s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -1.22, time = 5.52s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -0.54, time = 5.68s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -0.59, time = 5.54s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1.45, time = 5.56s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -1.74, time = 5.56s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -0.60, time = 5.52s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -0.67, time = 5.58s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -0.76, time = 5.60s\n",
      "Fold accuracy: 0.9473395982563361\n",
      "Fold precision: 0.5239709443099274\n",
      "Fold recall: 0.8316679477325134\n",
      "Fold F1-score: 0.6428995840760546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     43049\n",
      "           1       0.52      0.83      0.64      2602\n",
      "\n",
      "    accuracy                           0.95     45651\n",
      "   macro avg       0.76      0.89      0.81     45651\n",
      "weighted avg       0.96      0.95      0.95     45651\n",
      "\n",
      "X_train_resampled,  (343910, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171955\n",
      "1    171955\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.36, time = 4.82s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.36, time = 6.17s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.21, time = 6.22s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.04, time = 6.07s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.86, time = 6.17s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.06, time = 6.12s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.97, time = 6.10s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5.08, time = 6.19s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.98, time = 6.07s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.10, time = 6.20s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -3.93, time = 4.68s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -3.92, time = 5.56s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -3.89, time = 5.64s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -7.77, time = 5.55s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.02, time = 5.57s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -7.24, time = 5.58s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.06, time = 5.50s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -3.87, time = 5.54s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -6.09, time = 5.53s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.96, time = 5.53s\n",
      "Fold accuracy: 0.9455859802847755\n",
      "Fold precision: 0.5251215559157212\n",
      "Fold recall: 0.8396890040725657\n",
      "Fold F1-score: 0.6461538461538462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     42949\n",
      "           1       0.53      0.84      0.65      2701\n",
      "\n",
      "    accuracy                           0.95     45650\n",
      "   macro avg       0.76      0.90      0.81     45650\n",
      "weighted avg       0.96      0.95      0.95     45650\n",
      "\n",
      "X_train_resampled,  (343800, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171900\n",
      "1    171900\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.52, time = 4.92s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.34, time = 6.10s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.98, time = 6.24s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.11, time = 6.17s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.08, time = 6.10s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.93, time = 6.11s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.82, time = 6.09s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5.00, time = 6.07s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.97, time = 6.21s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.73, time = 6.10s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -4.48, time = 4.76s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.99, time = 5.55s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -6.24, time = 5.56s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.53, time = 5.63s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.49, time = 5.52s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.32, time = 5.63s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -6.07, time = 5.57s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.05, time = 5.52s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.17, time = 5.55s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.40, time = 5.57s\n",
      "Fold accuracy: 0.931631982475356\n",
      "Fold precision: 0.43141784579844067\n",
      "Fold recall: 0.564625850340136\n",
      "Fold F1-score: 0.4891144213455557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     43004\n",
      "           1       0.43      0.56      0.49      2646\n",
      "\n",
      "    accuracy                           0.93     45650\n",
      "   macro avg       0.70      0.76      0.73     45650\n",
      "weighted avg       0.94      0.93      0.94     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9409777539066516\n",
      "Mean precision: 0.49679331344444916\n",
      "Mean recall: 0.6803125986161762\n",
      "Mean F1-score: 0.5705392317441713\n",
      "\n",
      "El tiempo de ejecucion fue: 1206.9759562015533\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the DBN class\n",
    "class DBN(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rbm_layers, rbm_learning_rate, rbm_n_iter):\n",
    "        self.rbm_layers = rbm_layers\n",
    "        self.rbm_learning_rate = rbm_learning_rate\n",
    "        self.rbm_n_iter = rbm_n_iter\n",
    "        self.rbms = []\n",
    "        for i, n_components in enumerate(rbm_layers):\n",
    "            self.rbms.append(BernoulliRBM(n_components=n_components, learning_rate=rbm_learning_rate, n_iter=rbm_n_iter, verbose=1))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        input_data = X\n",
    "        for rbm in self.rbms:\n",
    "            rbm.fit(input_data)\n",
    "            input_data = rbm.transform(input_data)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        input_data = X\n",
    "        for rbm in self.rbms:\n",
    "            input_data = rbm.transform(input_data)\n",
    "        return input_data\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_dbn(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Resample with SMOTE \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        print(\"X_train_resampled, \", X_train_resampled.shape)\n",
    "        print(\"y_train_resampled, \", y_train_resampled.value_counts())\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        dbn = DBN(rbm_layers=[n_inputs*2, n_inputs], rbm_learning_rate=0.1, rbm_n_iter=10)\n",
    "        \n",
    "        # Fit the DBN model\n",
    "        dbn.fit(X_train)\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = dbn.transform(X_train)\n",
    "        X_test_encoded = dbn.transform(X_test)\n",
    "        \n",
    "        # Train AdaBoost classifier\n",
    "        ab_classifier_encoded = AdaBoostClassifier(n_estimators=100, algorithm='SAMME', random_state=42)\n",
    "        ab_classifier_encoded.fit(X_train_encoded, y_train_resampled)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = ab_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "    \n",
    "    \n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_dbn(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8124559-b551-4af6-8503-0901cfc82b15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### With Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c58e6d3-7e3c-4147-8ef4-a057322d7f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled,  (343860, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171930\n",
      "1    171930\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 701us/step - loss: 0.1529 - val_loss: 0.0615\n",
      "Epoch 2/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 690us/step - loss: 0.0798 - val_loss: 0.1096\n",
      "Epoch 3/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 693us/step - loss: 0.0729 - val_loss: 0.0500\n",
      "Epoch 4/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 691us/step - loss: 0.0643 - val_loss: 0.0487\n",
      "Epoch 5/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 695us/step - loss: 0.0829 - val_loss: 0.0402\n",
      "Epoch 6/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 693us/step - loss: 0.0494 - val_loss: 0.0533\n",
      "Epoch 7/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 697us/step - loss: 0.0373 - val_loss: 0.0404\n",
      "Epoch 8/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 694us/step - loss: 0.0410 - val_loss: 0.0305\n",
      "Epoch 9/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 697us/step - loss: 0.0451 - val_loss: 0.0289\n",
      "Epoch 10/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 697us/step - loss: 0.0350 - val_loss: 0.0388\n",
      "Epoch 11/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 694us/step - loss: 0.0351 - val_loss: 0.0313\n",
      "Epoch 12/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 697us/step - loss: 0.0443 - val_loss: 0.0282\n",
      "Epoch 13/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 693us/step - loss: 0.0357 - val_loss: 0.0449\n",
      "Epoch 14/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 696us/step - loss: 0.0373 - val_loss: 0.0619\n",
      "Epoch 15/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 696us/step - loss: 0.0498 - val_loss: 0.0294\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 417us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410us/step\n",
      "Fold accuracy: 0.9752250772162713\n",
      "Fold precision: 0.7033140452393477\n",
      "Fold recall: 0.9988793425476279\n",
      "Fold F1-score: 0.8254360240777898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     42974\n",
      "           1       0.70      1.00      0.83      2677\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.85      0.99      0.91     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343952, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171976\n",
      "1    171976\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 690us/step - loss: 0.1953 - val_loss: 0.0976\n",
      "Epoch 2/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 683us/step - loss: 0.0739 - val_loss: 0.0704\n",
      "Epoch 3/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 683us/step - loss: 0.0738 - val_loss: 0.1121\n",
      "Epoch 4/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 685us/step - loss: 0.0796 - val_loss: 0.0894\n",
      "Epoch 5/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 684us/step - loss: 0.1075 - val_loss: 0.1272\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 413us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406us/step\n",
      "Fold accuracy: 0.9750060239644257\n",
      "Fold precision: 0.7078297425118234\n",
      "Fold recall: 0.9893499816378993\n",
      "Fold F1-score: 0.8252412314290091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     42928\n",
      "           1       0.71      0.99      0.83      2723\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.85      0.98      0.91     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343710, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171855\n",
      "1    171855\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 694us/step - loss: 0.1494 - val_loss: 0.5579\n",
      "Epoch 2/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 684us/step - loss: 0.0721 - val_loss: 0.6220\n",
      "Epoch 3/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 688us/step - loss: 0.0464 - val_loss: 2.7139\n",
      "Epoch 4/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 680us/step - loss: 0.0406 - val_loss: 0.6118\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 417us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410us/step\n",
      "Fold accuracy: 0.9761889115243916\n",
      "Fold precision: 0.7061224489795919\n",
      "Fold recall: 0.9973097617217525\n",
      "Fold F1-score: 0.8268281025967819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     43049\n",
      "           1       0.71      1.00      0.83      2602\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.85      0.99      0.91     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343910, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171955\n",
      "1    171955\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 690us/step - loss: 0.1721 - val_loss: 0.1421\n",
      "Epoch 2/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 680us/step - loss: 0.1018 - val_loss: 0.0599\n",
      "Epoch 3/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 681us/step - loss: 0.0923 - val_loss: 0.0318\n",
      "Epoch 4/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 680us/step - loss: 0.1136 - val_loss: 0.1161\n",
      "Epoch 5/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 684us/step - loss: 0.0849 - val_loss: 0.0693\n",
      "Epoch 6/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 678us/step - loss: 0.0501 - val_loss: 0.0415\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 414us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409us/step\n",
      "Fold accuracy: 0.9754435925520263\n",
      "Fold precision: 0.7068062827225131\n",
      "Fold recall: 0.9996297667530544\n",
      "Fold F1-score: 0.8280938506364055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     42949\n",
      "           1       0.71      1.00      0.83      2701\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.85      0.99      0.91     45650\n",
      "weighted avg       0.98      0.98      0.98     45650\n",
      "\n",
      "X_train_resampled,  (343800, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171900\n",
      "1    171900\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 697us/step - loss: 0.1349 - val_loss: 2.7996\n",
      "Epoch 2/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 694us/step - loss: 0.1059 - val_loss: 0.0572\n",
      "Epoch 3/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 688us/step - loss: 0.0912 - val_loss: 0.0856\n",
      "Epoch 4/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 691us/step - loss: 0.0639 - val_loss: 0.1377\n",
      "Epoch 5/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 692us/step - loss: 0.0840 - val_loss: 0.0329\n",
      "Epoch 6/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 693us/step - loss: 0.0381 - val_loss: 0.1244\n",
      "Epoch 7/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 690us/step - loss: 0.0594 - val_loss: 0.0478\n",
      "Epoch 8/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 691us/step - loss: 0.0470 - val_loss: 0.0307\n",
      "Epoch 9/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 688us/step - loss: 0.0404 - val_loss: 0.2468\n",
      "Epoch 10/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 692us/step - loss: 0.0502 - val_loss: 0.0712\n",
      "Epoch 11/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 692us/step - loss: 0.0465 - val_loss: 0.0440\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 412us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411us/step\n",
      "Fold accuracy: 0.9799123767798467\n",
      "Fold precision: 0.7427688851446222\n",
      "Fold recall: 0.9996220710506425\n",
      "Fold F1-score: 0.852263573384888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43004\n",
      "           1       0.74      1.00      0.85      2646\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.87      0.99      0.92     45650\n",
      "weighted avg       0.99      0.98      0.98     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9763551964073924\n",
      "Mean precision: 0.7133682809195797\n",
      "Mean recall: 0.9969581847421953\n",
      "Mean F1-score: 0.8315725564249747\n",
      "\n",
      "El tiempo de ejecucion fue: 815.5149545669556\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the autoencoder model\n",
    "def create_autoencoder(n_inputs):\n",
    "    inputs = Input(shape=(n_inputs,))\n",
    "    \n",
    "    # Define Encoder\n",
    "    e = Dense(n_inputs*2)(inputs)\n",
    "    e = BatchNormalization()(e)\n",
    "    e = LeakyReLU()(e)\n",
    "    \n",
    "    # Bottleneck\n",
    "    n_bottleneck = round(float(n_inputs)/2.0)\n",
    "    bottleneck = Dense(n_bottleneck)(e)\n",
    "    \n",
    "    # Define Decoder\n",
    "    d = Dense(n_inputs*2)(bottleneck)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU()(d)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(n_inputs, activation='linear')(d)\n",
    "    \n",
    "    # Define autoencoder model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Define encoder model\n",
    "    encoder = Model(inputs=inputs, outputs=bottleneck)\n",
    "    \n",
    "    return model, encoder\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_autoencoder(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Resample with SMOTE \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        print(\"X_train_resampled, \", X_train_resampled.shape)\n",
    "        print(\"y_train_resampled, \", y_train_resampled.value_counts())\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        autoencoder, encoder = create_autoencoder(n_inputs)\n",
    "        \n",
    "        # Early Stopping\n",
    "        early_stopping1 = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "        early_stopping2 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # Fit the DNN model\n",
    "        autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, verbose=1,\n",
    "                        validation_data=(X_test, X_test),\n",
    "                        callbacks=[early_stopping1, early_stopping2])\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = encoder.predict(X_train)\n",
    "        X_test_encoded = encoder.predict(X_test)\n",
    "        \n",
    "        # Train AdaBoost classifier\n",
    "        ab_classifier_encoded = AdaBoostClassifier(n_estimators=100, algorithm='SAMME', random_state=42)\n",
    "        ab_classifier_encoded.fit(X_train_encoded, y_train_resampled)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = ab_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_autoencoder(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4daef-afdd-4dfe-a145-05ab6c4368c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
