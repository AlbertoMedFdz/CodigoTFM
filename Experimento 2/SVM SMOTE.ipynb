{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf026ff-8cbf-414b-a47b-9ca1cb0b2652",
   "metadata": {
    "tags": []
   },
   "source": [
    "_Alberto Medrano Fernández_\n",
    "\n",
    "# SVM (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe473f3-1603-43b8-8c4a-fe001e945785",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a37898-36cc-40b9-a502-97fc4f538cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from time import time\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder \n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeacebd-c31e-45bb-8d1c-037352c4acc7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd39d501-dc75-4f2e-a36c-1e26ad59c861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uid</th>\n",
       "      <th>originh</th>\n",
       "      <th>originp</th>\n",
       "      <th>responh</th>\n",
       "      <th>responp</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>idle.max</th>\n",
       "      <th>idle.tot</th>\n",
       "      <th>idle.avg</th>\n",
       "      <th>idle.std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>bwd_last_window_size</th>\n",
       "      <th>attack_category</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cmu9v81jToQyRF1gbk</td>\n",
       "      <td>184.0.48.168</td>\n",
       "      <td>38164</td>\n",
       "      <td>184.0.48.150</td>\n",
       "      <td>50443</td>\n",
       "      <td>0 days 00:00:00.000060</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CO21hl3TWkuXTOgajk</td>\n",
       "      <td>184.0.48.169</td>\n",
       "      <td>43068</td>\n",
       "      <td>184.0.48.150</td>\n",
       "      <td>50443</td>\n",
       "      <td>0 days 00:00:00.000083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBLJ6L19FP0MfYX7Oh</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:01:59.996602</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999912e+07</td>\n",
       "      <td>1.199966e+08</td>\n",
       "      <td>5.999830e+07</td>\n",
       "      <td>1156.846698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ChTG451zJ7hUYOcqje</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:00:59.996909</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cn9y6E2KVxzQbs5wjc</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:00:59.992130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>16634</td>\n",
       "      <td>Clt16PPxzrXEtpa5d</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>53866</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000027</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>53170</td>\n",
       "      <td>Cs8RA72uHDiQa5ch2k</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>54318</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000027</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>53529</td>\n",
       "      <td>Cy4dqo4YEq5YGxjUXa</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>65355</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>86308</td>\n",
       "      <td>CFXfNV3OTG04e0UnP4</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>53642</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000054</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>99240</td>\n",
       "      <td>CqO7kc2eC5InNvWrtl</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>61000</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                 uid       originh  originp  \\\n",
       "0                0  Cmu9v81jToQyRF1gbk  184.0.48.168    38164   \n",
       "1                1  CO21hl3TWkuXTOgajk  184.0.48.169    43068   \n",
       "2                2  CBLJ6L19FP0MfYX7Oh  184.0.48.124     5678   \n",
       "3                3  ChTG451zJ7hUYOcqje  184.0.48.124     5678   \n",
       "4                4  Cn9y6E2KVxzQbs5wjc  184.0.48.124     5678   \n",
       "...            ...                 ...           ...      ...   \n",
       "228248       16634   Clt16PPxzrXEtpa5d   184.0.48.20    53866   \n",
       "228249       53170  Cs8RA72uHDiQa5ch2k   184.0.48.20    54318   \n",
       "228250       53529  Cy4dqo4YEq5YGxjUXa   184.0.48.20    65355   \n",
       "228251       86308  CFXfNV3OTG04e0UnP4   184.0.48.20    53642   \n",
       "228252       99240  CqO7kc2eC5InNvWrtl   184.0.48.20    61000   \n",
       "\n",
       "                responh  responp           flow_duration  fwd_pkts_tot  \\\n",
       "0          184.0.48.150    50443  0 days 00:00:00.000060             1   \n",
       "1          184.0.48.150    50443  0 days 00:00:00.000083             1   \n",
       "2       255.255.255.255     5678  0 days 00:01:59.996602             3   \n",
       "3       255.255.255.255     5678  0 days 00:00:59.996909             2   \n",
       "4       255.255.255.255     5678  0 days 00:00:59.992130             2   \n",
       "...                 ...      ...                     ...           ...   \n",
       "228248     184.0.48.255     1947  0 days 00:00:00.000027             2   \n",
       "228249     184.0.48.255     1947  0 days 00:00:00.000027             2   \n",
       "228250     184.0.48.255     1947         0 days 00:00:00             2   \n",
       "228251     184.0.48.255     1947  0 days 00:00:00.000054             2   \n",
       "228252     184.0.48.255     1947         0 days 00:00:00             2   \n",
       "\n",
       "        bwd_pkts_tot  fwd_data_pkts_tot  ...      idle.max      idle.tot  \\\n",
       "0                  1                  0  ...  0.000000e+00  0.000000e+00   \n",
       "1                  1                  0  ...  0.000000e+00  0.000000e+00   \n",
       "2                  0                  3  ...  5.999912e+07  1.199966e+08   \n",
       "3                  0                  2  ...  5.999691e+07  5.999691e+07   \n",
       "4                  0                  2  ...  5.999213e+07  5.999213e+07   \n",
       "...              ...                ...  ...           ...           ...   \n",
       "228248             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228249             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228250             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228251             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228252             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "\n",
       "            idle.avg     idle.std  fwd_init_window_size  bwd_init_window_size  \\\n",
       "0       0.000000e+00     0.000000                 64240                     0   \n",
       "1       0.000000e+00     0.000000                 64240                     0   \n",
       "2       5.999830e+07  1156.846698                     0                     0   \n",
       "3       5.999691e+07     0.000000                     0                     0   \n",
       "4       5.999213e+07     0.000000                     0                     0   \n",
       "...              ...          ...                   ...                   ...   \n",
       "228248  0.000000e+00     0.000000                     0                     0   \n",
       "228249  0.000000e+00     0.000000                     0                     0   \n",
       "228250  0.000000e+00     0.000000                     0                     0   \n",
       "228251  0.000000e+00     0.000000                     0                     0   \n",
       "228252  0.000000e+00     0.000000                     0                     0   \n",
       "\n",
       "        fwd_last_window_size  bwd_last_window_size      attack_category  Label  \n",
       "0                      64240                     0               Benign      0  \n",
       "1                      64240                     0               Benign      0  \n",
       "2                          0                     0               Benign      0  \n",
       "3                          0                     0               Benign      0  \n",
       "4                          0                     0               Benign      0  \n",
       "...                      ...                   ...                  ...    ...  \n",
       "228248                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228249                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228250                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228251                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228252                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "\n",
       "[228253 rows x 88 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hikari_2022 = pd.read_csv('ALLFLOWMETER_HIKARI2022.csv', sep=',')\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956f3516-19f9-4d0e-8610-f3ebbc7a3fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originp</th>\n",
       "      <th>responp</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>idle.min</th>\n",
       "      <th>idle.max</th>\n",
       "      <th>idle.tot</th>\n",
       "      <th>idle.avg</th>\n",
       "      <th>idle.std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>bwd_last_window_size</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38164</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>33288.126984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43068</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>24105.195402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999748e+07</td>\n",
       "      <td>5.999912e+07</td>\n",
       "      <td>1.199966e+08</td>\n",
       "      <td>5.999830e+07</td>\n",
       "      <td>1156.846698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>53866</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>73584.280702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73584.280702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>54318</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74235.469027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74235.469027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>65355</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>53642</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37117.734513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37117.734513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>61000</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        originp  responp  fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  \\\n",
       "0         38164    50443             1             1                  0   \n",
       "1         43068    50443             1             1                  0   \n",
       "2          5678     5678             3             0                  3   \n",
       "3          5678     5678             2             0                  2   \n",
       "4          5678     5678             2             0                  2   \n",
       "...         ...      ...           ...           ...                ...   \n",
       "228248    53866     1947             2             0                  2   \n",
       "228249    54318     1947             2             0                  2   \n",
       "228250    65355     1947             2             0                  2   \n",
       "228251    53642     1947             2             0                  2   \n",
       "228252    61000     1947             2             0                  2   \n",
       "\n",
       "        bwd_data_pkts_tot  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
       "0                       0      16644.063492      16644.063492   \n",
       "1                       0      12052.597701      12052.597701   \n",
       "2                       0          0.025001          0.000000   \n",
       "3                       0          0.033335          0.000000   \n",
       "4                       0          0.033338          0.000000   \n",
       "...                   ...               ...               ...   \n",
       "228248                  0      73584.280702          0.000000   \n",
       "228249                  0      74235.469027          0.000000   \n",
       "228250                  0          0.000000          0.000000   \n",
       "228251                  0      37117.734513          0.000000   \n",
       "228252                  0          0.000000          0.000000   \n",
       "\n",
       "        flow_pkts_per_sec  down_up_ratio  ...      idle.min      idle.max  \\\n",
       "0            33288.126984            1.0  ...  0.000000e+00  0.000000e+00   \n",
       "1            24105.195402            1.0  ...  0.000000e+00  0.000000e+00   \n",
       "2                0.025001            0.0  ...  5.999748e+07  5.999912e+07   \n",
       "3                0.033335            0.0  ...  5.999691e+07  5.999691e+07   \n",
       "4                0.033338            0.0  ...  5.999213e+07  5.999213e+07   \n",
       "...                   ...            ...  ...           ...           ...   \n",
       "228248       73584.280702            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228249       74235.469027            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228250           0.000000            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228251       37117.734513            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228252           0.000000            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "\n",
       "            idle.tot      idle.avg     idle.std  fwd_init_window_size  \\\n",
       "0       0.000000e+00  0.000000e+00     0.000000                 64240   \n",
       "1       0.000000e+00  0.000000e+00     0.000000                 64240   \n",
       "2       1.199966e+08  5.999830e+07  1156.846698                     0   \n",
       "3       5.999691e+07  5.999691e+07     0.000000                     0   \n",
       "4       5.999213e+07  5.999213e+07     0.000000                     0   \n",
       "...              ...           ...          ...                   ...   \n",
       "228248  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228249  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228250  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228251  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228252  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "\n",
       "        bwd_init_window_size  fwd_last_window_size  bwd_last_window_size  \\\n",
       "0                          0                 64240                     0   \n",
       "1                          0                 64240                     0   \n",
       "2                          0                     0                     0   \n",
       "3                          0                     0                     0   \n",
       "4                          0                     0                     0   \n",
       "...                      ...                   ...                   ...   \n",
       "228248                     0                     0                     0   \n",
       "228249                     0                     0                     0   \n",
       "228250                     0                     0                     0   \n",
       "228251                     0                     0                     0   \n",
       "228252                     0                     0                     0   \n",
       "\n",
       "        Label  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "228248      1  \n",
       "228249      1  \n",
       "228250      1  \n",
       "228251      1  \n",
       "228252      1  \n",
       "\n",
       "[228253 rows x 80 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hikari_2022 = hikari_2022.drop(columns=['Unnamed: 0', 'uid', 'originh', 'responh', 'flow_duration', 'fwd_URG_flag_count', \n",
    "                                        'bwd_URG_flag_count', 'attack_category'])\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1982d3e1-56ee-4d9c-9a35-30da7a4dface",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after EDA:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originp</th>\n",
       "      <th>responp</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_tot</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>...</th>\n",
       "      <th>bwd_subflow_bytes</th>\n",
       "      <th>fwd_bulk_packets</th>\n",
       "      <th>bwd_bulk_packets</th>\n",
       "      <th>active.min</th>\n",
       "      <th>active.max</th>\n",
       "      <th>active.avg</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38164</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43068</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>53866</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>54318</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>65355</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>53642</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>61000</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        originp  responp  fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  \\\n",
       "0         38164    50443             1             1                  0   \n",
       "1         43068    50443             1             1                  0   \n",
       "2          5678     5678             3             0                  3   \n",
       "3          5678     5678             2             0                  2   \n",
       "4          5678     5678             2             0                  2   \n",
       "...         ...      ...           ...           ...                ...   \n",
       "228248    53866     1947             2             0                  2   \n",
       "228249    54318     1947             2             0                  2   \n",
       "228250    65355     1947             2             0                  2   \n",
       "228251    53642     1947             2             0                  2   \n",
       "228252    61000     1947             2             0                  2   \n",
       "\n",
       "        bwd_data_pkts_tot  bwd_pkts_per_sec  down_up_ratio  \\\n",
       "0                       0      16644.063492            1.0   \n",
       "1                       0      12052.597701            1.0   \n",
       "2                       0          0.000000            0.0   \n",
       "3                       0          0.000000            0.0   \n",
       "4                       0          0.000000            0.0   \n",
       "...                   ...               ...            ...   \n",
       "228248                  0          0.000000            0.0   \n",
       "228249                  0          0.000000            0.0   \n",
       "228250                  0          0.000000            0.0   \n",
       "228251                  0          0.000000            0.0   \n",
       "228252                  0          0.000000            0.0   \n",
       "\n",
       "        fwd_header_size_tot  fwd_header_size_min  ...  bwd_subflow_bytes  \\\n",
       "0                        40                   40  ...                0.0   \n",
       "1                        40                   40  ...                0.0   \n",
       "2                        24                    8  ...                0.0   \n",
       "3                        16                    8  ...                0.0   \n",
       "4                        16                    8  ...                0.0   \n",
       "...                     ...                  ...  ...                ...   \n",
       "228248                   16                    8  ...                0.0   \n",
       "228249                   16                    8  ...                0.0   \n",
       "228250                   16                    8  ...                0.0   \n",
       "228251                   16                    8  ...                0.0   \n",
       "228252                   16                    8  ...                0.0   \n",
       "\n",
       "        fwd_bulk_packets  bwd_bulk_packets  active.min  active.max  \\\n",
       "0                    0.0               0.0   60.081482   60.081482   \n",
       "1                    0.0               0.0   82.969666   82.969666   \n",
       "2                    0.0               0.0    0.000000    0.000000   \n",
       "3                    0.0               0.0    0.000000    0.000000   \n",
       "4                    0.0               0.0    0.000000    0.000000   \n",
       "...                  ...               ...         ...         ...   \n",
       "228248               0.0               0.0   27.179718   27.179718   \n",
       "228249               0.0               0.0   26.941299   26.941299   \n",
       "228250               0.0               0.0    0.000000    0.000000   \n",
       "228251               0.0               0.0   53.882599   53.882599   \n",
       "228252               0.0               0.0    0.000000    0.000000   \n",
       "\n",
       "        active.avg  fwd_init_window_size  bwd_init_window_size  \\\n",
       "0        60.081482                 64240                     0   \n",
       "1        82.969666                 64240                     0   \n",
       "2         0.000000                     0                     0   \n",
       "3         0.000000                     0                     0   \n",
       "4         0.000000                     0                     0   \n",
       "...            ...                   ...                   ...   \n",
       "228248   27.179718                     0                     0   \n",
       "228249   26.941299                     0                     0   \n",
       "228250    0.000000                     0                     0   \n",
       "228251   53.882599                     0                     0   \n",
       "228252    0.000000                     0                     0   \n",
       "\n",
       "        fwd_last_window_size  Label  \n",
       "0                      64240      0  \n",
       "1                      64240      0  \n",
       "2                          0      0  \n",
       "3                          0      0  \n",
       "4                          0      0  \n",
       "...                      ...    ...  \n",
       "228248                     0      1  \n",
       "228249                     0      1  \n",
       "228250                     0      1  \n",
       "228251                     0      1  \n",
       "228252                     0      1  \n",
       "\n",
       "[228253 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Pearson correlation coefficient\n",
    "corr = hikari_2022.corr(method ='pearson')\n",
    "\n",
    "# Extract the correlation with the target variable 'Label'\n",
    "corr_with_target = corr['Label']\n",
    "\n",
    "# Select only columns with a correlation less than 0.05\n",
    "relevant_features = corr_with_target[abs(corr_with_target) >= 0.05].index\n",
    "\n",
    "# Filter the DataFrame to keep only the relevant features\n",
    "hikari_2022 = hikari_2022[relevant_features]\n",
    "\n",
    "print(\"Dataset after EDA:\")\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078bc70f-198a-4179-8ff3-bffd38e7a6ee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dbbf30-c098-442b-92ad-ed1a9263d351",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Without feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac2ada9-2383-428d-ae11-0992d1cb9792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled,  (343860, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171930\n",
      "1    171930\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.9727497754704169\n",
      "Fold precision: 0.6830140485312899\n",
      "Fold recall: 0.9988793425476279\n",
      "Fold F1-score: 0.8112864077669902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     42974\n",
      "           1       0.68      1.00      0.81      2677\n",
      "\n",
      "    accuracy                           0.97     45651\n",
      "   macro avg       0.84      0.99      0.90     45651\n",
      "weighted avg       0.98      0.97      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343952, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171976\n",
      "1    171976\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.9730126393726315\n",
      "Fold precision: 0.6892612338156893\n",
      "Fold recall: 0.9970620639001102\n",
      "Fold F1-score: 0.8150705493845692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     42928\n",
      "           1       0.69      1.00      0.82      2723\n",
      "\n",
      "    accuracy                           0.97     45651\n",
      "   macro avg       0.84      0.98      0.90     45651\n",
      "weighted avg       0.98      0.97      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343710, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171855\n",
      "1    171855\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.9735821778274298\n",
      "Fold precision: 0.6837809373354397\n",
      "Fold recall: 0.9980784012298232\n",
      "Fold F1-score: 0.8115625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     43049\n",
      "           1       0.68      1.00      0.81      2602\n",
      "\n",
      "    accuracy                           0.97     45651\n",
      "   macro avg       0.84      0.99      0.90     45651\n",
      "weighted avg       0.98      0.97      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343910, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171955\n",
      "1    171955\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.9718072289156626\n",
      "Fold precision: 0.6773707977922729\n",
      "Fold recall: 0.9996297667530544\n",
      "Fold F1-score: 0.8075370121130552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     42949\n",
      "           1       0.68      1.00      0.81      2701\n",
      "\n",
      "    accuracy                           0.97     45650\n",
      "   macro avg       0.84      0.98      0.90     45650\n",
      "weighted avg       0.98      0.97      0.97     45650\n",
      "\n",
      "X_train_resampled,  (343800, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171900\n",
      "1    171900\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.9725958378970427\n",
      "Fold precision: 0.6790757381258024\n",
      "Fold recall: 0.9996220710506425\n",
      "Fold F1-score: 0.8087448402384957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     43004\n",
      "           1       0.68      1.00      0.81      2646\n",
      "\n",
      "    accuracy                           0.97     45650\n",
      "   macro avg       0.84      0.99      0.90     45650\n",
      "weighted avg       0.98      0.97      0.98     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9727495318966367\n",
      "Mean precision: 0.6825005511200988\n",
      "Mean recall: 0.9986543290962515\n",
      "Mean F1-score: 0.8108402619006221\n",
      "\n",
      "El tiempo de ejecucion fue: 224.91349053382874\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Resample with SMOTE \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        print(\"X_train_resampled, \", X_train_resampled.shape)\n",
    "        print(\"y_train_resampled, \", y_train_resampled.value_counts())\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Train SVM classifier\n",
    "        svm_classifier = LinearSVC(class_weight='balanced', max_iter=10000)\n",
    "        svm_classifier.fit(X_train, y_train_resampled)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")   \n",
    "\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e322040-5e11-4f73-bacc-00e3a7880e76",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### With DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f870be6e-6e65-4768-8b9a-5ef0dad8660e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled,  (343860, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171930\n",
      "1    171930\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 839us/step - accuracy: 0.9840 - loss: 0.0584 - val_accuracy: 0.9813 - val_loss: 0.0541\n",
      "Epoch 2/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 823us/step - accuracy: 0.9898 - loss: 0.0370 - val_accuracy: 0.9813 - val_loss: 0.0473\n",
      "Epoch 3/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 825us/step - accuracy: 0.9901 - loss: 0.0361 - val_accuracy: 0.9812 - val_loss: 0.0522\n",
      "Epoch 4/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 815us/step - accuracy: 0.9904 - loss: 0.0351 - val_accuracy: 0.9816 - val_loss: 0.0500\n",
      "Epoch 5/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 824us/step - accuracy: 0.9904 - loss: 0.0352 - val_accuracy: 0.9815 - val_loss: 0.0557\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 460us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 463us/step\n",
      "Fold accuracy: 0.9824100238768044\n",
      "Fold precision: 0.7695627157652474\n",
      "Fold recall: 0.999252895031752\n",
      "Fold F1-score: 0.8694945555013814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42974\n",
      "           1       0.77      1.00      0.87      2677\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.88      0.99      0.93     45651\n",
      "weighted avg       0.99      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343952, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171976\n",
      "1    171976\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 844us/step - accuracy: 0.9843 - loss: 0.0570 - val_accuracy: 0.9814 - val_loss: 0.0551\n",
      "Epoch 2/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 831us/step - accuracy: 0.9899 - loss: 0.0365 - val_accuracy: 0.9804 - val_loss: 0.0565\n",
      "Epoch 3/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 828us/step - accuracy: 0.9900 - loss: 0.0361 - val_accuracy: 0.9818 - val_loss: 0.0515\n",
      "Epoch 4/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 826us/step - accuracy: 0.9903 - loss: 0.0351 - val_accuracy: 0.9816 - val_loss: 0.0531\n",
      "Epoch 5/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 832us/step - accuracy: 0.9903 - loss: 0.0354 - val_accuracy: 0.9819 - val_loss: 0.0512\n",
      "Epoch 6/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 828us/step - accuracy: 0.9905 - loss: 0.0347 - val_accuracy: 0.9821 - val_loss: 0.0483\n",
      "Epoch 7/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 830us/step - accuracy: 0.9905 - loss: 0.0347 - val_accuracy: 0.9820 - val_loss: 0.0518\n",
      "Epoch 8/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 824us/step - accuracy: 0.9904 - loss: 0.0349 - val_accuracy: 0.9810 - val_loss: 0.0547\n",
      "Epoch 9/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 828us/step - accuracy: 0.9903 - loss: 0.0349 - val_accuracy: 0.9818 - val_loss: 0.0474\n",
      "Epoch 10/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 823us/step - accuracy: 0.9905 - loss: 0.0345 - val_accuracy: 0.9825 - val_loss: 0.0480\n",
      "Epoch 11/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 829us/step - accuracy: 0.9904 - loss: 0.0348 - val_accuracy: 0.9817 - val_loss: 0.0520\n",
      "Epoch 12/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 824us/step - accuracy: 0.9904 - loss: 0.0349 - val_accuracy: 0.9820 - val_loss: 0.0486\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 469us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459us/step\n",
      "Fold accuracy: 0.9822785919256971\n",
      "Fold precision: 0.7712585034013606\n",
      "Fold recall: 0.9992655159750276\n",
      "Fold F1-score: 0.8705807070868661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42928\n",
      "           1       0.77      1.00      0.87      2723\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.99      0.93     45651\n",
      "weighted avg       0.99      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343710, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171855\n",
      "1    171855\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 833us/step - accuracy: 0.9835 - loss: 0.0584 - val_accuracy: 0.9815 - val_loss: 0.0535\n",
      "Epoch 2/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 827us/step - accuracy: 0.9896 - loss: 0.0378 - val_accuracy: 0.9827 - val_loss: 0.0469\n",
      "Epoch 3/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 824us/step - accuracy: 0.9893 - loss: 0.0380 - val_accuracy: 0.9825 - val_loss: 0.0476\n",
      "Epoch 4/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 824us/step - accuracy: 0.9903 - loss: 0.0353 - val_accuracy: 0.9826 - val_loss: 0.0491\n",
      "Epoch 5/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 821us/step - accuracy: 0.9900 - loss: 0.0363 - val_accuracy: 0.9827 - val_loss: 0.0439\n",
      "Epoch 6/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 828us/step - accuracy: 0.9902 - loss: 0.0357 - val_accuracy: 0.9821 - val_loss: 0.0459\n",
      "Epoch 7/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 829us/step - accuracy: 0.9901 - loss: 0.0358 - val_accuracy: 0.9830 - val_loss: 0.0477\n",
      "Epoch 8/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 830us/step - accuracy: 0.9902 - loss: 0.0355 - val_accuracy: 0.9829 - val_loss: 0.0481\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 469us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473us/step\n",
      "Fold accuracy: 0.983264331559002\n",
      "Fold precision: 0.7735119047619048\n",
      "Fold recall: 0.9988470407378939\n",
      "Fold F1-score: 0.8718550821871855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43049\n",
      "           1       0.77      1.00      0.87      2602\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.99      0.93     45651\n",
      "weighted avg       0.99      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343910, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171955\n",
      "1    171955\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 859us/step - accuracy: 0.9838 - loss: 0.0630 - val_accuracy: 0.9810 - val_loss: 0.0521\n",
      "Epoch 2/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 838us/step - accuracy: 0.9897 - loss: 0.0372 - val_accuracy: 0.9810 - val_loss: 0.0498\n",
      "Epoch 3/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 844us/step - accuracy: 0.9902 - loss: 0.0358 - val_accuracy: 0.9803 - val_loss: 0.0577\n",
      "Epoch 4/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 840us/step - accuracy: 0.9902 - loss: 0.0355 - val_accuracy: 0.9804 - val_loss: 0.0553\n",
      "Epoch 5/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 845us/step - accuracy: 0.9905 - loss: 0.0349 - val_accuracy: 0.9799 - val_loss: 0.0540\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 462us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 466us/step\n",
      "Fold accuracy: 0.9816210295728368\n",
      "Fold precision: 0.7629943502824859\n",
      "Fold recall: 1.0\n",
      "Fold F1-score: 0.8655664156385194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42949\n",
      "           1       0.76      1.00      0.87      2701\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.88      0.99      0.93     45650\n",
      "weighted avg       0.99      0.98      0.98     45650\n",
      "\n",
      "X_train_resampled,  (343800, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171900\n",
      "1    171900\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 851us/step - accuracy: 0.9848 - loss: 0.0567 - val_accuracy: 0.9802 - val_loss: 0.0659\n",
      "Epoch 2/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842us/step - accuracy: 0.9896 - loss: 0.0379 - val_accuracy: 0.9815 - val_loss: 0.0517\n",
      "Epoch 3/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 844us/step - accuracy: 0.9902 - loss: 0.0360 - val_accuracy: 0.9828 - val_loss: 0.0462\n",
      "Epoch 4/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 841us/step - accuracy: 0.9903 - loss: 0.0357 - val_accuracy: 0.9808 - val_loss: 0.0544\n",
      "Epoch 5/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 848us/step - accuracy: 0.9901 - loss: 0.0358 - val_accuracy: 0.9817 - val_loss: 0.0636\n",
      "Epoch 6/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 838us/step - accuracy: 0.9900 - loss: 0.0362 - val_accuracy: 0.9814 - val_loss: 0.0475\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 475us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step\n",
      "Fold accuracy: 0.9829572836801752\n",
      "Fold precision: 0.7727803738317757\n",
      "Fold recall: 1.0\n",
      "Fold F1-score: 0.871828665568369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43004\n",
      "           1       0.77      1.00      0.87      2646\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.89      0.99      0.93     45650\n",
      "weighted avg       0.99      0.98      0.98     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9825062521229032\n",
      "Mean precision: 0.770021569608555\n",
      "Mean recall: 0.9994730903489348\n",
      "Mean F1-score: 0.8698650851964643\n",
      "\n",
      "El tiempo de ejecucion fue: 382.4061281681061\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the DNN model\n",
    "def create_dnn(input_dim):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    \n",
    "    # Hidden layer 1\n",
    "    x = Dense(input_dim * 2)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Hidden layer 2\n",
    "    x = Dense(input_dim)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Feature layer\n",
    "    n_bottleneck = round(float(input_dim) / 2.0)\n",
    "    bottleneck = Dense(n_bottleneck)(x)\n",
    "    bottleneck = BatchNormalization()(bottleneck)\n",
    "    bottleneck = ReLU()(bottleneck)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation='sigmoid')(bottleneck)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Model for feature extraction\n",
    "    feature_extractor = Model(inputs=inputs, outputs=bottleneck)\n",
    "    \n",
    "    return model, feature_extractor\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_dnn(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Resample with SMOTE \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        print(\"X_train_resampled, \", X_train_resampled.shape)\n",
    "        print(\"y_train_resampled, \", y_train_resampled.value_counts())\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        dnn, feature_extractor = create_dnn(n_inputs)\n",
    "        \n",
    "        # Early Stopping\n",
    "        early_stopping1 = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "        early_stopping2 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # Fit the DNN model\n",
    "        dnn.fit(X_train, y_train_resampled, epochs=100, batch_size=32, verbose=1,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        callbacks=[early_stopping1, early_stopping2])\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = feature_extractor.predict(X_train)\n",
    "        X_test_encoded = feature_extractor.predict(X_test)\n",
    "        \n",
    "        # Train SVM classifier\n",
    "        svm_classifier_encoded = LinearSVC(class_weight='balanced', max_iter=10000)\n",
    "        svm_classifier_encoded.fit(X_train_encoded, y_train_resampled)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = svm_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_dnn(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9176c09-ba87-45f0-9113-30f7de69c72d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### With DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f60b25-c365-4e28-9022-59c22addcd30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_dbn(layers, file_name='dbn_structure.png'):\n",
    "    # Crear un grafo dirigido\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Añadir nodos para cada capa RBM\n",
    "    for i, n_units in enumerate(layers):\n",
    "        G.add_node(f\"RBM {i+1}\\n{n_units} unidades\", layer=i+1)\n",
    "\n",
    "    # Añadir aristas entre nodos (de una capa a otra)\n",
    "    for i in range(len(layers) - 1):\n",
    "        G.add_edge(f\"RBM {i+1}\\n{layers[i]} unidades\", f\"RBM {i+2}\\n{layers[i+1]} unidades\")\n",
    "\n",
    "    # Dibujar el grafo\n",
    "    pos = nx.spring_layout(G)  # Posición de los nodos\n",
    "    nx.draw(G, pos, with_labels=True, node_size=3000, node_color='lightblue', font_size=10, font_weight='bold')\n",
    "    \n",
    "    # Guardar la imagen a un archivo\n",
    "    plt.title(\"Arquitectura de la DBN\")\n",
    "    plt.savefig(file_name)\n",
    "    plt.show()\n",
    "    \n",
    "#visualize_dbn([X.shape[1]*2, X.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d237480-eb1b-4961-9f4d-0846b4517f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled,  (343860, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171930\n",
      "1    171930\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.30, time = 5.75s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.28, time = 7.20s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.98, time = 7.10s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.14, time = 7.15s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.07, time = 7.18s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.94, time = 7.17s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.90, time = 7.08s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.96, time = 6.97s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.90, time = 7.19s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.90, time = 7.01s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -3.88, time = 5.66s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -4.06, time = 6.54s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.83, time = 6.49s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -3.87, time = 6.52s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.19, time = 6.55s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.13, time = 6.52s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.18, time = 6.51s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.92, time = 6.55s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.77, time = 6.54s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.63, time = 6.42s\n",
      "Fold accuracy: 0.9188407701912334\n",
      "Fold precision: 0.3764423076923077\n",
      "Fold recall: 0.5849831901382144\n",
      "Fold F1-score: 0.45809565598946905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96     42974\n",
      "           1       0.38      0.58      0.46      2677\n",
      "\n",
      "    accuracy                           0.92     45651\n",
      "   macro avg       0.67      0.76      0.71     45651\n",
      "weighted avg       0.94      0.92      0.93     45651\n",
      "\n",
      "X_train_resampled,  (343952, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171976\n",
      "1    171976\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.43, time = 5.76s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.24, time = 7.19s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.39, time = 7.55s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.41, time = 7.20s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.45, time = 7.19s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.44, time = 7.05s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5.37, time = 7.17s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5.31, time = 7.12s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.14, time = 7.18s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.37, time = 7.07s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -3.59, time = 5.64s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1.17, time = 6.59s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -1.42, time = 6.45s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1.12, time = 6.51s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1.58, time = 6.49s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -2.67, time = 6.57s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -1.19, time = 6.55s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -2.46, time = 6.49s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -2.17, time = 6.59s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -1.25, time = 6.42s\n",
      "Fold accuracy: 0.9256533263236293\n",
      "Fold precision: 0.41260744985673353\n",
      "Fold recall: 0.5817113477781858\n",
      "Fold F1-score: 0.48277964035355075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     42928\n",
      "           1       0.41      0.58      0.48      2723\n",
      "\n",
      "    accuracy                           0.93     45651\n",
      "   macro avg       0.69      0.76      0.72     45651\n",
      "weighted avg       0.94      0.93      0.93     45651\n",
      "\n",
      "X_train_resampled,  (343710, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171855\n",
      "1    171855\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.36, time = 5.97s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.35, time = 7.17s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.27, time = 7.22s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.15, time = 7.17s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.24, time = 7.13s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.04, time = 7.05s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5.20, time = 7.03s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5.19, time = 7.08s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.21, time = 7.09s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.11, time = 7.16s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -3.83, time = 5.54s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -4.02, time = 6.48s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.80, time = 6.44s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -3.97, time = 6.43s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.28, time = 6.49s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -3.95, time = 6.41s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -3.94, time = 6.49s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.06, time = 6.38s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.00, time = 6.56s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.86, time = 6.48s\n",
      "Fold accuracy: 0.9181617051105123\n",
      "Fold precision: 0.35853293413173654\n",
      "Fold recall: 0.5522674865488086\n",
      "Fold F1-score: 0.43479576399394854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96     43049\n",
      "           1       0.36      0.55      0.43      2602\n",
      "\n",
      "    accuracy                           0.92     45651\n",
      "   macro avg       0.67      0.75      0.70     45651\n",
      "weighted avg       0.94      0.92      0.93     45651\n",
      "\n",
      "X_train_resampled,  (343910, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171955\n",
      "1    171955\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.35, time = 5.74s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.31, time = 7.26s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.21, time = 7.19s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.02, time = 7.22s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.07, time = 7.06s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.08, time = 7.20s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5.03, time = 7.19s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5.08, time = 7.14s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.98, time = 7.11s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.06, time = 7.02s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -4.43, time = 5.54s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -6.11, time = 6.46s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -3.91, time = 6.44s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.09, time = 6.35s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -3.86, time = 6.47s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -3.92, time = 6.62s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -3.87, time = 6.48s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -3.87, time = 6.64s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.31, time = 6.48s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.92, time = 6.48s\n",
      "Fold accuracy: 0.9237020810514787\n",
      "Fold precision: 0.39742917103882475\n",
      "Fold recall: 0.5609033691225472\n",
      "Fold F1-score: 0.4652233993551359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     42949\n",
      "           1       0.40      0.56      0.47      2701\n",
      "\n",
      "    accuracy                           0.92     45650\n",
      "   macro avg       0.68      0.75      0.71     45650\n",
      "weighted avg       0.94      0.92      0.93     45650\n",
      "\n",
      "X_train_resampled,  (343800, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171900\n",
      "1    171900\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.25, time = 5.84s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.11, time = 7.15s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.10, time = 7.24s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.08, time = 7.12s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.93, time = 7.14s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.93, time = 7.08s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.97, time = 7.08s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.92, time = 7.04s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.06, time = 7.14s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.07, time = 7.02s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -3.83, time = 5.68s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -6.52, time = 6.43s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.97, time = 6.48s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -3.84, time = 6.49s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.20, time = 6.39s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.58, time = 6.50s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.28, time = 6.48s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.00, time = 6.38s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.88, time = 6.44s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.87, time = 6.43s\n",
      "Fold accuracy: 0.9263307776560789\n",
      "Fold precision: 0.40323886639676115\n",
      "Fold recall: 0.564625850340136\n",
      "Fold F1-score: 0.4704770902220123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     43004\n",
      "           1       0.40      0.56      0.47      2646\n",
      "\n",
      "    accuracy                           0.93     45650\n",
      "   macro avg       0.69      0.76      0.72     45650\n",
      "weighted avg       0.94      0.93      0.93     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9225377320665865\n",
      "Mean precision: 0.38965014582327273\n",
      "Mean recall: 0.5688982487855785\n",
      "Mean F1-score: 0.4622743099828234\n",
      "\n",
      "El tiempo de ejecucion fue: 697.2693004608154\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the DBN class\n",
    "class DBN(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rbm_layers, rbm_learning_rate, rbm_n_iter):\n",
    "        self.rbm_layers = rbm_layers\n",
    "        self.rbm_learning_rate = rbm_learning_rate\n",
    "        self.rbm_n_iter = rbm_n_iter\n",
    "        self.rbms = []\n",
    "        for i, n_components in enumerate(rbm_layers):\n",
    "            self.rbms.append(BernoulliRBM(n_components=n_components, learning_rate=rbm_learning_rate, n_iter=rbm_n_iter, verbose=1))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        input_data = X\n",
    "        for rbm in self.rbms:\n",
    "            rbm.fit(input_data)\n",
    "            input_data = rbm.transform(input_data)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        input_data = X\n",
    "        for rbm in self.rbms:\n",
    "            input_data = rbm.transform(input_data)\n",
    "        return input_data\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_dbn(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Resample with SMOTE \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        print(\"X_train_resampled, \", X_train_resampled.shape)\n",
    "        print(\"y_train_resampled, \", y_train_resampled.value_counts())\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        dbn = DBN(rbm_layers=[n_inputs*2, n_inputs], rbm_learning_rate=0.1, rbm_n_iter=10)\n",
    "        \n",
    "        # Fit the DBN model\n",
    "        dbn.fit(X_train)\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = dbn.transform(X_train)\n",
    "        X_test_encoded = dbn.transform(X_test)\n",
    "        \n",
    "        # Train SVM classifier\n",
    "        svm_classifier_encoded = LinearSVC(class_weight='balanced', max_iter=10000)\n",
    "        svm_classifier_encoded.fit(X_train_encoded, y_train_resampled)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = svm_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "    \n",
    "    \n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_dbn(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8124559-b551-4af6-8503-0901cfc82b15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### With Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c58e6d3-7e3c-4147-8ef4-a057322d7f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled,  (343860, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171930\n",
      "1    171930\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 745us/step - loss: 0.1652 - val_loss: 0.1031\n",
      "Epoch 2/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 724us/step - loss: 0.0808 - val_loss: 0.0681\n",
      "Epoch 3/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 719us/step - loss: 0.0806 - val_loss: 0.0552\n",
      "Epoch 4/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 721us/step - loss: 0.0624 - val_loss: 0.0813\n",
      "Epoch 5/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 724us/step - loss: 0.0673 - val_loss: 0.0306\n",
      "Epoch 6/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 721us/step - loss: 0.0801 - val_loss: 0.0273\n",
      "Epoch 7/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 728us/step - loss: 0.0371 - val_loss: 0.0282\n",
      "Epoch 8/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 719us/step - loss: 0.0429 - val_loss: 0.0321\n",
      "Epoch 9/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 727us/step - loss: 0.0385 - val_loss: 0.0425\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 426us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step\n",
      "Fold accuracy: 0.9649076690543471\n",
      "Fold precision: 0.6258487473659564\n",
      "Fold recall: 0.9985057900635039\n",
      "Fold F1-score: 0.7694300518134715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     42974\n",
      "           1       0.63      1.00      0.77      2677\n",
      "\n",
      "    accuracy                           0.96     45651\n",
      "   macro avg       0.81      0.98      0.88     45651\n",
      "weighted avg       0.98      0.96      0.97     45651\n",
      "\n",
      "X_train_resampled,  (343952, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171976\n",
      "1    171976\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 724us/step - loss: 0.1876 - val_loss: 0.3073\n",
      "Epoch 2/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 714us/step - loss: 0.1280 - val_loss: 0.1125\n",
      "Epoch 3/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 713us/step - loss: 0.0826 - val_loss: 0.0786\n",
      "Epoch 4/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 720us/step - loss: 0.0673 - val_loss: 0.1740\n",
      "Epoch 5/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 713us/step - loss: 0.0732 - val_loss: 0.0941\n",
      "Epoch 6/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 717us/step - loss: 0.0711 - val_loss: 0.0554\n",
      "Epoch 7/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 717us/step - loss: 0.0802 - val_loss: 0.0613\n",
      "Epoch 8/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 718us/step - loss: 0.0342 - val_loss: 0.0620\n",
      "Epoch 9/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 715us/step - loss: 0.0445 - val_loss: 0.0573\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 428us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438us/step\n",
      "Fold accuracy: 0.9683906157586909\n",
      "Fold precision: 0.654291224686596\n",
      "Fold recall: 0.9966948218876239\n",
      "Fold F1-score: 0.7899869014699461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     42928\n",
      "           1       0.65      1.00      0.79      2723\n",
      "\n",
      "    accuracy                           0.97     45651\n",
      "   macro avg       0.83      0.98      0.89     45651\n",
      "weighted avg       0.98      0.97      0.97     45651\n",
      "\n",
      "X_train_resampled,  (343710, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171855\n",
      "1    171855\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 740us/step - loss: 0.1338 - val_loss: 0.4503\n",
      "Epoch 2/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 722us/step - loss: 0.0744 - val_loss: 0.7218\n",
      "Epoch 3/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 717us/step - loss: 0.0415 - val_loss: 0.4445\n",
      "Epoch 4/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 723us/step - loss: 0.0554 - val_loss: 0.5277\n",
      "Epoch 5/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 719us/step - loss: 0.0317 - val_loss: 0.5233\n",
      "Epoch 6/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 725us/step - loss: 0.0454 - val_loss: 0.3625\n",
      "Epoch 7/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 720us/step - loss: 0.0486 - val_loss: 0.2818\n",
      "Epoch 8/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 724us/step - loss: 0.0356 - val_loss: 0.3411\n",
      "Epoch 9/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 720us/step - loss: 0.0311 - val_loss: 0.3439\n",
      "Epoch 10/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 724us/step - loss: 0.0307 - val_loss: 0.3309\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 421us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418us/step\n",
      "Fold accuracy: 0.9691573021401503\n",
      "Fold precision: 0.6495490981963928\n",
      "Fold recall: 0.9965411222136817\n",
      "Fold F1-score: 0.786472550803761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     43049\n",
      "           1       0.65      1.00      0.79      2602\n",
      "\n",
      "    accuracy                           0.97     45651\n",
      "   macro avg       0.82      0.98      0.88     45651\n",
      "weighted avg       0.98      0.97      0.97     45651\n",
      "\n",
      "X_train_resampled,  (343910, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171955\n",
      "1    171955\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 729us/step - loss: 0.1835 - val_loss: 0.0556\n",
      "Epoch 2/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 715us/step - loss: 0.0813 - val_loss: 0.2477\n",
      "Epoch 3/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 714us/step - loss: 0.0826 - val_loss: 0.0573\n",
      "Epoch 4/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 714us/step - loss: 0.0766 - val_loss: 0.0466\n",
      "Epoch 5/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 715us/step - loss: 0.0700 - val_loss: 0.0503\n",
      "Epoch 6/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 717us/step - loss: 0.0456 - val_loss: 0.0907\n",
      "Epoch 7/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 718us/step - loss: 0.0684 - val_loss: 0.0418\n",
      "Epoch 8/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 719us/step - loss: 0.0613 - val_loss: 0.0352\n",
      "Epoch 9/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 728us/step - loss: 0.0315 - val_loss: 0.0406\n",
      "Epoch 10/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 721us/step - loss: 0.0382 - val_loss: 0.0484\n",
      "Epoch 11/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 719us/step - loss: 0.0314 - val_loss: 0.1149\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 424us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step\n",
      "Fold accuracy: 0.9689156626506024\n",
      "Fold precision: 0.6557337220602527\n",
      "Fold recall: 0.9992595335061089\n",
      "Fold F1-score: 0.7918439196127329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     42949\n",
      "           1       0.66      1.00      0.79      2701\n",
      "\n",
      "    accuracy                           0.97     45650\n",
      "   macro avg       0.83      0.98      0.89     45650\n",
      "weighted avg       0.98      0.97      0.97     45650\n",
      "\n",
      "X_train_resampled,  (343800, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171900\n",
      "1    171900\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 724us/step - loss: 0.1554 - val_loss: 0.1514\n",
      "Epoch 2/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 718us/step - loss: 0.0756 - val_loss: 0.1395\n",
      "Epoch 3/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 714us/step - loss: 0.0593 - val_loss: 0.4484\n",
      "Epoch 4/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 724us/step - loss: 0.0470 - val_loss: 0.0913\n",
      "Epoch 5/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 712us/step - loss: 0.0677 - val_loss: 0.0718\n",
      "Epoch 6/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 719us/step - loss: 0.0709 - val_loss: 0.2188\n",
      "Epoch 7/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 713us/step - loss: 0.0605 - val_loss: 0.0342\n",
      "Epoch 8/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 718us/step - loss: 0.0598 - val_loss: 0.0754\n",
      "Epoch 9/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 713us/step - loss: 0.0541 - val_loss: 0.0805\n",
      "Epoch 10/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 717us/step - loss: 0.0448 - val_loss: 0.1277\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 425us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434us/step\n",
      "Fold accuracy: 0.9658926615553122\n",
      "Fold precision: 0.6299212598425197\n",
      "Fold recall: 0.9977324263038548\n",
      "Fold F1-score: 0.7722685388328214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     43004\n",
      "           1       0.63      1.00      0.77      2646\n",
      "\n",
      "    accuracy                           0.97     45650\n",
      "   macro avg       0.81      0.98      0.88     45650\n",
      "weighted avg       0.98      0.97      0.97     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9674527822318206\n",
      "Mean precision: 0.6430688104303435\n",
      "Mean recall: 0.9977467387949547\n",
      "Mean F1-score: 0.7820003925065466\n",
      "\n",
      "El tiempo de ejecucion fue: 446.0999987125397\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the autoencoder model\n",
    "def create_autoencoder(n_inputs):\n",
    "    inputs = Input(shape=(n_inputs,))\n",
    "    \n",
    "    # Define Encoder\n",
    "    e = Dense(n_inputs*2)(inputs)\n",
    "    e = BatchNormalization()(e)\n",
    "    e = LeakyReLU()(e)\n",
    "    \n",
    "    # Bottleneck\n",
    "    n_bottleneck = round(float(n_inputs)/2.0)\n",
    "    bottleneck = Dense(n_bottleneck)(e)\n",
    "    \n",
    "    # Define Decoder\n",
    "    d = Dense(n_inputs*2)(bottleneck)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU()(d)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(n_inputs, activation='linear')(d)\n",
    "    \n",
    "    # Define autoencoder model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Define encoder model\n",
    "    encoder = Model(inputs=inputs, outputs=bottleneck)\n",
    "    \n",
    "    return model, encoder\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_autoencoder(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Resample with SMOTE \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        print(\"X_train_resampled, \", X_train_resampled.shape)\n",
    "        print(\"y_train_resampled, \", y_train_resampled.value_counts())\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        autoencoder, encoder = create_autoencoder(n_inputs)\n",
    "        \n",
    "        # Early Stopping\n",
    "        early_stopping1 = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "        early_stopping2 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # Fit the DNN model\n",
    "        autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, verbose=1,\n",
    "                        validation_data=(X_test, X_test),\n",
    "                        callbacks=[early_stopping1, early_stopping2])\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = encoder.predict(X_train)\n",
    "        X_test_encoded = encoder.predict(X_test)\n",
    "        \n",
    "        # Train SVM classifier\n",
    "        svm_classifier_encoded = LinearSVC(class_weight='balanced', max_iter=10000)\n",
    "        svm_classifier_encoded.fit(X_train_encoded, y_train_resampled)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = svm_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_autoencoder(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4daef-afdd-4dfe-a145-05ab6c4368c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
