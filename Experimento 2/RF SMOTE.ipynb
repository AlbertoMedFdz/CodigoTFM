{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf026ff-8cbf-414b-a47b-9ca1cb0b2652",
   "metadata": {
    "tags": []
   },
   "source": [
    "_Alberto Medrano Fern√°ndez_\n",
    "\n",
    "# Random Forest (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe473f3-1603-43b8-8c4a-fe001e945785",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a37898-36cc-40b9-a502-97fc4f538cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from time import time\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder \n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeacebd-c31e-45bb-8d1c-037352c4acc7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd39d501-dc75-4f2e-a36c-1e26ad59c861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uid</th>\n",
       "      <th>originh</th>\n",
       "      <th>originp</th>\n",
       "      <th>responh</th>\n",
       "      <th>responp</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>idle.max</th>\n",
       "      <th>idle.tot</th>\n",
       "      <th>idle.avg</th>\n",
       "      <th>idle.std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>bwd_last_window_size</th>\n",
       "      <th>attack_category</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cmu9v81jToQyRF1gbk</td>\n",
       "      <td>184.0.48.168</td>\n",
       "      <td>38164</td>\n",
       "      <td>184.0.48.150</td>\n",
       "      <td>50443</td>\n",
       "      <td>0 days 00:00:00.000060</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CO21hl3TWkuXTOgajk</td>\n",
       "      <td>184.0.48.169</td>\n",
       "      <td>43068</td>\n",
       "      <td>184.0.48.150</td>\n",
       "      <td>50443</td>\n",
       "      <td>0 days 00:00:00.000083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBLJ6L19FP0MfYX7Oh</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:01:59.996602</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999912e+07</td>\n",
       "      <td>1.199966e+08</td>\n",
       "      <td>5.999830e+07</td>\n",
       "      <td>1156.846698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ChTG451zJ7hUYOcqje</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:00:59.996909</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cn9y6E2KVxzQbs5wjc</td>\n",
       "      <td>184.0.48.124</td>\n",
       "      <td>5678</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>5678</td>\n",
       "      <td>0 days 00:00:59.992130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>16634</td>\n",
       "      <td>Clt16PPxzrXEtpa5d</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>53866</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000027</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>53170</td>\n",
       "      <td>Cs8RA72uHDiQa5ch2k</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>54318</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000027</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>53529</td>\n",
       "      <td>Cy4dqo4YEq5YGxjUXa</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>65355</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>86308</td>\n",
       "      <td>CFXfNV3OTG04e0UnP4</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>53642</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00.000054</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>99240</td>\n",
       "      <td>CqO7kc2eC5InNvWrtl</td>\n",
       "      <td>184.0.48.20</td>\n",
       "      <td>61000</td>\n",
       "      <td>184.0.48.255</td>\n",
       "      <td>1947</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XMRIGCC CryptoMiner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows √ó 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                 uid       originh  originp  \\\n",
       "0                0  Cmu9v81jToQyRF1gbk  184.0.48.168    38164   \n",
       "1                1  CO21hl3TWkuXTOgajk  184.0.48.169    43068   \n",
       "2                2  CBLJ6L19FP0MfYX7Oh  184.0.48.124     5678   \n",
       "3                3  ChTG451zJ7hUYOcqje  184.0.48.124     5678   \n",
       "4                4  Cn9y6E2KVxzQbs5wjc  184.0.48.124     5678   \n",
       "...            ...                 ...           ...      ...   \n",
       "228248       16634   Clt16PPxzrXEtpa5d   184.0.48.20    53866   \n",
       "228249       53170  Cs8RA72uHDiQa5ch2k   184.0.48.20    54318   \n",
       "228250       53529  Cy4dqo4YEq5YGxjUXa   184.0.48.20    65355   \n",
       "228251       86308  CFXfNV3OTG04e0UnP4   184.0.48.20    53642   \n",
       "228252       99240  CqO7kc2eC5InNvWrtl   184.0.48.20    61000   \n",
       "\n",
       "                responh  responp           flow_duration  fwd_pkts_tot  \\\n",
       "0          184.0.48.150    50443  0 days 00:00:00.000060             1   \n",
       "1          184.0.48.150    50443  0 days 00:00:00.000083             1   \n",
       "2       255.255.255.255     5678  0 days 00:01:59.996602             3   \n",
       "3       255.255.255.255     5678  0 days 00:00:59.996909             2   \n",
       "4       255.255.255.255     5678  0 days 00:00:59.992130             2   \n",
       "...                 ...      ...                     ...           ...   \n",
       "228248     184.0.48.255     1947  0 days 00:00:00.000027             2   \n",
       "228249     184.0.48.255     1947  0 days 00:00:00.000027             2   \n",
       "228250     184.0.48.255     1947         0 days 00:00:00             2   \n",
       "228251     184.0.48.255     1947  0 days 00:00:00.000054             2   \n",
       "228252     184.0.48.255     1947         0 days 00:00:00             2   \n",
       "\n",
       "        bwd_pkts_tot  fwd_data_pkts_tot  ...      idle.max      idle.tot  \\\n",
       "0                  1                  0  ...  0.000000e+00  0.000000e+00   \n",
       "1                  1                  0  ...  0.000000e+00  0.000000e+00   \n",
       "2                  0                  3  ...  5.999912e+07  1.199966e+08   \n",
       "3                  0                  2  ...  5.999691e+07  5.999691e+07   \n",
       "4                  0                  2  ...  5.999213e+07  5.999213e+07   \n",
       "...              ...                ...  ...           ...           ...   \n",
       "228248             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228249             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228250             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228251             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "228252             0                  2  ...  0.000000e+00  0.000000e+00   \n",
       "\n",
       "            idle.avg     idle.std  fwd_init_window_size  bwd_init_window_size  \\\n",
       "0       0.000000e+00     0.000000                 64240                     0   \n",
       "1       0.000000e+00     0.000000                 64240                     0   \n",
       "2       5.999830e+07  1156.846698                     0                     0   \n",
       "3       5.999691e+07     0.000000                     0                     0   \n",
       "4       5.999213e+07     0.000000                     0                     0   \n",
       "...              ...          ...                   ...                   ...   \n",
       "228248  0.000000e+00     0.000000                     0                     0   \n",
       "228249  0.000000e+00     0.000000                     0                     0   \n",
       "228250  0.000000e+00     0.000000                     0                     0   \n",
       "228251  0.000000e+00     0.000000                     0                     0   \n",
       "228252  0.000000e+00     0.000000                     0                     0   \n",
       "\n",
       "        fwd_last_window_size  bwd_last_window_size      attack_category  Label  \n",
       "0                      64240                     0               Benign      0  \n",
       "1                      64240                     0               Benign      0  \n",
       "2                          0                     0               Benign      0  \n",
       "3                          0                     0               Benign      0  \n",
       "4                          0                     0               Benign      0  \n",
       "...                      ...                   ...                  ...    ...  \n",
       "228248                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228249                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228250                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228251                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "228252                     0                     0  XMRIGCC CryptoMiner      1  \n",
       "\n",
       "[228253 rows x 88 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hikari_2022 = pd.read_csv('ALLFLOWMETER_HIKARI2022.csv', sep=',')\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956f3516-19f9-4d0e-8610-f3ebbc7a3fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originp</th>\n",
       "      <th>responp</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>idle.min</th>\n",
       "      <th>idle.max</th>\n",
       "      <th>idle.tot</th>\n",
       "      <th>idle.avg</th>\n",
       "      <th>idle.std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>bwd_last_window_size</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38164</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>33288.126984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43068</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>24105.195402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999748e+07</td>\n",
       "      <td>5.999912e+07</td>\n",
       "      <td>1.199966e+08</td>\n",
       "      <td>5.999830e+07</td>\n",
       "      <td>1156.846698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>5.999691e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>5.999213e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>53866</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>73584.280702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73584.280702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>54318</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74235.469027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74235.469027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>65355</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>53642</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37117.734513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37117.734513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>61000</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows √ó 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        originp  responp  fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  \\\n",
       "0         38164    50443             1             1                  0   \n",
       "1         43068    50443             1             1                  0   \n",
       "2          5678     5678             3             0                  3   \n",
       "3          5678     5678             2             0                  2   \n",
       "4          5678     5678             2             0                  2   \n",
       "...         ...      ...           ...           ...                ...   \n",
       "228248    53866     1947             2             0                  2   \n",
       "228249    54318     1947             2             0                  2   \n",
       "228250    65355     1947             2             0                  2   \n",
       "228251    53642     1947             2             0                  2   \n",
       "228252    61000     1947             2             0                  2   \n",
       "\n",
       "        bwd_data_pkts_tot  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
       "0                       0      16644.063492      16644.063492   \n",
       "1                       0      12052.597701      12052.597701   \n",
       "2                       0          0.025001          0.000000   \n",
       "3                       0          0.033335          0.000000   \n",
       "4                       0          0.033338          0.000000   \n",
       "...                   ...               ...               ...   \n",
       "228248                  0      73584.280702          0.000000   \n",
       "228249                  0      74235.469027          0.000000   \n",
       "228250                  0          0.000000          0.000000   \n",
       "228251                  0      37117.734513          0.000000   \n",
       "228252                  0          0.000000          0.000000   \n",
       "\n",
       "        flow_pkts_per_sec  down_up_ratio  ...      idle.min      idle.max  \\\n",
       "0            33288.126984            1.0  ...  0.000000e+00  0.000000e+00   \n",
       "1            24105.195402            1.0  ...  0.000000e+00  0.000000e+00   \n",
       "2                0.025001            0.0  ...  5.999748e+07  5.999912e+07   \n",
       "3                0.033335            0.0  ...  5.999691e+07  5.999691e+07   \n",
       "4                0.033338            0.0  ...  5.999213e+07  5.999213e+07   \n",
       "...                   ...            ...  ...           ...           ...   \n",
       "228248       73584.280702            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228249       74235.469027            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228250           0.000000            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228251       37117.734513            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "228252           0.000000            0.0  ...  0.000000e+00  0.000000e+00   \n",
       "\n",
       "            idle.tot      idle.avg     idle.std  fwd_init_window_size  \\\n",
       "0       0.000000e+00  0.000000e+00     0.000000                 64240   \n",
       "1       0.000000e+00  0.000000e+00     0.000000                 64240   \n",
       "2       1.199966e+08  5.999830e+07  1156.846698                     0   \n",
       "3       5.999691e+07  5.999691e+07     0.000000                     0   \n",
       "4       5.999213e+07  5.999213e+07     0.000000                     0   \n",
       "...              ...           ...          ...                   ...   \n",
       "228248  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228249  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228250  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228251  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "228252  0.000000e+00  0.000000e+00     0.000000                     0   \n",
       "\n",
       "        bwd_init_window_size  fwd_last_window_size  bwd_last_window_size  \\\n",
       "0                          0                 64240                     0   \n",
       "1                          0                 64240                     0   \n",
       "2                          0                     0                     0   \n",
       "3                          0                     0                     0   \n",
       "4                          0                     0                     0   \n",
       "...                      ...                   ...                   ...   \n",
       "228248                     0                     0                     0   \n",
       "228249                     0                     0                     0   \n",
       "228250                     0                     0                     0   \n",
       "228251                     0                     0                     0   \n",
       "228252                     0                     0                     0   \n",
       "\n",
       "        Label  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "228248      1  \n",
       "228249      1  \n",
       "228250      1  \n",
       "228251      1  \n",
       "228252      1  \n",
       "\n",
       "[228253 rows x 80 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hikari_2022 = hikari_2022.drop(columns=['Unnamed: 0', 'uid', 'originh', 'responh', 'flow_duration', 'fwd_URG_flag_count', \n",
    "                                        'bwd_URG_flag_count', 'attack_category'])\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1982d3e1-56ee-4d9c-9a35-30da7a4dface",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after EDA:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originp</th>\n",
       "      <th>responp</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_tot</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>...</th>\n",
       "      <th>bwd_subflow_bytes</th>\n",
       "      <th>fwd_bulk_packets</th>\n",
       "      <th>bwd_bulk_packets</th>\n",
       "      <th>active.min</th>\n",
       "      <th>active.max</th>\n",
       "      <th>active.avg</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38164</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16644.063492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>60.081482</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43068</td>\n",
       "      <td>50443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12052.597701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>82.969666</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "      <td>64240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5678</td>\n",
       "      <td>5678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228248</th>\n",
       "      <td>53866</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>27.179718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228249</th>\n",
       "      <td>54318</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>26.941299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228250</th>\n",
       "      <td>65355</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228251</th>\n",
       "      <td>53642</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>53.882599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228252</th>\n",
       "      <td>61000</td>\n",
       "      <td>1947</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228253 rows √ó 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        originp  responp  fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  \\\n",
       "0         38164    50443             1             1                  0   \n",
       "1         43068    50443             1             1                  0   \n",
       "2          5678     5678             3             0                  3   \n",
       "3          5678     5678             2             0                  2   \n",
       "4          5678     5678             2             0                  2   \n",
       "...         ...      ...           ...           ...                ...   \n",
       "228248    53866     1947             2             0                  2   \n",
       "228249    54318     1947             2             0                  2   \n",
       "228250    65355     1947             2             0                  2   \n",
       "228251    53642     1947             2             0                  2   \n",
       "228252    61000     1947             2             0                  2   \n",
       "\n",
       "        bwd_data_pkts_tot  bwd_pkts_per_sec  down_up_ratio  \\\n",
       "0                       0      16644.063492            1.0   \n",
       "1                       0      12052.597701            1.0   \n",
       "2                       0          0.000000            0.0   \n",
       "3                       0          0.000000            0.0   \n",
       "4                       0          0.000000            0.0   \n",
       "...                   ...               ...            ...   \n",
       "228248                  0          0.000000            0.0   \n",
       "228249                  0          0.000000            0.0   \n",
       "228250                  0          0.000000            0.0   \n",
       "228251                  0          0.000000            0.0   \n",
       "228252                  0          0.000000            0.0   \n",
       "\n",
       "        fwd_header_size_tot  fwd_header_size_min  ...  bwd_subflow_bytes  \\\n",
       "0                        40                   40  ...                0.0   \n",
       "1                        40                   40  ...                0.0   \n",
       "2                        24                    8  ...                0.0   \n",
       "3                        16                    8  ...                0.0   \n",
       "4                        16                    8  ...                0.0   \n",
       "...                     ...                  ...  ...                ...   \n",
       "228248                   16                    8  ...                0.0   \n",
       "228249                   16                    8  ...                0.0   \n",
       "228250                   16                    8  ...                0.0   \n",
       "228251                   16                    8  ...                0.0   \n",
       "228252                   16                    8  ...                0.0   \n",
       "\n",
       "        fwd_bulk_packets  bwd_bulk_packets  active.min  active.max  \\\n",
       "0                    0.0               0.0   60.081482   60.081482   \n",
       "1                    0.0               0.0   82.969666   82.969666   \n",
       "2                    0.0               0.0    0.000000    0.000000   \n",
       "3                    0.0               0.0    0.000000    0.000000   \n",
       "4                    0.0               0.0    0.000000    0.000000   \n",
       "...                  ...               ...         ...         ...   \n",
       "228248               0.0               0.0   27.179718   27.179718   \n",
       "228249               0.0               0.0   26.941299   26.941299   \n",
       "228250               0.0               0.0    0.000000    0.000000   \n",
       "228251               0.0               0.0   53.882599   53.882599   \n",
       "228252               0.0               0.0    0.000000    0.000000   \n",
       "\n",
       "        active.avg  fwd_init_window_size  bwd_init_window_size  \\\n",
       "0        60.081482                 64240                     0   \n",
       "1        82.969666                 64240                     0   \n",
       "2         0.000000                     0                     0   \n",
       "3         0.000000                     0                     0   \n",
       "4         0.000000                     0                     0   \n",
       "...            ...                   ...                   ...   \n",
       "228248   27.179718                     0                     0   \n",
       "228249   26.941299                     0                     0   \n",
       "228250    0.000000                     0                     0   \n",
       "228251   53.882599                     0                     0   \n",
       "228252    0.000000                     0                     0   \n",
       "\n",
       "        fwd_last_window_size  Label  \n",
       "0                      64240      0  \n",
       "1                      64240      0  \n",
       "2                          0      0  \n",
       "3                          0      0  \n",
       "4                          0      0  \n",
       "...                      ...    ...  \n",
       "228248                     0      1  \n",
       "228249                     0      1  \n",
       "228250                     0      1  \n",
       "228251                     0      1  \n",
       "228252                     0      1  \n",
       "\n",
       "[228253 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Pearson correlation coefficient\n",
    "corr = hikari_2022.corr(method ='pearson')\n",
    "\n",
    "# Extract the correlation with the target variable 'Label'\n",
    "corr_with_target = corr['Label']\n",
    "\n",
    "# Select only columns with a correlation less than 0.05\n",
    "relevant_features = corr_with_target[abs(corr_with_target) >= 0.05].index\n",
    "\n",
    "# Filter the DataFrame to keep only the relevant features\n",
    "hikari_2022 = hikari_2022[relevant_features]\n",
    "\n",
    "print(\"Dataset after EDA:\")\n",
    "hikari_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078bc70f-198a-4179-8ff3-bffd38e7a6ee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dbbf30-c098-442b-92ad-ed1a9263d351",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Without feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac2ada9-2383-428d-ae11-0992d1cb9792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled,  (343860, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171930\n",
      "1    171930\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.9813804735931305\n",
      "Fold precision: 0.772767990444909\n",
      "Fold recall: 0.9667538289129622\n",
      "Fold F1-score: 0.8589445735147694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42974\n",
      "           1       0.77      0.97      0.86      2677\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.97      0.92     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343952, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171976\n",
      "1    171976\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.9820595386738517\n",
      "Fold precision: 0.78\n",
      "Fold recall: 0.9739258171134778\n",
      "Fold F1-score: 0.8662420382165605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42928\n",
      "           1       0.78      0.97      0.87      2723\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.98      0.93     45651\n",
      "weighted avg       0.99      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343710, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171855\n",
      "1    171855\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.9826947931042036\n",
      "Fold precision: 0.7808431494110354\n",
      "Fold recall: 0.9681014604150653\n",
      "Fold F1-score: 0.8644474948524365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43049\n",
      "           1       0.78      0.97      0.86      2602\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.98      0.93     45651\n",
      "weighted avg       0.99      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343910, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171955\n",
      "1    171955\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.9817086527929901\n",
      "Fold precision: 0.7726475745178258\n",
      "Fold recall: 0.9788967049241022\n",
      "Fold F1-score: 0.863628940062061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42949\n",
      "           1       0.77      0.98      0.86      2701\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.89      0.98      0.93     45650\n",
      "weighted avg       0.99      0.98      0.98     45650\n",
      "\n",
      "X_train_resampled,  (343800, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171900\n",
      "1    171900\n",
      "Name: count, dtype: int64\n",
      "Fold accuracy: 0.982935377875137\n",
      "Fold precision: 0.7841704718417047\n",
      "Fold recall: 0.9735449735449735\n",
      "Fold F1-score: 0.8686562131175182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43004\n",
      "           1       0.78      0.97      0.87      2646\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.89      0.98      0.93     45650\n",
      "weighted avg       0.99      0.98      0.98     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9821557672078626\n",
      "Mean precision: 0.778085837243095\n",
      "Mean recall: 0.9722445569821161\n",
      "Mean F1-score: 0.8643838519526691\n",
      "\n",
      "El tiempo de ejecucion fue: 204.17910766601562\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Resample with SMOTE \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        print(\"X_train_resampled, \", X_train_resampled.shape)\n",
    "        print(\"y_train_resampled, \", y_train_resampled.value_counts())\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Train Random Forest classifier\n",
    "        rf_classifier = RandomForestClassifier(random_state=42)\n",
    "        rf_classifier.fit(X_train, y_train_resampled)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")   \n",
    "\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e322040-5e11-4f73-bacc-00e3a7880e76",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### With DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f870be6e-6e65-4768-8b9a-5ef0dad8660e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled,  (343860, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171930\n",
      "1    171930\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 825us/step - accuracy: 0.9844 - loss: 0.0564 - val_accuracy: 0.9810 - val_loss: 0.0532\n",
      "Epoch 2/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 825us/step - accuracy: 0.9898 - loss: 0.0373 - val_accuracy: 0.9815 - val_loss: 0.0511\n",
      "Epoch 3/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 838us/step - accuracy: 0.9902 - loss: 0.0356 - val_accuracy: 0.9811 - val_loss: 0.0514\n",
      "Epoch 4/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 800us/step - accuracy: 0.9905 - loss: 0.0350 - val_accuracy: 0.9814 - val_loss: 0.0528\n",
      "Epoch 5/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 787us/step - accuracy: 0.9902 - loss: 0.0357 - val_accuracy: 0.9817 - val_loss: 0.0513\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 467us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449us/step\n",
      "Fold accuracy: 0.981161420341285\n",
      "Fold precision: 0.7743884022953791\n",
      "Fold recall: 0.9577885692939858\n",
      "Fold F1-score: 0.8563794255177021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42974\n",
      "           1       0.77      0.96      0.86      2677\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.97      0.92     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343952, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171976\n",
      "1    171976\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 824us/step - accuracy: 0.9846 - loss: 0.0576 - val_accuracy: 0.9808 - val_loss: 0.0562\n",
      "Epoch 2/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 790us/step - accuracy: 0.9898 - loss: 0.0369 - val_accuracy: 0.9804 - val_loss: 0.0599\n",
      "Epoch 3/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 790us/step - accuracy: 0.9899 - loss: 0.0365 - val_accuracy: 0.9806 - val_loss: 0.0562\n",
      "Epoch 4/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 787us/step - accuracy: 0.9903 - loss: 0.0353 - val_accuracy: 0.9820 - val_loss: 0.0469\n",
      "Epoch 5/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 810us/step - accuracy: 0.9901 - loss: 0.0359 - val_accuracy: 0.9820 - val_loss: 0.0490\n",
      "Epoch 6/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 787us/step - accuracy: 0.9905 - loss: 0.0348 - val_accuracy: 0.9815 - val_loss: 0.0567\n",
      "Epoch 7/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 789us/step - accuracy: 0.9904 - loss: 0.0349 - val_accuracy: 0.9815 - val_loss: 0.0534\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 457us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481us/step\n",
      "Fold accuracy: 0.9815776215197914\n",
      "Fold precision: 0.7784023668639053\n",
      "Fold recall: 0.9662137348512669\n",
      "Fold F1-score: 0.8621989185646404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42928\n",
      "           1       0.78      0.97      0.86      2723\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.97      0.93     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343710, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171855\n",
      "1    171855\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 808us/step - accuracy: 0.9843 - loss: 0.0618 - val_accuracy: 0.9811 - val_loss: 0.0452\n",
      "Epoch 2/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 807us/step - accuracy: 0.9896 - loss: 0.0381 - val_accuracy: 0.9826 - val_loss: 0.0504\n",
      "Epoch 3/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 803us/step - accuracy: 0.9901 - loss: 0.0360 - val_accuracy: 0.9828 - val_loss: 0.0439\n",
      "Epoch 4/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 788us/step - accuracy: 0.9902 - loss: 0.0356 - val_accuracy: 0.9804 - val_loss: 0.0557\n",
      "Epoch 5/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 793us/step - accuracy: 0.9904 - loss: 0.0353 - val_accuracy: 0.9808 - val_loss: 0.0521\n",
      "Epoch 6/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 814us/step - accuracy: 0.9901 - loss: 0.0358 - val_accuracy: 0.9824 - val_loss: 0.0506\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 463us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454us/step\n",
      "Fold accuracy: 0.9823224025760663\n",
      "Fold precision: 0.7800312012480499\n",
      "Fold recall: 0.9607993850883936\n",
      "Fold F1-score: 0.8610297916307904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43049\n",
      "           1       0.78      0.96      0.86      2602\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.97      0.93     45651\n",
      "weighted avg       0.99      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343910, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171955\n",
      "1    171955\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 817us/step - accuracy: 0.9765 - loss: 0.0825 - val_accuracy: 0.9784 - val_loss: 0.0621\n",
      "Epoch 2/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 804us/step - accuracy: 0.9895 - loss: 0.0379 - val_accuracy: 0.9802 - val_loss: 0.0533\n",
      "Epoch 3/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 809us/step - accuracy: 0.9900 - loss: 0.0364 - val_accuracy: 0.9814 - val_loss: 0.0530\n",
      "Epoch 4/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 809us/step - accuracy: 0.9902 - loss: 0.0358 - val_accuracy: 0.9815 - val_loss: 0.0479\n",
      "Epoch 5/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 802us/step - accuracy: 0.9902 - loss: 0.0358 - val_accuracy: 0.9800 - val_loss: 0.0564\n",
      "Epoch 6/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 798us/step - accuracy: 0.9902 - loss: 0.0359 - val_accuracy: 0.9810 - val_loss: 0.0518\n",
      "Epoch 7/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 819us/step - accuracy: 0.9906 - loss: 0.0345 - val_accuracy: 0.9816 - val_loss: 0.0531\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 454us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 466us/step\n",
      "Fold accuracy: 0.9815334063526835\n",
      "Fold precision: 0.7724340175953079\n",
      "Fold recall: 0.9751943724546465\n",
      "Fold F1-score: 0.8620520373097693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42949\n",
      "           1       0.77      0.98      0.86      2701\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.89      0.98      0.93     45650\n",
      "weighted avg       0.99      0.98      0.98     45650\n",
      "\n",
      "X_train_resampled,  (343800, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171900\n",
      "1    171900\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 822us/step - accuracy: 0.9844 - loss: 0.0626 - val_accuracy: 0.9812 - val_loss: 0.0559\n",
      "Epoch 2/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 802us/step - accuracy: 0.9899 - loss: 0.0366 - val_accuracy: 0.9804 - val_loss: 0.0529\n",
      "Epoch 3/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 804us/step - accuracy: 0.9902 - loss: 0.0360 - val_accuracy: 0.9816 - val_loss: 0.0539\n",
      "Epoch 4/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 811us/step - accuracy: 0.9899 - loss: 0.0364 - val_accuracy: 0.9814 - val_loss: 0.0494\n",
      "Epoch 5/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 798us/step - accuracy: 0.9900 - loss: 0.0365 - val_accuracy: 0.9806 - val_loss: 0.0489\n",
      "Epoch 6/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 804us/step - accuracy: 0.9906 - loss: 0.0347 - val_accuracy: 0.9823 - val_loss: 0.0495\n",
      "Epoch 7/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 816us/step - accuracy: 0.9903 - loss: 0.0355 - val_accuracy: 0.9827 - val_loss: 0.0464\n",
      "Epoch 8/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 801us/step - accuracy: 0.9904 - loss: 0.0353 - val_accuracy: 0.9824 - val_loss: 0.0442\n",
      "Epoch 9/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 800us/step - accuracy: 0.9902 - loss: 0.0355 - val_accuracy: 0.9819 - val_loss: 0.0504\n",
      "Epoch 10/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 813us/step - accuracy: 0.9904 - loss: 0.0350 - val_accuracy: 0.9823 - val_loss: 0.0477\n",
      "Epoch 11/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 810us/step - accuracy: 0.9902 - loss: 0.0356 - val_accuracy: 0.9816 - val_loss: 0.0533\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 460us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451us/step\n",
      "Fold accuracy: 0.9826506024096385\n",
      "Fold precision: 0.7838334353949785\n",
      "Fold recall: 0.9674981103552532\n",
      "Fold F1-score: 0.8660351826792964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43004\n",
      "           1       0.78      0.97      0.87      2646\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.89      0.98      0.93     45650\n",
      "weighted avg       0.99      0.98      0.98     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9818490906398928\n",
      "Mean precision: 0.7778178846795241\n",
      "Mean recall: 0.9654988344087092\n",
      "Mean F1-score: 0.8615390711404398\n",
      "\n",
      "El tiempo de ejecucion fue: 583.7174139022827\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the DNN model\n",
    "def create_dnn(input_dim):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    \n",
    "    # Hidden layer 1\n",
    "    x = Dense(input_dim * 2)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Hidden layer 2\n",
    "    x = Dense(input_dim)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Feature layer\n",
    "    n_bottleneck = round(float(input_dim) / 2.0)\n",
    "    bottleneck = Dense(n_bottleneck)(x)\n",
    "    bottleneck = BatchNormalization()(bottleneck)\n",
    "    bottleneck = ReLU()(bottleneck)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation='sigmoid')(bottleneck)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Model for feature extraction\n",
    "    feature_extractor = Model(inputs=inputs, outputs=bottleneck)\n",
    "    \n",
    "    return model, feature_extractor\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_dnn(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Resample with SMOTE \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        print(\"X_train_resampled, \", X_train_resampled.shape)\n",
    "        print(\"y_train_resampled, \", y_train_resampled.value_counts())\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        dnn, feature_extractor = create_dnn(n_inputs)\n",
    "        \n",
    "        # Early Stopping\n",
    "        early_stopping1 = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "        early_stopping2 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # Fit the DNN model\n",
    "        dnn.fit(X_train, y_train_resampled, epochs=100, batch_size=32, verbose=1,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        callbacks=[early_stopping1, early_stopping2])\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = feature_extractor.predict(X_train)\n",
    "        X_test_encoded = feature_extractor.predict(X_test)\n",
    "        \n",
    "        # Train Random Forest classifier\n",
    "        rf_classifier_encoded = RandomForestClassifier(random_state=42)\n",
    "        rf_classifier_encoded.fit(X_train_encoded, y_train_resampled)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = rf_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_dnn(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9176c09-ba87-45f0-9113-30f7de69c72d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### With DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f60b25-c365-4e28-9022-59c22addcd30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_dbn(layers, file_name='dbn_structure.png'):\n",
    "    # Crear un grafo dirigido\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # A√±adir nodos para cada capa RBM\n",
    "    for i, n_units in enumerate(layers):\n",
    "        G.add_node(f\"RBM {i+1}\\n{n_units} unidades\", layer=i+1)\n",
    "\n",
    "    # A√±adir aristas entre nodos (de una capa a otra)\n",
    "    for i in range(len(layers) - 1):\n",
    "        G.add_edge(f\"RBM {i+1}\\n{layers[i]} unidades\", f\"RBM {i+2}\\n{layers[i+1]} unidades\")\n",
    "\n",
    "    # Dibujar el grafo\n",
    "    pos = nx.spring_layout(G)  # Posici√≥n de los nodos\n",
    "    nx.draw(G, pos, with_labels=True, node_size=3000, node_color='lightblue', font_size=10, font_weight='bold')\n",
    "    \n",
    "    # Guardar la imagen a un archivo\n",
    "    plt.title(\"Arquitectura de la DBN\")\n",
    "    plt.savefig(file_name)\n",
    "    plt.show()\n",
    "    \n",
    "#visualize_dbn([X.shape[1]*2, X.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d237480-eb1b-4961-9f4d-0846b4517f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled,  (343860, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171930\n",
      "1    171930\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.31, time = 5.23s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.26, time = 6.40s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.21, time = 6.50s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.15, time = 6.28s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.14, time = 6.31s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.25, time = 6.53s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5.23, time = 6.28s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5.11, time = 6.40s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.13, time = 6.19s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.03, time = 6.34s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -2.85, time = 4.89s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -0.75, time = 5.76s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -0.86, time = 5.79s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -0.79, time = 5.76s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -0.85, time = 5.86s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -0.87, time = 5.95s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -1.25, time = 5.96s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -0.79, time = 5.77s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -0.76, time = 5.81s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -0.83, time = 5.77s\n",
      "Fold accuracy: 0.9735383671770608\n",
      "Fold precision: 0.7385514777525171\n",
      "Fold recall: 0.8494583488980202\n",
      "Fold F1-score: 0.7901320361362058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     42974\n",
      "           1       0.74      0.85      0.79      2677\n",
      "\n",
      "    accuracy                           0.97     45651\n",
      "   macro avg       0.86      0.92      0.89     45651\n",
      "weighted avg       0.98      0.97      0.97     45651\n",
      "\n",
      "X_train_resampled,  (343952, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171976\n",
      "1    171976\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.59, time = 5.19s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.45, time = 6.43s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.18, time = 6.57s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.23, time = 6.54s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.09, time = 6.67s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.77, time = 6.54s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5.11, time = 6.54s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.84, time = 6.46s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.95, time = 6.72s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.88, time = 6.59s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -3.04, time = 5.08s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -3.45, time = 5.79s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -3.11, time = 5.87s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -3.25, time = 6.21s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -3.33, time = 5.97s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -3.34, time = 5.92s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -3.05, time = 5.90s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -3.16, time = 5.84s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.13, time = 6.14s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.29, time = 5.92s\n",
      "Fold accuracy: 0.9560141070294188\n",
      "Fold precision: 0.645858833129335\n",
      "Fold recall: 0.5813441057656996\n",
      "Fold F1-score: 0.611905682257441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     42928\n",
      "           1       0.65      0.58      0.61      2723\n",
      "\n",
      "    accuracy                           0.96     45651\n",
      "   macro avg       0.81      0.78      0.79     45651\n",
      "weighted avg       0.95      0.96      0.95     45651\n",
      "\n",
      "X_train_resampled,  (343710, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171855\n",
      "1    171855\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.51, time = 5.29s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.53, time = 6.83s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.21, time = 6.70s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.11, time = 6.54s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.22, time = 6.68s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.25, time = 6.63s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5.13, time = 6.60s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5.11, time = 6.63s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.14, time = 6.55s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.03, time = 6.58s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -4.10, time = 5.13s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -3.96, time = 5.91s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.21, time = 5.94s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -3.91, time = 5.80s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -3.89, time = 5.83s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.08, time = 6.05s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.15, time = 5.80s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.67, time = 6.04s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.04, time = 5.74s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.89, time = 5.85s\n",
      "Fold accuracy: 0.9807452191627785\n",
      "Fold precision: 0.7481993661768943\n",
      "Fold recall: 0.9980784012298232\n",
      "Fold F1-score: 0.855260991272847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43049\n",
      "           1       0.75      1.00      0.86      2602\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.87      0.99      0.92     45651\n",
      "weighted avg       0.99      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343910, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171955\n",
      "1    171955\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.44, time = 5.14s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.39, time = 6.43s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.30, time = 6.62s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.20, time = 6.32s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.34, time = 6.59s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.25, time = 6.42s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5.23, time = 6.30s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5.15, time = 6.38s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.01, time = 6.43s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.22, time = 6.57s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -1.89, time = 4.99s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -2.77, time = 5.73s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -0.68, time = 5.73s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -0.79, time = 6.07s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -0.68, time = 5.85s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -0.93, time = 5.85s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -3.35, time = 5.71s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -0.62, time = 5.75s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -0.83, time = 5.88s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -0.72, time = 5.86s\n",
      "Fold accuracy: 0.9815772179627601\n",
      "Fold precision: 0.7636054421768708\n",
      "Fold recall: 0.9974083672713809\n",
      "Fold F1-score: 0.8649863541499438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42949\n",
      "           1       0.76      1.00      0.86      2701\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.88      0.99      0.93     45650\n",
      "weighted avg       0.99      0.98      0.98     45650\n",
      "\n",
      "X_train_resampled,  (343800, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171900\n",
      "1    171900\n",
      "Name: count, dtype: int64\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5.35, time = 5.08s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.37, time = 6.47s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5.05, time = 6.44s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.04, time = 6.57s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.10, time = 6.36s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.04, time = 6.39s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5.00, time = 6.46s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.97, time = 6.44s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.84, time = 6.60s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.83, time = 6.46s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -4.35, time = 5.75s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -4.87, time = 6.25s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.49, time = 6.09s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.43, time = 6.32s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.57, time = 6.17s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.87, time = 6.02s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.50, time = 5.88s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.48, time = 5.90s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.87, time = 5.70s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.64, time = 6.00s\n",
      "Fold accuracy: 0.963723986856517\n",
      "Fold precision: 0.6731980405878236\n",
      "Fold recall: 0.72713529856387\n",
      "Fold F1-score: 0.6991279069767442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     43004\n",
      "           1       0.67      0.73      0.70      2646\n",
      "\n",
      "    accuracy                           0.96     45650\n",
      "   macro avg       0.83      0.85      0.84     45650\n",
      "weighted avg       0.97      0.96      0.96     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9711197796377069\n",
      "Mean precision: 0.7138826319646882\n",
      "Mean recall: 0.8306849043457587\n",
      "Mean F1-score: 0.7642825941586364\n",
      "\n",
      "El tiempo de ejecucion fue: 1010.9553580284119\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the DBN class\n",
    "class DBN(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rbm_layers, rbm_learning_rate, rbm_n_iter):\n",
    "        self.rbm_layers = rbm_layers\n",
    "        self.rbm_learning_rate = rbm_learning_rate\n",
    "        self.rbm_n_iter = rbm_n_iter\n",
    "        self.rbms = []\n",
    "        for i, n_components in enumerate(rbm_layers):\n",
    "            self.rbms.append(BernoulliRBM(n_components=n_components, learning_rate=rbm_learning_rate, n_iter=rbm_n_iter, verbose=1))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        input_data = X\n",
    "        for rbm in self.rbms:\n",
    "            rbm.fit(input_data)\n",
    "            input_data = rbm.transform(input_data)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        input_data = X\n",
    "        for rbm in self.rbms:\n",
    "            input_data = rbm.transform(input_data)\n",
    "        return input_data\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_dbn(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Resample with SMOTE \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        print(\"X_train_resampled, \", X_train_resampled.shape)\n",
    "        print(\"y_train_resampled, \", y_train_resampled.value_counts())\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        dbn = DBN(rbm_layers=[n_inputs*2, n_inputs], rbm_learning_rate=0.1, rbm_n_iter=10)\n",
    "        \n",
    "        # Fit the DBN model\n",
    "        dbn.fit(X_train)\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = dbn.transform(X_train)\n",
    "        X_test_encoded = dbn.transform(X_test)\n",
    "        \n",
    "        # Train Random Forest classifier\n",
    "        rf_classifier_encoded = RandomForestClassifier(random_state=42)\n",
    "        rf_classifier_encoded.fit(X_train_encoded, y_train_resampled)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = rf_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "    \n",
    "    \n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_dbn(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8124559-b551-4af6-8503-0901cfc82b15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### With Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c58e6d3-7e3c-4147-8ef4-a057322d7f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled,  (343860, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171930\n",
      "1    171930\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 730us/step - loss: 0.1773 - val_loss: 0.0787\n",
      "Epoch 2/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 704us/step - loss: 0.0810 - val_loss: 0.0567\n",
      "Epoch 3/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 701us/step - loss: 0.0835 - val_loss: 0.0327\n",
      "Epoch 4/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 719us/step - loss: 0.0620 - val_loss: 0.0300\n",
      "Epoch 5/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 717us/step - loss: 0.0604 - val_loss: 0.0705\n",
      "Epoch 6/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 761us/step - loss: 0.0717 - val_loss: 0.0323\n",
      "Epoch 7/100\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 725us/step - loss: 0.0589 - val_loss: 0.0303\n",
      "\u001b[1m10746/10746\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 421us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434us/step\n",
      "Fold accuracy: 0.981161420341285\n",
      "Fold precision: 0.7745542459957692\n",
      "Fold recall: 0.9574150168098617\n",
      "Fold F1-score: 0.856331440026729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42974\n",
      "           1       0.77      0.96      0.86      2677\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.97      0.92     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343952, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171976\n",
      "1    171976\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 708us/step - loss: 0.1581 - val_loss: 0.0642\n",
      "Epoch 2/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 689us/step - loss: 0.0823 - val_loss: 0.1027\n",
      "Epoch 3/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 705us/step - loss: 0.1051 - val_loss: 0.1255\n",
      "Epoch 4/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 726us/step - loss: 0.0633 - val_loss: 0.0482\n",
      "Epoch 5/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 708us/step - loss: 0.0887 - val_loss: 0.0503\n",
      "Epoch 6/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 690us/step - loss: 0.0478 - val_loss: 0.0668\n",
      "Epoch 7/100\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 699us/step - loss: 0.0742 - val_loss: 0.0887\n",
      "\u001b[1m10749/10749\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 415us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409us/step\n",
      "Fold accuracy: 0.9815338108694224\n",
      "Fold precision: 0.7786010669828097\n",
      "Fold recall: 0.964744766801322\n",
      "Fold F1-score: 0.8617352796457274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42928\n",
      "           1       0.78      0.96      0.86      2723\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.97      0.93     45651\n",
      "weighted avg       0.98      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343710, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171855\n",
      "1    171855\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 719us/step - loss: 0.1224 - val_loss: 0.7764\n",
      "Epoch 2/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 705us/step - loss: 0.0550 - val_loss: 0.5417\n",
      "Epoch 3/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 715us/step - loss: 0.0582 - val_loss: 0.3000\n",
      "Epoch 4/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 717us/step - loss: 0.0479 - val_loss: 0.3857\n",
      "Epoch 5/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 723us/step - loss: 0.0529 - val_loss: 0.4437\n",
      "Epoch 6/100\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 723us/step - loss: 0.0445 - val_loss: 0.3072\n",
      "\u001b[1m10741/10741\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 429us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step\n",
      "Fold accuracy: 0.9822785919256971\n",
      "Fold precision: 0.7797191887675508\n",
      "Fold recall: 0.9604150653343582\n",
      "Fold F1-score: 0.860685379714138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43049\n",
      "           1       0.78      0.96      0.86      2602\n",
      "\n",
      "    accuracy                           0.98     45651\n",
      "   macro avg       0.89      0.97      0.93     45651\n",
      "weighted avg       0.99      0.98      0.98     45651\n",
      "\n",
      "X_train_resampled,  (343910, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171955\n",
      "1    171955\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 752us/step - loss: 0.1928 - val_loss: 0.1199\n",
      "Epoch 2/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 712us/step - loss: 0.1011 - val_loss: 0.0824\n",
      "Epoch 3/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 695us/step - loss: 0.0821 - val_loss: 0.5132\n",
      "Epoch 4/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 702us/step - loss: 0.0925 - val_loss: 0.2058\n",
      "Epoch 5/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 722us/step - loss: 0.0794 - val_loss: 0.0442\n",
      "Epoch 6/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 705us/step - loss: 0.0503 - val_loss: 0.1101\n",
      "Epoch 7/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 712us/step - loss: 0.0384 - val_loss: 0.1621\n",
      "Epoch 8/100\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 700us/step - loss: 0.0658 - val_loss: 0.0729\n",
      "\u001b[1m10748/10748\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 418us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416us/step\n",
      "Fold accuracy: 0.9814895947426068\n",
      "Fold precision: 0.7734236888626989\n",
      "Fold recall: 0.9718622732321363\n",
      "Fold F1-score: 0.8613617719442166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42949\n",
      "           1       0.77      0.97      0.86      2701\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.89      0.98      0.93     45650\n",
      "weighted avg       0.98      0.98      0.98     45650\n",
      "\n",
      "X_train_resampled,  (343800, 43)\n",
      "y_train_resampled,  Label\n",
      "0    171900\n",
      "1    171900\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 734us/step - loss: 0.1855 - val_loss: 0.0787\n",
      "Epoch 2/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 720us/step - loss: 0.0937 - val_loss: 0.0389\n",
      "Epoch 3/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 708us/step - loss: 0.0695 - val_loss: 0.1357\n",
      "Epoch 4/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 707us/step - loss: 0.0569 - val_loss: 0.0749\n",
      "Epoch 5/100\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 733us/step - loss: 0.0535 - val_loss: 0.1297\n",
      "\u001b[1m10744/10744\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 438us/step\n",
      "\u001b[1m1427/1427\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435us/step\n",
      "Fold accuracy: 0.9824972617743702\n",
      "Fold precision: 0.7830217591173766\n",
      "Fold recall: 0.9656084656084656\n",
      "Fold F1-score: 0.8647825351159248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     43004\n",
      "           1       0.78      0.97      0.86      2646\n",
      "\n",
      "    accuracy                           0.98     45650\n",
      "   macro avg       0.89      0.97      0.93     45650\n",
      "weighted avg       0.99      0.98      0.98     45650\n",
      "\n",
      "Mean classification report:\n",
      "==========================\n",
      "Mean accuracy: 0.9817921359306764\n",
      "Mean precision: 0.777863989945241\n",
      "Mean recall: 0.9640091175572287\n",
      "Mean F1-score: 0.8609792812893472\n",
      "\n",
      "El tiempo de ejecucion fue: 1027.23504114151\n"
     ]
    }
   ],
   "source": [
    "X = hikari_2022.iloc[:, :-1]\n",
    "y = hikari_2022['Label']\n",
    "\n",
    "# Define the autoencoder model\n",
    "def create_autoencoder(n_inputs):\n",
    "    inputs = Input(shape=(n_inputs,))\n",
    "    \n",
    "    # Define Encoder\n",
    "    e = Dense(n_inputs*2)(inputs)\n",
    "    e = BatchNormalization()(e)\n",
    "    e = LeakyReLU()(e)\n",
    "    \n",
    "    # Bottleneck\n",
    "    n_bottleneck = round(float(n_inputs)/2.0)\n",
    "    bottleneck = Dense(n_bottleneck)(e)\n",
    "    \n",
    "    # Define Decoder\n",
    "    d = Dense(n_inputs*2)(bottleneck)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU()(d)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(n_inputs, activation='linear')(d)\n",
    "    \n",
    "    # Define autoencoder model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Define encoder model\n",
    "    encoder = Model(inputs=inputs, outputs=bottleneck)\n",
    "    \n",
    "    return model, encoder\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validation_autoencoder(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Resample with SMOTE \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        print(\"X_train_resampled, \", X_train_resampled.shape)\n",
    "        print(\"y_train_resampled, \", y_train_resampled.value_counts())\n",
    "        \n",
    "        # Normalize data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        autoencoder, encoder = create_autoencoder(n_inputs)\n",
    "        \n",
    "        # Early Stopping\n",
    "        early_stopping1 = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "        early_stopping2 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # Fit the DNN model\n",
    "        autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, verbose=1,\n",
    "                        validation_data=(X_test, X_test),\n",
    "                        callbacks=[early_stopping1, early_stopping2])\n",
    "        \n",
    "        # Encode the data\n",
    "        X_train_encoded = encoder.predict(X_train)\n",
    "        X_test_encoded = encoder.predict(X_test)\n",
    "        \n",
    "        # Train Random Forest classifier\n",
    "        rf_classifier_encoded = RandomForestClassifier(random_state=42)\n",
    "        rf_classifier_encoded.fit(X_train_encoded, y_train_resampled)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_encoded = rf_classifier_encoded.predict(X_test_encoded)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_encoded)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred_encoded)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred_encoded)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold accuracy: {accuracy}\")\n",
    "        print(f\"Fold precision: {precision}\")\n",
    "        print(f\"Fold recall: {recall}\")\n",
    "        print(f\"Fold F1-score: {f1}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred_encoded)\n",
    "        print(report)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"Mean classification report:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean precision: {mean_precision}\")\n",
    "    print(f\"Mean recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1}\")\n",
    "\n",
    "\n",
    "tiempo_inicial = time()\n",
    "#\n",
    "cross_validation_autoencoder(X, y)\n",
    "#\n",
    "tiempo_final = time() \n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print ('\\nEl tiempo de ejecucion fue:', tiempo_ejecucion) # Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4daef-afdd-4dfe-a145-05ab6c4368c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
